Model,AVG,ifeval,ifeval_for_system_prompt,m_ifeval,m_ifeval_for_system_prompt
Llama-3.1-Swallow-8B-Instruct-v0.5,0.51,0.65,0.52,0.49,0.38
Llama-3.3-Swallow-70B-Instruct-v0.4,0.58,0.80,0.54,0.59,0.40
Qwen3-235B-A22B-FP8_non-thinking,0.77,0.88,0.85,0.67,0.66
RakutenAI-2.0-8x7B-instruct,0.51,0.85,0.44,0.52,0.22
Stockmark-2-100B-instruct-beta,0.50,0.56,0.54,0.47,0.44
gemma-3-27b-it,0.76,0.88,0.90,0.62,0.65
llm-jp-3.1-8x13b-instruct4,0.39,0.56,0.29,0.40,0.31
qwq-bakeneko-32b,0.72,0.83,0.81,0.63,0.60
sarashina2.2-3b-instruct-v0.1,0.38,0.48,0.41,0.33,0.29
gemini-2.5-pro,0.84,0.91,0.91,0.77,0.78
gpt-4.1-2025-04-14,0.86,0.91,0.89,0.82,0.81