
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../MatchMaker/">
      
      
        <link rel="next" href="../PairwiseJudge/">
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.5">
    
    
      
        <title>Metric - flexeval</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.8608ea7d.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../assets/_mkdocstrings.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="green" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#flexeval.core.metric.base.Metric" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="flexeval" class="md-header__button md-logo" aria-label="flexeval" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            flexeval
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Metric
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="flexeval" class="md-nav__button md-logo" aria-label="flexeval" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    flexeval
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    FlexEval
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../installation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Installation
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../getting_started/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Getting Started
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../configuration_guide/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Configuration Guide
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../how_to/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    How to
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5" id="__nav_5_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            How to
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../how_to/configure_few_shot_examples/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Configure Few-shot Examples
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../how_to/evaluate_with_llm_judges/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Evaluate with LLM Judges
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../how_to/implement_your_own_module/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Implement Your Own Class
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../design_principles/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Design Principles
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../preset_configs/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Preset Configs
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_7" id="__nav_7_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            Preset Configs
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_1" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../preset_configs/EvalSetup/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    EvalSetup
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_7_1" id="__nav_7_1_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_7_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_1">
            <span class="md-nav__icon md-icon"></span>
            EvalSetup
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../preset_configs/EvalSetup/code_chat/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Code chat
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../preset_configs/EvalSetup/code_generation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Code generation
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../preset_configs/EvalSetup/en_chat/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    En chat
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../preset_configs/EvalSetup/en_generation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    En generation
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../preset_configs/EvalSetup/en_multiple_choice/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    En multiple choice
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../preset_configs/EvalSetup/en_perplexity/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    En perplexity
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../preset_configs/EvalSetup/ja_chat/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Ja chat
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../preset_configs/EvalSetup/ja_generation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Ja generation
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../preset_configs/EvalSetup/ja_multiple_choice/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Ja multiple choice
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../preset_configs/EvalSetup/translation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Translation
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../preset_configs/EvalSetup/translation_chat/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Translation chat
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../preset_configs/Metric/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Metric
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../preset_configs/PairwiseJudge/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PairwiseJudge
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_8" checked>
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    API Reference
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_8" id="__nav_8_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_8_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_8">
            <span class="md-nav__icon md-icon"></span>
            API Reference
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ChatDataset/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ChatDataset
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../EvalSetup/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    EvalSetup
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../FewShotGenerator/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    FewShotGenerator
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../GenerationDataset/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    GenerationDataset
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../HFMultipleChoiceDataset/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    HFMultipleChoiceDataset
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../HFRewardBenchDataset/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    HFRewardBenchDataset
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../LMOutput/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    LMOutput
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../MatchMaker/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    MatchMaker
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Metric
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Metric
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#flexeval.core.metric.base.Metric" class="md-nav__link">
    <span class="md-ellipsis">
      Metric
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#flexeval.core.metric.base.MetricResult" class="md-nav__link">
    <span class="md-ellipsis">
      MetricResult
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#flexeval.core.metric.bleu.BLEU" class="md-nav__link">
    <span class="md-ellipsis">
      BLEU
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#flexeval.core.metric.char_f1.CharF1" class="md-nav__link">
    <span class="md-ellipsis">
      CharF1
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#flexeval.core.metric.code_eval.CodeEval" class="md-nav__link">
    <span class="md-ellipsis">
      CodeEval
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#flexeval.core.metric.common_prefix_length.CommonPrefixLength" class="md-nav__link">
    <span class="md-ellipsis">
      CommonPrefixLength
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#flexeval.core.metric.common_string_length.CommonStringLength" class="md-nav__link">
    <span class="md-ellipsis">
      CommonStringLength
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#flexeval.core.metric.correlation.Correlation" class="md-nav__link">
    <span class="md-ellipsis">
      Correlation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#flexeval.core.metric.exact_match.ExactMatch" class="md-nav__link">
    <span class="md-ellipsis">
      ExactMatch
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#flexeval.core.metric.llm_geval_score.ChatLLMGEvalScore" class="md-nav__link">
    <span class="md-ellipsis">
      ChatLLMGEvalScore
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#flexeval.core.metric.llm_geval_score.LLMGEvalScore" class="md-nav__link">
    <span class="md-ellipsis">
      LLMGEvalScore
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#flexeval.core.metric.llm_label.ChatLLMLabel" class="md-nav__link">
    <span class="md-ellipsis">
      ChatLLMLabel
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#flexeval.core.metric.llm_label.LLMLabel" class="md-nav__link">
    <span class="md-ellipsis">
      LLMLabel
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#flexeval.core.metric.llm_score.ChatLLMScore" class="md-nav__link">
    <span class="md-ellipsis">
      ChatLLMScore
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#flexeval.core.metric.llm_score.LLMScore" class="md-nav__link">
    <span class="md-ellipsis">
      LLMScore
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#flexeval.core.metric.output_length_stats.OutputLengthStats" class="md-nav__link">
    <span class="md-ellipsis">
      OutputLengthStats
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#flexeval.core.metric.perspective_api.PerspectiveAPI" class="md-nav__link">
    <span class="md-ellipsis">
      PerspectiveAPI
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#flexeval.core.metric.repetition_count.RepetitionCount" class="md-nav__link">
    <span class="md-ellipsis">
      RepetitionCount
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#flexeval.core.metric.rouge.ROUGE" class="md-nav__link">
    <span class="md-ellipsis">
      ROUGE
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#flexeval.core.metric.substring_match.SubstringMatch" class="md-nav__link">
    <span class="md-ellipsis">
      SubstringMatch
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#flexeval.core.metric.xer.XER" class="md-nav__link">
    <span class="md-ellipsis">
      XER
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../PairwiseJudge/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PairwiseJudge
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../PairwiseScorer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PairwiseScorer
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../PromptTemplate/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PromptTemplate
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ResultRecorder/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ResultRecorder
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../RewardModel/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    RewardModel
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../StringProcessor/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    StringProcessor
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../TextDataset/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TextDataset
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Tokenizer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Tokenizer
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../utils/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Utils
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#flexeval.core.metric.base.Metric" class="md-nav__link">
    <span class="md-ellipsis">
      Metric
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#flexeval.core.metric.base.MetricResult" class="md-nav__link">
    <span class="md-ellipsis">
      MetricResult
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#flexeval.core.metric.bleu.BLEU" class="md-nav__link">
    <span class="md-ellipsis">
      BLEU
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#flexeval.core.metric.char_f1.CharF1" class="md-nav__link">
    <span class="md-ellipsis">
      CharF1
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#flexeval.core.metric.code_eval.CodeEval" class="md-nav__link">
    <span class="md-ellipsis">
      CodeEval
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#flexeval.core.metric.common_prefix_length.CommonPrefixLength" class="md-nav__link">
    <span class="md-ellipsis">
      CommonPrefixLength
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#flexeval.core.metric.common_string_length.CommonStringLength" class="md-nav__link">
    <span class="md-ellipsis">
      CommonStringLength
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#flexeval.core.metric.correlation.Correlation" class="md-nav__link">
    <span class="md-ellipsis">
      Correlation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#flexeval.core.metric.exact_match.ExactMatch" class="md-nav__link">
    <span class="md-ellipsis">
      ExactMatch
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#flexeval.core.metric.llm_geval_score.ChatLLMGEvalScore" class="md-nav__link">
    <span class="md-ellipsis">
      ChatLLMGEvalScore
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#flexeval.core.metric.llm_geval_score.LLMGEvalScore" class="md-nav__link">
    <span class="md-ellipsis">
      LLMGEvalScore
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#flexeval.core.metric.llm_label.ChatLLMLabel" class="md-nav__link">
    <span class="md-ellipsis">
      ChatLLMLabel
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#flexeval.core.metric.llm_label.LLMLabel" class="md-nav__link">
    <span class="md-ellipsis">
      LLMLabel
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#flexeval.core.metric.llm_score.ChatLLMScore" class="md-nav__link">
    <span class="md-ellipsis">
      ChatLLMScore
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#flexeval.core.metric.llm_score.LLMScore" class="md-nav__link">
    <span class="md-ellipsis">
      LLMScore
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#flexeval.core.metric.output_length_stats.OutputLengthStats" class="md-nav__link">
    <span class="md-ellipsis">
      OutputLengthStats
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#flexeval.core.metric.perspective_api.PerspectiveAPI" class="md-nav__link">
    <span class="md-ellipsis">
      PerspectiveAPI
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#flexeval.core.metric.repetition_count.RepetitionCount" class="md-nav__link">
    <span class="md-ellipsis">
      RepetitionCount
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#flexeval.core.metric.rouge.ROUGE" class="md-nav__link">
    <span class="md-ellipsis">
      ROUGE
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#flexeval.core.metric.substring_match.SubstringMatch" class="md-nav__link">
    <span class="md-ellipsis">
      SubstringMatch
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#flexeval.core.metric.xer.XER" class="md-nav__link">
    <span class="md-ellipsis">
      XER
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



  <h1>Metric</h1>

<div class="doc doc-object doc-class">



<h2 id="flexeval.core.metric.base.Metric" class="doc doc-heading">
            <span class="doc doc-object-name doc-class-name">Metric</span>


<a href="#flexeval.core.metric.base.Metric" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents first">


        <p>Base class for metrics.</p>







              <details class="quote">
                <summary>Source code in <code>flexeval/core/metric/base.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">Metric</span><span class="p">(</span><span class="n">ABC</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Base class for metrics.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">lm_outputs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">references_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
        <span class="n">task_inputs_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MetricResult</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Evaluate the outputs of `LanguageModel` against the references.</span>

<span class="sd">        Args:</span>
<span class="sd">            lm_outputs: List of model outputs.</span>
<span class="sd">            references_list: List of reference outputs.</span>
<span class="sd">            task_inputs_list: List of task inputs.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="flexeval.core.metric.base.Metric.evaluate" class="doc doc-heading">
            <span class="doc doc-object-name doc-function-name">evaluate</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-abstractmethod"><code>abstractmethod</code></small>
  </span>

<a href="#flexeval.core.metric.base.Metric.evaluate" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="nf">evaluate</span><span class="p">(</span>
    <span class="n">lm_outputs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">references_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
    <span class="n">task_inputs_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MetricResult</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Evaluate the outputs of <code>LanguageModel</code> against the references.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>lm_outputs</code></b>
              (<code><span title="list">list</span>[<span title="str">str</span>]</code>)
          –
          <div class="doc-md-description">
            <p>List of model outputs.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>references_list</code></b>
              (<code><span title="list">list</span>[<span title="list">list</span>[<span title="str">str</span>]]</code>)
          –
          <div class="doc-md-description">
            <p>List of reference outputs.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>task_inputs_list</code></b>
              (<code><span title="list">list</span>[<span title="dict">dict</span>[<span title="str">str</span>, <span title="str">str</span>]] | None</code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>List of task inputs.</p>
          </div>
        </li>
    </ul>


            <details class="quote">
              <summary>Source code in <code>flexeval/core/metric/base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@abstractmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">lm_outputs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">references_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
    <span class="n">task_inputs_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MetricResult</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Evaluate the outputs of `LanguageModel` against the references.</span>

<span class="sd">    Args:</span>
<span class="sd">        lm_outputs: List of model outputs.</span>
<span class="sd">        references_list: List of reference outputs.</span>
<span class="sd">        task_inputs_list: List of task inputs.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="flexeval.core.metric.base.MetricResult" class="doc doc-heading">
            <span class="doc doc-object-name doc-class-name">MetricResult</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-dataclass"><code>dataclass</code></small>
  </span>

<a href="#flexeval.core.metric.base.MetricResult" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents first">


        <p>A dataclass representing the result of a metric evaluation.</p>







              <details class="quote">
                <summary>Source code in <code>flexeval/core/metric/base.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@dataclass</span>
<span class="k">class</span><span class="w"> </span><span class="nc">MetricResult</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A dataclass representing the result of a metric evaluation.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">summary</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Summary containing aggregated metric values.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">instance_details</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A list of evaluate details for each instance.</span>
<span class="sd">    Useful for error analysis.</span>
<span class="sd">    &quot;&quot;&quot;</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.base.MetricResult.summary" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">summary</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.base.MetricResult.summary" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">summary</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Summary containing aggregated metric values.</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.base.MetricResult.instance_details" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">instance_details</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-class-attribute"><code>class-attribute</code></small>
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.base.MetricResult.instance_details" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">instance_details</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>A list of evaluate details for each instance.
Useful for error analysis.</p>

    </div>

</div>



<div class="doc doc-object doc-function">


<h3 id="flexeval.core.metric.base.MetricResult.__init__" class="doc doc-heading">
            <span class="doc doc-object-name doc-function-name">__init__</span>


<a href="#flexeval.core.metric.base.MetricResult.__init__" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="fm">__init__</span><span class="p">(</span>
    <span class="nf">summary</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span>
    <span class="n">instance_details</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>

    <div class="doc doc-contents ">


    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="flexeval.core.metric.bleu.BLEU" class="doc doc-heading">
            <span class="doc doc-object-name doc-class-name">BLEU</span>


<a href="#flexeval.core.metric.bleu.BLEU" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents first">


        <p>An implementation of <a href="https://aclanthology.org/P02-1040/">BLEU</a>.
The calculation is based on the <a href="https://github.com/mjpost/sacrebleu">sacrebleu</a> library.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>tokenize_option</code></b>
              (<code><span title="str">str</span> | None</code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>Tokenization option for sacrebleu.
If <code>None</code>, sacrebleu will use the default tokenization.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>lm_output_processor</code></b>
              (<code><a class="autorefs autorefs-internal" title="StringProcessor (flexeval.core.string_processor.base.StringProcessor)" href="../StringProcessor/#flexeval.core.string_processor.base.StringProcessor">StringProcessor</a> | <span title="list">list</span>[<a class="autorefs autorefs-internal" title="StringProcessor (flexeval.core.string_processor.base.StringProcessor)" href="../StringProcessor/#flexeval.core.string_processor.base.StringProcessor">StringProcessor</a>] | None</code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>StringProcessor or a list of StringProcessor to be applied to the model outputs before comparison.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>reference_processor</code></b>
              (<code><a class="autorefs autorefs-internal" title="StringProcessor (flexeval.core.string_processor.base.StringProcessor)" href="../StringProcessor/#flexeval.core.string_processor.base.StringProcessor">StringProcessor</a> | <span title="list">list</span>[<a class="autorefs autorefs-internal" title="StringProcessor (flexeval.core.string_processor.base.StringProcessor)" href="../StringProcessor/#flexeval.core.string_processor.base.StringProcessor">StringProcessor</a>] | None</code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>StringProcessor or list of StringProcessor to apply to the references before comparison.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>category_key</code></b>
              (<code><span title="str">str</span> | None</code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>A key to create category-wise mean score.
The category key is expected to be in task inputs.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">flexeval</span><span class="w"> </span><span class="kn">import</span> <span class="n">BLEU</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bleu</span> <span class="o">=</span> <span class="n">BLEU</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lm_outputs</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;I am a student .&quot;</span><span class="p">,</span> <span class="s2">&quot;I am a teacher .&quot;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">references_list</span> <span class="o">=</span> <span class="p">[[</span><span class="s2">&quot;I am a student .&quot;</span><span class="p">,</span> <span class="s2">&quot;I am a learner .&quot;</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;I am a teacher .&quot;</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">bleu</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">lm_outputs</span><span class="p">,</span> <span class="n">references_list</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
<span class="go">MetricResult(</span>
<span class="go">    summary={</span>
<span class="go">        &#39;bleu_score&#39;: 1.0,</span>
<span class="go">        &#39;bleu_bp&#39;: 1.0,</span>
<span class="go">        &#39;bleu_signature&#39;: nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.1},</span>
<span class="go">        instance_details=[</span>
<span class="go">            {&#39;bleu_score&#39;: 1.0, &#39;bleu_bp&#39;: 1.0},</span>
<span class="go">            {&#39;bleu_score&#39;: 1.0, &#39;bleu_bp&#39;: 1.0}</span>
<span class="go">        ]</span>
<span class="go">    )</span>
</code></pre></div>







              <details class="quote">
                <summary>Source code in <code>flexeval/core/metric/bleu.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 13</span>
<span class="normal"> 14</span>
<span class="normal"> 15</span>
<span class="normal"> 16</span>
<span class="normal"> 17</span>
<span class="normal"> 18</span>
<span class="normal"> 19</span>
<span class="normal"> 20</span>
<span class="normal"> 21</span>
<span class="normal"> 22</span>
<span class="normal"> 23</span>
<span class="normal"> 24</span>
<span class="normal"> 25</span>
<span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">BLEU</span><span class="p">(</span><span class="n">Metric</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;An implementation of [BLEU](https://aclanthology.org/P02-1040/).</span>
<span class="sd">    The calculation is based on the [sacrebleu](https://github.com/mjpost/sacrebleu) library.</span>

<span class="sd">    Args:</span>
<span class="sd">        tokenize_option: Tokenization option for sacrebleu.</span>
<span class="sd">            If `None`, sacrebleu will use the default tokenization.</span>
<span class="sd">        lm_output_processor:</span>
<span class="sd">            StringProcessor or a list of StringProcessor to be applied to the model outputs before comparison.</span>
<span class="sd">        reference_processor: StringProcessor or list of StringProcessor to apply to the references before comparison.</span>
<span class="sd">        category_key: A key to create category-wise mean score.</span>
<span class="sd">            The category key is expected to be in task inputs.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from flexeval import BLEU</span>
<span class="sd">        &gt;&gt;&gt; bleu = BLEU()</span>
<span class="sd">        &gt;&gt;&gt; lm_outputs = [&quot;I am a student .&quot;, &quot;I am a teacher .&quot;]</span>
<span class="sd">        &gt;&gt;&gt; references_list = [[&quot;I am a student .&quot;, &quot;I am a learner .&quot;], [&quot;I am a teacher .&quot;]]</span>
<span class="sd">        &gt;&gt;&gt; result = bleu.evaluate(lm_outputs, references_list)</span>
<span class="sd">        &gt;&gt;&gt; print(result)</span>
<span class="sd">        MetricResult(</span>
<span class="sd">            summary={</span>
<span class="sd">                &#39;bleu_score&#39;: 1.0,</span>
<span class="sd">                &#39;bleu_bp&#39;: 1.0,</span>
<span class="sd">                &#39;bleu_signature&#39;: nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.4.1},</span>
<span class="sd">                instance_details=[</span>
<span class="sd">                    {&#39;bleu_score&#39;: 1.0, &#39;bleu_bp&#39;: 1.0},</span>
<span class="sd">                    {&#39;bleu_score&#39;: 1.0, &#39;bleu_bp&#39;: 1.0}</span>
<span class="sd">                ]</span>
<span class="sd">            )</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">tokenize_option</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">lm_output_processor</span><span class="p">:</span> <span class="n">StringProcessor</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="n">StringProcessor</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">reference_processor</span><span class="p">:</span> <span class="n">StringProcessor</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="n">StringProcessor</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">category_key</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_corpus_bleu</span> <span class="o">=</span> <span class="n">sacrebleu</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">BLEU</span><span class="p">(</span><span class="n">tokenize</span><span class="o">=</span><span class="n">tokenize_option</span><span class="p">)</span>
        <span class="c1"># For sentence BLEU, we need to set `effective_order=True` as recommended by sacrebleu.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_sentence_bleu</span> <span class="o">=</span> <span class="n">sacrebleu</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">BLEU</span><span class="p">(</span><span class="n">tokenize</span><span class="o">=</span><span class="n">tokenize_option</span><span class="p">,</span> <span class="n">effective_order</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">lm_output_processor</span><span class="p">,</span> <span class="n">StringProcessor</span><span class="p">):</span>
            <span class="n">lm_output_processor</span> <span class="o">=</span> <span class="p">[</span><span class="n">lm_output_processor</span><span class="p">]</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">reference_processor</span><span class="p">,</span> <span class="n">StringProcessor</span><span class="p">):</span>
            <span class="n">reference_processor</span> <span class="o">=</span> <span class="p">[</span><span class="n">reference_processor</span><span class="p">]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">lm_output_processors</span> <span class="o">=</span> <span class="n">lm_output_processor</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reference_processors</span> <span class="o">=</span> <span class="n">reference_processor</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">category_key</span> <span class="o">=</span> <span class="n">category_key</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">lm_outputs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">references_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
        <span class="n">task_inputs_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MetricResult</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">lm_outputs</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">references_list</span><span class="p">):</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;lm_outputs and references_list must have the same length, &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;but got </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">lm_outputs</span><span class="p">)</span><span class="si">}</span><span class="s2"> and </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">references_list</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">lm_output_processors</span><span class="p">:</span>
            <span class="n">lm_outputs</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">functools</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">norm</span><span class="p">:</span> <span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">lm_output_processors</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span> <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">lm_outputs</span>
            <span class="p">]</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">reference_processors</span><span class="p">:</span>
            <span class="n">references_list</span> <span class="o">=</span> <span class="p">[</span>
                <span class="p">[</span><span class="n">functools</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">norm</span><span class="p">:</span> <span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">reference_processors</span><span class="p">,</span> <span class="n">ref</span><span class="p">)</span> <span class="k">for</span> <span class="n">ref</span> <span class="ow">in</span> <span class="n">references</span><span class="p">]</span>
                <span class="k">for</span> <span class="n">references</span> <span class="ow">in</span> <span class="n">references_list</span>
            <span class="p">]</span>

        <span class="c1"># we need restructure the references to match the format expected by sacrebleu</span>
        <span class="n">max_num_refs</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">refs</span><span class="p">)</span> <span class="k">for</span> <span class="n">refs</span> <span class="ow">in</span> <span class="n">references_list</span><span class="p">)</span>
        <span class="n">references_for_sacrebleu</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_num_refs</span><span class="p">):</span>
            <span class="n">set_of_references</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">refs_for_source</span> <span class="ow">in</span> <span class="n">references_list</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">refs_for_source</span><span class="p">):</span>
                    <span class="n">set_of_references</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">refs_for_source</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">set_of_references</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
            <span class="n">references_for_sacrebleu</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">set_of_references</span><span class="p">)</span>

        <span class="n">bleu</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_corpus_bleu</span><span class="o">.</span><span class="n">corpus_score</span><span class="p">([</span><span class="n">o</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="n">lm_outputs</span><span class="p">],</span> <span class="n">references_for_sacrebleu</span><span class="p">)</span>
        <span class="n">sentence_bleu_list</span> <span class="o">=</span> <span class="p">[</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_sentence_bleu</span><span class="o">.</span><span class="n">sentence_score</span><span class="p">(</span><span class="n">o</span><span class="o">.</span><span class="n">strip</span><span class="p">(),</span> <span class="n">refs</span><span class="p">)</span> <span class="k">for</span> <span class="n">o</span><span class="p">,</span> <span class="n">refs</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">lm_outputs</span><span class="p">,</span> <span class="n">references_list</span><span class="p">)</span>
        <span class="p">]</span>

        <span class="n">summary</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;bleu_score&quot;</span><span class="p">:</span> <span class="n">bleu</span><span class="o">.</span><span class="n">score</span> <span class="o">/</span> <span class="mi">100</span><span class="p">,</span>
            <span class="s2">&quot;bleu_bp&quot;</span><span class="p">:</span> <span class="n">bleu</span><span class="o">.</span><span class="n">bp</span><span class="p">,</span>
            <span class="s2">&quot;bleu_signature&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_corpus_bleu</span><span class="o">.</span><span class="n">get_signature</span><span class="p">(),</span>
        <span class="p">}</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">category_key</span><span class="p">:</span>
            <span class="n">categories</span> <span class="o">=</span> <span class="p">[</span><span class="n">task_input</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">category_key</span><span class="p">]</span> <span class="k">for</span> <span class="n">task_input</span> <span class="ow">in</span> <span class="n">task_inputs_list</span><span class="p">]</span>
            <span class="n">sentence_bleu_score_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">b</span><span class="o">.</span><span class="n">score</span> <span class="o">/</span> <span class="mi">100</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">sentence_bleu_list</span><span class="p">]</span>
            <span class="n">category_wise_scores</span> <span class="o">=</span> <span class="n">aggregate_category_wise_scores</span><span class="p">(</span><span class="n">sentence_bleu_score_list</span><span class="p">,</span> <span class="n">categories</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">category</span><span class="p">,</span> <span class="n">category_wise_score</span> <span class="ow">in</span> <span class="n">category_wise_scores</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="n">summary</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;sentence_bleu_score/</span><span class="si">{</span><span class="n">category</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">category_wise_score</span>

        <span class="k">return</span> <span class="n">MetricResult</span><span class="p">(</span>
            <span class="n">summary</span><span class="p">,</span>
            <span class="n">instance_details</span><span class="o">=</span><span class="p">[{</span><span class="s2">&quot;bleu_score&quot;</span><span class="p">:</span> <span class="n">b</span><span class="o">.</span><span class="n">score</span> <span class="o">/</span> <span class="mi">100</span><span class="p">,</span> <span class="s2">&quot;bleu_bp&quot;</span><span class="p">:</span> <span class="n">b</span><span class="o">.</span><span class="n">bp</span><span class="p">}</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">sentence_bleu_list</span><span class="p">],</span>
        <span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.bleu.BLEU.lm_output_processors" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">lm_output_processors</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.bleu.BLEU.lm_output_processors" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">lm_output_processors</span> <span class="o">=</span> <span class="n">lm_output_processor</span>
</code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.bleu.BLEU.reference_processors" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">reference_processors</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.bleu.BLEU.reference_processors" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">reference_processors</span> <span class="o">=</span> <span class="n">reference_processor</span>
</code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.bleu.BLEU.category_key" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">category_key</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.bleu.BLEU.category_key" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">category_key</span> <span class="o">=</span> <span class="n">category_key</span>
</code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>



<div class="doc doc-object doc-function">


<h3 id="flexeval.core.metric.bleu.BLEU.__init__" class="doc doc-heading">
            <span class="doc doc-object-name doc-function-name">__init__</span>


<a href="#flexeval.core.metric.bleu.BLEU.__init__" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="fm">__init__</span><span class="p">(</span>
    <span class="nf">tokenize_option</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">lm_output_processor</span><span class="p">:</span> <span class="n">StringProcessor</span>
    <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="n">StringProcessor</span><span class="p">]</span>
    <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">reference_processor</span><span class="p">:</span> <span class="n">StringProcessor</span>
    <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="n">StringProcessor</span><span class="p">]</span>
    <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">category_key</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>

    <div class="doc doc-contents ">


            <details class="quote">
              <summary>Source code in <code>flexeval/core/metric/bleu.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">tokenize_option</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">lm_output_processor</span><span class="p">:</span> <span class="n">StringProcessor</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="n">StringProcessor</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">reference_processor</span><span class="p">:</span> <span class="n">StringProcessor</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="n">StringProcessor</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">category_key</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_corpus_bleu</span> <span class="o">=</span> <span class="n">sacrebleu</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">BLEU</span><span class="p">(</span><span class="n">tokenize</span><span class="o">=</span><span class="n">tokenize_option</span><span class="p">)</span>
    <span class="c1"># For sentence BLEU, we need to set `effective_order=True` as recommended by sacrebleu.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_sentence_bleu</span> <span class="o">=</span> <span class="n">sacrebleu</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">BLEU</span><span class="p">(</span><span class="n">tokenize</span><span class="o">=</span><span class="n">tokenize_option</span><span class="p">,</span> <span class="n">effective_order</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">lm_output_processor</span><span class="p">,</span> <span class="n">StringProcessor</span><span class="p">):</span>
        <span class="n">lm_output_processor</span> <span class="o">=</span> <span class="p">[</span><span class="n">lm_output_processor</span><span class="p">]</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">reference_processor</span><span class="p">,</span> <span class="n">StringProcessor</span><span class="p">):</span>
        <span class="n">reference_processor</span> <span class="o">=</span> <span class="p">[</span><span class="n">reference_processor</span><span class="p">]</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">lm_output_processors</span> <span class="o">=</span> <span class="n">lm_output_processor</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">reference_processors</span> <span class="o">=</span> <span class="n">reference_processor</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">category_key</span> <span class="o">=</span> <span class="n">category_key</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="flexeval.core.metric.bleu.BLEU.evaluate" class="doc doc-heading">
            <span class="doc doc-object-name doc-function-name">evaluate</span>


<a href="#flexeval.core.metric.bleu.BLEU.evaluate" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="nf">evaluate</span><span class="p">(</span>
    <span class="n">lm_outputs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">references_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
    <span class="n">task_inputs_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MetricResult</span>
</code></pre></div>

    <div class="doc doc-contents ">


            <details class="quote">
              <summary>Source code in <code>flexeval/core/metric/bleu.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">lm_outputs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">references_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
    <span class="n">task_inputs_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MetricResult</span><span class="p">:</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">lm_outputs</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">references_list</span><span class="p">):</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;lm_outputs and references_list must have the same length, &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;but got </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">lm_outputs</span><span class="p">)</span><span class="si">}</span><span class="s2"> and </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">references_list</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span>
        <span class="p">)</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">lm_output_processors</span><span class="p">:</span>
        <span class="n">lm_outputs</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">functools</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">norm</span><span class="p">:</span> <span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">lm_output_processors</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span> <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">lm_outputs</span>
        <span class="p">]</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">reference_processors</span><span class="p">:</span>
        <span class="n">references_list</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">[</span><span class="n">functools</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">norm</span><span class="p">:</span> <span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">reference_processors</span><span class="p">,</span> <span class="n">ref</span><span class="p">)</span> <span class="k">for</span> <span class="n">ref</span> <span class="ow">in</span> <span class="n">references</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">references</span> <span class="ow">in</span> <span class="n">references_list</span>
        <span class="p">]</span>

    <span class="c1"># we need restructure the references to match the format expected by sacrebleu</span>
    <span class="n">max_num_refs</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">refs</span><span class="p">)</span> <span class="k">for</span> <span class="n">refs</span> <span class="ow">in</span> <span class="n">references_list</span><span class="p">)</span>
    <span class="n">references_for_sacrebleu</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_num_refs</span><span class="p">):</span>
        <span class="n">set_of_references</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">refs_for_source</span> <span class="ow">in</span> <span class="n">references_list</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">refs_for_source</span><span class="p">):</span>
                <span class="n">set_of_references</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">refs_for_source</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">set_of_references</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="n">references_for_sacrebleu</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">set_of_references</span><span class="p">)</span>

    <span class="n">bleu</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_corpus_bleu</span><span class="o">.</span><span class="n">corpus_score</span><span class="p">([</span><span class="n">o</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="n">lm_outputs</span><span class="p">],</span> <span class="n">references_for_sacrebleu</span><span class="p">)</span>
    <span class="n">sentence_bleu_list</span> <span class="o">=</span> <span class="p">[</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_sentence_bleu</span><span class="o">.</span><span class="n">sentence_score</span><span class="p">(</span><span class="n">o</span><span class="o">.</span><span class="n">strip</span><span class="p">(),</span> <span class="n">refs</span><span class="p">)</span> <span class="k">for</span> <span class="n">o</span><span class="p">,</span> <span class="n">refs</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">lm_outputs</span><span class="p">,</span> <span class="n">references_list</span><span class="p">)</span>
    <span class="p">]</span>

    <span class="n">summary</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;bleu_score&quot;</span><span class="p">:</span> <span class="n">bleu</span><span class="o">.</span><span class="n">score</span> <span class="o">/</span> <span class="mi">100</span><span class="p">,</span>
        <span class="s2">&quot;bleu_bp&quot;</span><span class="p">:</span> <span class="n">bleu</span><span class="o">.</span><span class="n">bp</span><span class="p">,</span>
        <span class="s2">&quot;bleu_signature&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_corpus_bleu</span><span class="o">.</span><span class="n">get_signature</span><span class="p">(),</span>
    <span class="p">}</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">category_key</span><span class="p">:</span>
        <span class="n">categories</span> <span class="o">=</span> <span class="p">[</span><span class="n">task_input</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">category_key</span><span class="p">]</span> <span class="k">for</span> <span class="n">task_input</span> <span class="ow">in</span> <span class="n">task_inputs_list</span><span class="p">]</span>
        <span class="n">sentence_bleu_score_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">b</span><span class="o">.</span><span class="n">score</span> <span class="o">/</span> <span class="mi">100</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">sentence_bleu_list</span><span class="p">]</span>
        <span class="n">category_wise_scores</span> <span class="o">=</span> <span class="n">aggregate_category_wise_scores</span><span class="p">(</span><span class="n">sentence_bleu_score_list</span><span class="p">,</span> <span class="n">categories</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">category</span><span class="p">,</span> <span class="n">category_wise_score</span> <span class="ow">in</span> <span class="n">category_wise_scores</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">summary</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;sentence_bleu_score/</span><span class="si">{</span><span class="n">category</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">category_wise_score</span>

    <span class="k">return</span> <span class="n">MetricResult</span><span class="p">(</span>
        <span class="n">summary</span><span class="p">,</span>
        <span class="n">instance_details</span><span class="o">=</span><span class="p">[{</span><span class="s2">&quot;bleu_score&quot;</span><span class="p">:</span> <span class="n">b</span><span class="o">.</span><span class="n">score</span> <span class="o">/</span> <span class="mi">100</span><span class="p">,</span> <span class="s2">&quot;bleu_bp&quot;</span><span class="p">:</span> <span class="n">b</span><span class="o">.</span><span class="n">bp</span><span class="p">}</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">sentence_bleu_list</span><span class="p">],</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="flexeval.core.metric.char_f1.CharF1" class="doc doc-heading">
            <span class="doc doc-object-name doc-class-name">CharF1</span>


<a href="#flexeval.core.metric.char_f1.CharF1" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents first">


        <p>A metric that calculates how many characters in the output string are included
in the characters of the expected output.
If there are multiple expected outputs, the highest score is adopted.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>lm_output_processor</code></b>
              (<code><a class="autorefs autorefs-internal" title="StringProcessor (flexeval.core.string_processor.StringProcessor)" href="../StringProcessor/#flexeval.core.string_processor.base.StringProcessor">StringProcessor</a> | <span title="list">list</span>[<a class="autorefs autorefs-internal" title="StringProcessor (flexeval.core.string_processor.StringProcessor)" href="../StringProcessor/#flexeval.core.string_processor.base.StringProcessor">StringProcessor</a>] | None</code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>StringProcessor or list of Normalizers to apply to the model outputs before comparison.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>reference_processor</code></b>
              (<code><a class="autorefs autorefs-internal" title="StringProcessor (flexeval.core.string_processor.StringProcessor)" href="../StringProcessor/#flexeval.core.string_processor.base.StringProcessor">StringProcessor</a> | <span title="list">list</span>[<a class="autorefs autorefs-internal" title="StringProcessor (flexeval.core.string_processor.StringProcessor)" href="../StringProcessor/#flexeval.core.string_processor.base.StringProcessor">StringProcessor</a>] | None</code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>StringProcessor or list of Normalizers to apply to the references before comparison.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>category_key</code></b>
              (<code><span title="str">str</span> | None</code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>A key to create category-wise mean score.
The category key is expected to be in task inputs.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">flexeval</span><span class="w"> </span><span class="kn">import</span> <span class="n">CharF1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">char_f1</span> <span class="o">=</span> <span class="n">CharF1</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lm_outputs</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;abcd&quot;</span><span class="p">,</span> <span class="s2">&quot;efgh&quot;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">references_list</span> <span class="o">=</span> <span class="p">[[</span><span class="s2">&quot;abcd&quot;</span><span class="p">,</span> <span class="s2">&quot;ABCD&quot;</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;efGH&quot;</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">char_f1</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">lm_outputs</span><span class="p">,</span> <span class="n">references_list</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
<span class="go">MetricResult(summary={&#39;char_f1&#39;: 0.75}, instance_details=[{&#39;char_f1&#39;: 1.0}, {&#39;char_f1&#39;: 0.5}])</span>
</code></pre></div>







              <details class="quote">
                <summary>Source code in <code>flexeval/core/metric/char_f1.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">CharF1</span><span class="p">(</span><span class="n">Metric</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A metric that calculates how many characters in the output string are included</span>
<span class="sd">    in the characters of the expected output.</span>
<span class="sd">    If there are multiple expected outputs, the highest score is adopted.</span>

<span class="sd">    Args:</span>
<span class="sd">        lm_output_processor: StringProcessor or list of Normalizers to apply to the model outputs before comparison.</span>
<span class="sd">        reference_processor: StringProcessor or list of Normalizers to apply to the references before comparison.</span>
<span class="sd">        category_key: A key to create category-wise mean score.</span>
<span class="sd">            The category key is expected to be in task inputs.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from flexeval import CharF1</span>
<span class="sd">        &gt;&gt;&gt; char_f1 = CharF1()</span>
<span class="sd">        &gt;&gt;&gt; lm_outputs = [&quot;abcd&quot;, &quot;efgh&quot;]</span>
<span class="sd">        &gt;&gt;&gt; references_list = [[&quot;abcd&quot;, &quot;ABCD&quot;], [&quot;efGH&quot;]]</span>
<span class="sd">        &gt;&gt;&gt; result = char_f1.evaluate(lm_outputs, references_list)</span>
<span class="sd">        &gt;&gt;&gt; print(result)</span>
<span class="sd">        MetricResult(summary={&#39;char_f1&#39;: 0.75}, instance_details=[{&#39;char_f1&#39;: 1.0}, {&#39;char_f1&#39;: 0.5}])</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">lm_output_processor</span><span class="p">:</span> <span class="n">StringProcessor</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="n">StringProcessor</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">reference_processor</span><span class="p">:</span> <span class="n">StringProcessor</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="n">StringProcessor</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">category_key</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">lm_output_processor</span><span class="p">,</span> <span class="n">StringProcessor</span><span class="p">):</span>
            <span class="n">lm_output_processor</span> <span class="o">=</span> <span class="p">[</span><span class="n">lm_output_processor</span><span class="p">]</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">reference_processor</span><span class="p">,</span> <span class="n">StringProcessor</span><span class="p">):</span>
            <span class="n">reference_processor</span> <span class="o">=</span> <span class="p">[</span><span class="n">reference_processor</span><span class="p">]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">lm_output_processors</span> <span class="o">=</span> <span class="n">lm_output_processor</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reference_processors</span> <span class="o">=</span> <span class="n">reference_processor</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">category_key</span> <span class="o">=</span> <span class="n">category_key</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">lm_outputs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">references_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
        <span class="n">task_inputs_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MetricResult</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">lm_output_processors</span><span class="p">:</span>
            <span class="n">lm_outputs</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">functools</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">norm</span><span class="p">:</span> <span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">lm_output_processors</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span> <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">lm_outputs</span>
            <span class="p">]</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">reference_processors</span><span class="p">:</span>
            <span class="n">references_list</span> <span class="o">=</span> <span class="p">[</span>
                <span class="p">[</span><span class="n">functools</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">norm</span><span class="p">:</span> <span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">reference_processors</span><span class="p">,</span> <span class="n">ref</span><span class="p">)</span> <span class="k">for</span> <span class="n">ref</span> <span class="ow">in</span> <span class="n">references</span><span class="p">]</span>
                <span class="k">for</span> <span class="n">references</span> <span class="ow">in</span> <span class="n">references_list</span>
            <span class="p">]</span>

        <span class="n">char_f1_scores</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">lm_output</span><span class="p">,</span> <span class="n">expected_output</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">lm_outputs</span><span class="p">,</span> <span class="n">references_list</span><span class="p">):</span>
            <span class="n">score</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">fuzz</span><span class="o">.</span><span class="n">ratio</span><span class="p">(</span><span class="n">lm_output</span><span class="p">,</span> <span class="n">o</span><span class="p">)</span> <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="n">expected_output</span><span class="p">)</span> <span class="o">/</span> <span class="mi">100</span>
            <span class="n">char_f1_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>

        <span class="n">summary</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;char_f1&quot;</span><span class="p">:</span> <span class="nb">sum</span><span class="p">(</span><span class="n">char_f1_scores</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">char_f1_scores</span><span class="p">)}</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">category_key</span><span class="p">:</span>
            <span class="n">categories</span> <span class="o">=</span> <span class="p">[</span><span class="n">task_input</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">category_key</span><span class="p">]</span> <span class="k">for</span> <span class="n">task_input</span> <span class="ow">in</span> <span class="n">task_inputs_list</span><span class="p">]</span>
            <span class="n">category_wise_scores</span> <span class="o">=</span> <span class="n">aggregate_category_wise_scores</span><span class="p">(</span><span class="n">char_f1_scores</span><span class="p">,</span> <span class="n">categories</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">category</span><span class="p">,</span> <span class="n">category_wise_score</span> <span class="ow">in</span> <span class="n">category_wise_scores</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="n">summary</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;char_f1/</span><span class="si">{</span><span class="n">category</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">category_wise_score</span>

        <span class="k">return</span> <span class="n">MetricResult</span><span class="p">(</span>
            <span class="n">summary</span><span class="p">,</span>
            <span class="n">instance_details</span><span class="o">=</span><span class="p">[{</span><span class="s2">&quot;char_f1&quot;</span><span class="p">:</span> <span class="n">s</span><span class="p">}</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">char_f1_scores</span><span class="p">],</span>
        <span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.char_f1.CharF1.lm_output_processors" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">lm_output_processors</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.char_f1.CharF1.lm_output_processors" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">lm_output_processors</span> <span class="o">=</span> <span class="n">lm_output_processor</span>
</code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.char_f1.CharF1.reference_processors" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">reference_processors</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.char_f1.CharF1.reference_processors" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">reference_processors</span> <span class="o">=</span> <span class="n">reference_processor</span>
</code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.char_f1.CharF1.category_key" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">category_key</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.char_f1.CharF1.category_key" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">category_key</span> <span class="o">=</span> <span class="n">category_key</span>
</code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>



<div class="doc doc-object doc-function">


<h3 id="flexeval.core.metric.char_f1.CharF1.__init__" class="doc doc-heading">
            <span class="doc doc-object-name doc-function-name">__init__</span>


<a href="#flexeval.core.metric.char_f1.CharF1.__init__" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="fm">__init__</span><span class="p">(</span>
    <span class="nf">lm_output_processor</span><span class="p">:</span> <span class="n">StringProcessor</span>
    <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="n">StringProcessor</span><span class="p">]</span>
    <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">reference_processor</span><span class="p">:</span> <span class="n">StringProcessor</span>
    <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="n">StringProcessor</span><span class="p">]</span>
    <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">category_key</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>

    <div class="doc doc-contents ">


            <details class="quote">
              <summary>Source code in <code>flexeval/core/metric/char_f1.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">lm_output_processor</span><span class="p">:</span> <span class="n">StringProcessor</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="n">StringProcessor</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">reference_processor</span><span class="p">:</span> <span class="n">StringProcessor</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="n">StringProcessor</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">category_key</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">lm_output_processor</span><span class="p">,</span> <span class="n">StringProcessor</span><span class="p">):</span>
        <span class="n">lm_output_processor</span> <span class="o">=</span> <span class="p">[</span><span class="n">lm_output_processor</span><span class="p">]</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">reference_processor</span><span class="p">,</span> <span class="n">StringProcessor</span><span class="p">):</span>
        <span class="n">reference_processor</span> <span class="o">=</span> <span class="p">[</span><span class="n">reference_processor</span><span class="p">]</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">lm_output_processors</span> <span class="o">=</span> <span class="n">lm_output_processor</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">reference_processors</span> <span class="o">=</span> <span class="n">reference_processor</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">category_key</span> <span class="o">=</span> <span class="n">category_key</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="flexeval.core.metric.char_f1.CharF1.evaluate" class="doc doc-heading">
            <span class="doc doc-object-name doc-function-name">evaluate</span>


<a href="#flexeval.core.metric.char_f1.CharF1.evaluate" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="nf">evaluate</span><span class="p">(</span>
    <span class="n">lm_outputs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">references_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
    <span class="n">task_inputs_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MetricResult</span>
</code></pre></div>

    <div class="doc doc-contents ">


            <details class="quote">
              <summary>Source code in <code>flexeval/core/metric/char_f1.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">lm_outputs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">references_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
    <span class="n">task_inputs_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MetricResult</span><span class="p">:</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">lm_output_processors</span><span class="p">:</span>
        <span class="n">lm_outputs</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">functools</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">norm</span><span class="p">:</span> <span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">lm_output_processors</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span> <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">lm_outputs</span>
        <span class="p">]</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">reference_processors</span><span class="p">:</span>
        <span class="n">references_list</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">[</span><span class="n">functools</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">norm</span><span class="p">:</span> <span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">reference_processors</span><span class="p">,</span> <span class="n">ref</span><span class="p">)</span> <span class="k">for</span> <span class="n">ref</span> <span class="ow">in</span> <span class="n">references</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">references</span> <span class="ow">in</span> <span class="n">references_list</span>
        <span class="p">]</span>

    <span class="n">char_f1_scores</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">lm_output</span><span class="p">,</span> <span class="n">expected_output</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">lm_outputs</span><span class="p">,</span> <span class="n">references_list</span><span class="p">):</span>
        <span class="n">score</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">fuzz</span><span class="o">.</span><span class="n">ratio</span><span class="p">(</span><span class="n">lm_output</span><span class="p">,</span> <span class="n">o</span><span class="p">)</span> <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="n">expected_output</span><span class="p">)</span> <span class="o">/</span> <span class="mi">100</span>
        <span class="n">char_f1_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>

    <span class="n">summary</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;char_f1&quot;</span><span class="p">:</span> <span class="nb">sum</span><span class="p">(</span><span class="n">char_f1_scores</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">char_f1_scores</span><span class="p">)}</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">category_key</span><span class="p">:</span>
        <span class="n">categories</span> <span class="o">=</span> <span class="p">[</span><span class="n">task_input</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">category_key</span><span class="p">]</span> <span class="k">for</span> <span class="n">task_input</span> <span class="ow">in</span> <span class="n">task_inputs_list</span><span class="p">]</span>
        <span class="n">category_wise_scores</span> <span class="o">=</span> <span class="n">aggregate_category_wise_scores</span><span class="p">(</span><span class="n">char_f1_scores</span><span class="p">,</span> <span class="n">categories</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">category</span><span class="p">,</span> <span class="n">category_wise_score</span> <span class="ow">in</span> <span class="n">category_wise_scores</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">summary</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;char_f1/</span><span class="si">{</span><span class="n">category</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">category_wise_score</span>

    <span class="k">return</span> <span class="n">MetricResult</span><span class="p">(</span>
        <span class="n">summary</span><span class="p">,</span>
        <span class="n">instance_details</span><span class="o">=</span><span class="p">[{</span><span class="s2">&quot;char_f1&quot;</span><span class="p">:</span> <span class="n">s</span><span class="p">}</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">char_f1_scores</span><span class="p">],</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="flexeval.core.metric.code_eval.CodeEval" class="doc doc-heading">
            <span class="doc doc-object-name doc-class-name">CodeEval</span>


<a href="#flexeval.core.metric.code_eval.CodeEval" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents first">


        <p>A metric that evaluates generated code with test cases.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>code_template</code></b>
              (<code><span title="str">str</span> | None</code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>A Jinja2 template string to make the generated code.
The template can contain variables from task inputs.
If <code>None</code>, the code prompt will be the generated text itself.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>lm_output_processor</code></b>
              (<code><a class="autorefs autorefs-internal" title="StringProcessor (flexeval.core.string_processor.StringProcessor)" href="../StringProcessor/#flexeval.core.string_processor.base.StringProcessor">StringProcessor</a> | <span title="list">list</span>[<a class="autorefs autorefs-internal" title="StringProcessor (flexeval.core.string_processor.StringProcessor)" href="../StringProcessor/#flexeval.core.string_processor.base.StringProcessor">StringProcessor</a>] | None</code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>String processors applied to model outputs before evaluation.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>evaluate_module</code></b>
              (<code><span title="str">str</span></code>, default:
                  <code>&#39;code_eval&#39;</code>
)
          –
          <div class="doc-md-description">
            <p>An evaluate module to use.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">flexeval</span><span class="w"> </span><span class="kn">import</span> <span class="n">CodeEval</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">code_eval</span> <span class="o">=</span> <span class="n">CodeEval</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lm_outputs</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;def add(a, b):</span><span class="se">\n</span><span class="s2">    return a + b&quot;</span><span class="p">,</span> <span class="s2">&quot;def is_equal(a, b):</span><span class="se">\n</span><span class="s2">    return a = b&quot;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">references_list</span> <span class="o">=</span> <span class="p">[[</span><span class="s2">&quot;assert add(1, 2) == 3&quot;</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;assert is_equal(1, 2) == False&quot;</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">code_eval</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">lm_outputs</span><span class="p">,</span> <span class="n">references_list</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
<span class="go">MetricResult(</span>
<span class="go">    summary={&#39;pass@1&#39;: 0.5},</span>
<span class="go">    instance_details=[</span>
<span class="go">        {&#39;passed&#39;: True, &#39;result&#39;: &#39;passed&#39;},</span>
<span class="go">        {&#39;passed&#39;: False, &#39;result&#39;: &#39;failed: invalid syntax (&lt;string&gt;, line 2)&#39;}</span>
<span class="go">    ]</span>
<span class="go">)</span>
</code></pre></div>







              <details class="quote">
                <summary>Source code in <code>flexeval/core/metric/code_eval.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 17</span>
<span class="normal"> 18</span>
<span class="normal"> 19</span>
<span class="normal"> 20</span>
<span class="normal"> 21</span>
<span class="normal"> 22</span>
<span class="normal"> 23</span>
<span class="normal"> 24</span>
<span class="normal"> 25</span>
<span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">CodeEval</span><span class="p">(</span><span class="n">Metric</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A metric that evaluates generated code with test cases.</span>

<span class="sd">    Args:</span>
<span class="sd">        code_template: A Jinja2 template string to make the generated code.</span>
<span class="sd">            The template can contain variables from task inputs.</span>
<span class="sd">            If `None`, the code prompt will be the generated text itself.</span>
<span class="sd">        lm_output_processor: String processors applied to model outputs before evaluation.</span>
<span class="sd">        evaluate_module: An evaluate module to use.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from flexeval import CodeEval</span>
<span class="sd">        &gt;&gt;&gt; code_eval = CodeEval()</span>
<span class="sd">        &gt;&gt;&gt; lm_outputs = [&quot;def add(a, b):\\n    return a + b&quot;, &quot;def is_equal(a, b):\\n    return a = b&quot;]</span>
<span class="sd">        &gt;&gt;&gt; references_list = [[&quot;assert add(1, 2) == 3&quot;], [&quot;assert is_equal(1, 2) == False&quot;]]</span>
<span class="sd">        &gt;&gt;&gt; result = code_eval.evaluate(lm_outputs, references_list)</span>
<span class="sd">        &gt;&gt;&gt; print(result)</span>
<span class="sd">        MetricResult(</span>
<span class="sd">            summary={&#39;pass@1&#39;: 0.5},</span>
<span class="sd">            instance_details=[</span>
<span class="sd">                {&#39;passed&#39;: True, &#39;result&#39;: &#39;passed&#39;},</span>
<span class="sd">                {&#39;passed&#39;: False, &#39;result&#39;: &#39;failed: invalid syntax (&lt;string&gt;, line 2)&#39;}</span>
<span class="sd">            ]</span>
<span class="sd">        )</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">code_template</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">lm_output_processor</span><span class="p">:</span> <span class="n">StringProcessor</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="n">StringProcessor</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">evaluate_module</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;code_eval&quot;</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">code_template</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">code_template</span> <span class="o">=</span> <span class="s2">&quot;{{ lm_output }}&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">code_template</span> <span class="o">=</span> <span class="n">JINJA2_ENV</span><span class="o">.</span><span class="n">from_string</span><span class="p">(</span><span class="n">code_template</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">code_eval</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">evaluate_module</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">lm_output_processor</span><span class="p">,</span> <span class="n">StringProcessor</span><span class="p">):</span>
            <span class="n">lm_output_processor</span> <span class="o">=</span> <span class="p">[</span><span class="n">lm_output_processor</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lm_output_processors</span> <span class="o">=</span> <span class="n">lm_output_processor</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">lm_outputs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">references_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
        <span class="n">task_inputs_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MetricResult</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">task_inputs_list</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">task_inputs_list</span> <span class="o">=</span> <span class="p">[{}</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">lm_outputs</span><span class="p">]</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">lm_output_processors</span><span class="p">:</span>
            <span class="n">lm_outputs</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">functools</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">norm</span><span class="p">:</span> <span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">lm_output_processors</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span> <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">lm_outputs</span>
            <span class="p">]</span>

        <span class="n">generated_code_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">test_case_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="c1"># in code generation tasks, references_list contains the test cases</span>
        <span class="k">for</span> <span class="n">lm_output</span><span class="p">,</span> <span class="n">task_inputs</span><span class="p">,</span> <span class="n">test_cases</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
            <span class="n">lm_outputs</span><span class="p">,</span>
            <span class="n">task_inputs_list</span><span class="p">,</span>
            <span class="n">references_list</span><span class="p">,</span>
        <span class="p">):</span>
            <span class="n">generated_code</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">code_template</span><span class="o">.</span><span class="n">render</span><span class="p">(</span><span class="n">lm_output</span><span class="o">=</span><span class="n">lm_output</span><span class="p">,</span> <span class="o">**</span><span class="n">task_inputs</span><span class="p">)</span>
            <span class="n">generated_code_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">generated_code</span><span class="p">)</span>
            <span class="n">test_case_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">test_cases</span><span class="p">))</span>
        <span class="n">pass_at_k</span><span class="p">,</span> <span class="n">results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">code_eval</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span>
            <span class="n">references</span><span class="o">=</span><span class="n">test_case_list</span><span class="p">,</span>
            <span class="n">predictions</span><span class="o">=</span><span class="p">[[</span><span class="n">c</span><span class="p">]</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">generated_code_list</span><span class="p">],</span>
            <span class="n">k</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
        <span class="p">)</span>

        <span class="c1"># `results` contain the detailed results for each test case</span>
        <span class="c1"># e.g., {0: [(0, {&#39;task_id&#39;: 0, &#39;passed&#39;: False, &#39;result&#39;: &quot;failed&quot;, &#39;completion_id&#39;: 0})]}</span>
        <span class="n">results</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]]]</span>

        <span class="n">instance_details</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">lm_outputs</span><span class="p">)):</span>
            <span class="n">first_result</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># we only assume one candidate code per instance, so we take the first result</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">detail_result</span> <span class="o">=</span> <span class="n">first_result</span>  <span class="c1"># the first element is just the index so we ignore it</span>
            <span class="c1"># remove unnecessary fields to save space</span>
            <span class="n">detail_result</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;completion_id&quot;</span><span class="p">)</span>
            <span class="n">detail_result</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;task_id&quot;</span><span class="p">)</span>
            <span class="n">instance_details</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">detail_result</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">MetricResult</span><span class="p">(</span><span class="n">pass_at_k</span><span class="p">,</span> <span class="n">instance_details</span><span class="o">=</span><span class="n">instance_details</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.code_eval.CodeEval.code_template" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">code_template</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.code_eval.CodeEval.code_template" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">code_template</span> <span class="o">=</span> <span class="n">from_string</span><span class="p">(</span><span class="n">code_template</span><span class="p">)</span>
</code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.code_eval.CodeEval.code_eval" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">code_eval</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.code_eval.CodeEval.code_eval" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">code_eval</span> <span class="o">=</span> <span class="n">load</span><span class="p">(</span><span class="n">evaluate_module</span><span class="p">)</span>
</code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.code_eval.CodeEval.lm_output_processors" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">lm_output_processors</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.code_eval.CodeEval.lm_output_processors" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">lm_output_processors</span> <span class="o">=</span> <span class="n">lm_output_processor</span>
</code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>



<div class="doc doc-object doc-function">


<h3 id="flexeval.core.metric.code_eval.CodeEval.__init__" class="doc doc-heading">
            <span class="doc doc-object-name doc-function-name">__init__</span>


<a href="#flexeval.core.metric.code_eval.CodeEval.__init__" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="fm">__init__</span><span class="p">(</span>
    <span class="nf">code_template</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">lm_output_processor</span><span class="p">:</span> <span class="n">StringProcessor</span>
    <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="n">StringProcessor</span><span class="p">]</span>
    <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">evaluate_module</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;code_eval&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>

    <div class="doc doc-contents ">


            <details class="quote">
              <summary>Source code in <code>flexeval/core/metric/code_eval.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">code_template</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">lm_output_processor</span><span class="p">:</span> <span class="n">StringProcessor</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="n">StringProcessor</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">evaluate_module</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;code_eval&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">code_template</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">code_template</span> <span class="o">=</span> <span class="s2">&quot;{{ lm_output }}&quot;</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">code_template</span> <span class="o">=</span> <span class="n">JINJA2_ENV</span><span class="o">.</span><span class="n">from_string</span><span class="p">(</span><span class="n">code_template</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">code_eval</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">evaluate_module</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">lm_output_processor</span><span class="p">,</span> <span class="n">StringProcessor</span><span class="p">):</span>
        <span class="n">lm_output_processor</span> <span class="o">=</span> <span class="p">[</span><span class="n">lm_output_processor</span><span class="p">]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">lm_output_processors</span> <span class="o">=</span> <span class="n">lm_output_processor</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="flexeval.core.metric.code_eval.CodeEval.evaluate" class="doc doc-heading">
            <span class="doc doc-object-name doc-function-name">evaluate</span>


<a href="#flexeval.core.metric.code_eval.CodeEval.evaluate" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="nf">evaluate</span><span class="p">(</span>
    <span class="n">lm_outputs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">references_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
    <span class="n">task_inputs_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MetricResult</span>
</code></pre></div>

    <div class="doc doc-contents ">


            <details class="quote">
              <summary>Source code in <code>flexeval/core/metric/code_eval.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">lm_outputs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">references_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
    <span class="n">task_inputs_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MetricResult</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">task_inputs_list</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">task_inputs_list</span> <span class="o">=</span> <span class="p">[{}</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">lm_outputs</span><span class="p">]</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">lm_output_processors</span><span class="p">:</span>
        <span class="n">lm_outputs</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">functools</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">norm</span><span class="p">:</span> <span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">lm_output_processors</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span> <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">lm_outputs</span>
        <span class="p">]</span>

    <span class="n">generated_code_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">test_case_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="c1"># in code generation tasks, references_list contains the test cases</span>
    <span class="k">for</span> <span class="n">lm_output</span><span class="p">,</span> <span class="n">task_inputs</span><span class="p">,</span> <span class="n">test_cases</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
        <span class="n">lm_outputs</span><span class="p">,</span>
        <span class="n">task_inputs_list</span><span class="p">,</span>
        <span class="n">references_list</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="n">generated_code</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">code_template</span><span class="o">.</span><span class="n">render</span><span class="p">(</span><span class="n">lm_output</span><span class="o">=</span><span class="n">lm_output</span><span class="p">,</span> <span class="o">**</span><span class="n">task_inputs</span><span class="p">)</span>
        <span class="n">generated_code_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">generated_code</span><span class="p">)</span>
        <span class="n">test_case_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">test_cases</span><span class="p">))</span>
    <span class="n">pass_at_k</span><span class="p">,</span> <span class="n">results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">code_eval</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span>
        <span class="n">references</span><span class="o">=</span><span class="n">test_case_list</span><span class="p">,</span>
        <span class="n">predictions</span><span class="o">=</span><span class="p">[[</span><span class="n">c</span><span class="p">]</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">generated_code_list</span><span class="p">],</span>
        <span class="n">k</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
    <span class="p">)</span>

    <span class="c1"># `results` contain the detailed results for each test case</span>
    <span class="c1"># e.g., {0: [(0, {&#39;task_id&#39;: 0, &#39;passed&#39;: False, &#39;result&#39;: &quot;failed&quot;, &#39;completion_id&#39;: 0})]}</span>
    <span class="n">results</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]]]</span>

    <span class="n">instance_details</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">lm_outputs</span><span class="p">)):</span>
        <span class="n">first_result</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># we only assume one candidate code per instance, so we take the first result</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">detail_result</span> <span class="o">=</span> <span class="n">first_result</span>  <span class="c1"># the first element is just the index so we ignore it</span>
        <span class="c1"># remove unnecessary fields to save space</span>
        <span class="n">detail_result</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;completion_id&quot;</span><span class="p">)</span>
        <span class="n">detail_result</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;task_id&quot;</span><span class="p">)</span>
        <span class="n">instance_details</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">detail_result</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">MetricResult</span><span class="p">(</span><span class="n">pass_at_k</span><span class="p">,</span> <span class="n">instance_details</span><span class="o">=</span><span class="n">instance_details</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="flexeval.core.metric.common_prefix_length.CommonPrefixLength" class="doc doc-heading">
            <span class="doc doc-object-name doc-class-name">CommonPrefixLength</span>


<a href="#flexeval.core.metric.common_prefix_length.CommonPrefixLength" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents first">


        <p>A metric that calculates the length of the longest common prefix between the model output and the reference.</p>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">flexeval</span><span class="w"> </span><span class="kn">import</span> <span class="n">CommonPrefixLength</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">common_prefix_length</span> <span class="o">=</span> <span class="n">CommonPrefixLength</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lm_outputs</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;ABCDEFG&quot;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">references_list</span> <span class="o">=</span> <span class="p">[[</span><span class="s2">&quot;ABCdefg&quot;</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">common_prefix_length</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">lm_outputs</span><span class="p">,</span> <span class="n">references_list</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
<span class="go">MetricResult(</span>
<span class="go">    summary={&quot;average_common_prefix_length&quot;: 3.0, &quot;longest_common_prefix_length&quot;: 3},</span>
<span class="go">    instance_details=[{&quot;common_prefix_length&quot;: 3}],</span>
<span class="go">)</span>
</code></pre></div>







              <details class="quote">
                <summary>Source code in <code>flexeval/core/metric/common_prefix_length.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">CommonPrefixLength</span><span class="p">(</span><span class="n">Metric</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A metric that calculates the length of the longest common prefix between the model output and the reference.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from flexeval import CommonPrefixLength</span>
<span class="sd">        &gt;&gt;&gt; common_prefix_length = CommonPrefixLength()</span>
<span class="sd">        &gt;&gt;&gt; lm_outputs = [&quot;ABCDEFG&quot;]</span>
<span class="sd">        &gt;&gt;&gt; references_list = [[&quot;ABCdefg&quot;]]</span>
<span class="sd">        &gt;&gt;&gt; result = common_prefix_length.evaluate(lm_outputs, references_list)</span>
<span class="sd">        &gt;&gt;&gt; print(result)</span>
<span class="sd">        MetricResult(</span>
<span class="sd">            summary={&quot;average_common_prefix_length&quot;: 3.0, &quot;longest_common_prefix_length&quot;: 3},</span>
<span class="sd">            instance_details=[{&quot;common_prefix_length&quot;: 3}],</span>
<span class="sd">        )</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">lm_outputs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">references_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
        <span class="n">task_inputs_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MetricResult</span><span class="p">:</span>
        <span class="n">common_prefix_length_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">lm_output</span><span class="p">,</span> <span class="n">references</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">lm_outputs</span><span class="p">,</span> <span class="n">references_list</span><span class="p">):</span>
            <span class="n">common_prefix_length</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">get_longest_common_prefix</span><span class="p">(</span><span class="n">lm_output</span><span class="p">,</span> <span class="n">gt</span><span class="p">))</span> <span class="k">for</span> <span class="n">gt</span> <span class="ow">in</span> <span class="n">references</span><span class="p">)</span>
            <span class="n">common_prefix_length_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">common_prefix_length</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">MetricResult</span><span class="p">(</span>
            <span class="p">{</span>
                <span class="s2">&quot;average_common_prefix_length&quot;</span><span class="p">:</span> <span class="nb">sum</span><span class="p">(</span><span class="n">common_prefix_length_list</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">common_prefix_length_list</span><span class="p">),</span>
                <span class="s2">&quot;longest_common_prefix_length&quot;</span><span class="p">:</span> <span class="nb">max</span><span class="p">(</span><span class="n">common_prefix_length_list</span><span class="p">),</span>
            <span class="p">},</span>
            <span class="n">instance_details</span><span class="o">=</span><span class="p">[{</span><span class="s2">&quot;common_prefix_length&quot;</span><span class="p">:</span> <span class="n">s</span><span class="p">}</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">common_prefix_length_list</span><span class="p">],</span>
        <span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="flexeval.core.metric.common_prefix_length.CommonPrefixLength.evaluate" class="doc doc-heading">
            <span class="doc doc-object-name doc-function-name">evaluate</span>


<a href="#flexeval.core.metric.common_prefix_length.CommonPrefixLength.evaluate" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="nf">evaluate</span><span class="p">(</span>
    <span class="n">lm_outputs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">references_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
    <span class="n">task_inputs_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MetricResult</span>
</code></pre></div>

    <div class="doc doc-contents ">


            <details class="quote">
              <summary>Source code in <code>flexeval/core/metric/common_prefix_length.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">lm_outputs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">references_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
    <span class="n">task_inputs_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MetricResult</span><span class="p">:</span>
    <span class="n">common_prefix_length_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">lm_output</span><span class="p">,</span> <span class="n">references</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">lm_outputs</span><span class="p">,</span> <span class="n">references_list</span><span class="p">):</span>
        <span class="n">common_prefix_length</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">get_longest_common_prefix</span><span class="p">(</span><span class="n">lm_output</span><span class="p">,</span> <span class="n">gt</span><span class="p">))</span> <span class="k">for</span> <span class="n">gt</span> <span class="ow">in</span> <span class="n">references</span><span class="p">)</span>
        <span class="n">common_prefix_length_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">common_prefix_length</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">MetricResult</span><span class="p">(</span>
        <span class="p">{</span>
            <span class="s2">&quot;average_common_prefix_length&quot;</span><span class="p">:</span> <span class="nb">sum</span><span class="p">(</span><span class="n">common_prefix_length_list</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">common_prefix_length_list</span><span class="p">),</span>
            <span class="s2">&quot;longest_common_prefix_length&quot;</span><span class="p">:</span> <span class="nb">max</span><span class="p">(</span><span class="n">common_prefix_length_list</span><span class="p">),</span>
        <span class="p">},</span>
        <span class="n">instance_details</span><span class="o">=</span><span class="p">[{</span><span class="s2">&quot;common_prefix_length&quot;</span><span class="p">:</span> <span class="n">s</span><span class="p">}</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">common_prefix_length_list</span><span class="p">],</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="flexeval.core.metric.common_string_length.CommonStringLength" class="doc doc-heading">
            <span class="doc doc-object-name doc-class-name">CommonStringLength</span>


<a href="#flexeval.core.metric.common_string_length.CommonStringLength" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents first">


        <p>A metric that calculates the length of the longest common substring between the model output and the reference.</p>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">flexeval</span><span class="w"> </span><span class="kn">import</span> <span class="n">CommonStringLength</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">common_string_length</span> <span class="o">=</span> <span class="n">CommonStringLength</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lm_outputs</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;aBCDEFG&quot;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">references_list</span> <span class="o">=</span> <span class="p">[[</span><span class="s2">&quot;ABCDefg&quot;</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">common_string_length</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">lm_outputs</span><span class="p">,</span> <span class="n">references_list</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
<span class="go">MetricResult(</span>
<span class="go">    summary={&quot;average_common_string_length&quot;: 3.0, &quot;longest_common_string_length&quot;: 3},</span>
<span class="go">    instance_details=[{&quot;common_string_length&quot;: 3}],</span>
<span class="go">)</span>
</code></pre></div>







              <details class="quote">
                <summary>Source code in <code>flexeval/core/metric/common_string_length.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">CommonStringLength</span><span class="p">(</span><span class="n">Metric</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A metric that calculates the length of the longest common substring between the model output and the reference.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from flexeval import CommonStringLength</span>
<span class="sd">        &gt;&gt;&gt; common_string_length = CommonStringLength()</span>
<span class="sd">        &gt;&gt;&gt; lm_outputs = [&quot;aBCDEFG&quot;]</span>
<span class="sd">        &gt;&gt;&gt; references_list = [[&quot;ABCDefg&quot;]]</span>
<span class="sd">        &gt;&gt;&gt; result = common_string_length.evaluate(lm_outputs, references_list)</span>
<span class="sd">        &gt;&gt;&gt; print(result)</span>
<span class="sd">        MetricResult(</span>
<span class="sd">            summary={&quot;average_common_string_length&quot;: 3.0, &quot;longest_common_string_length&quot;: 3},</span>
<span class="sd">            instance_details=[{&quot;common_string_length&quot;: 3}],</span>
<span class="sd">        )</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">lm_outputs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">references_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
        <span class="n">task_inputs_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MetricResult</span><span class="p">:</span>
        <span class="n">common_string_length_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">lm_output</span><span class="p">,</span> <span class="n">references</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">lm_outputs</span><span class="p">,</span> <span class="n">references_list</span><span class="p">):</span>
            <span class="n">common_string_length</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">get_longest_common_substring</span><span class="p">(</span><span class="n">lm_output</span><span class="p">,</span> <span class="n">gt</span><span class="p">))</span> <span class="k">for</span> <span class="n">gt</span> <span class="ow">in</span> <span class="n">references</span><span class="p">)</span>
            <span class="n">common_string_length_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">common_string_length</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">MetricResult</span><span class="p">(</span>
            <span class="p">{</span>
                <span class="s2">&quot;average_common_string_length&quot;</span><span class="p">:</span> <span class="nb">sum</span><span class="p">(</span><span class="n">common_string_length_list</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">common_string_length_list</span><span class="p">),</span>
                <span class="s2">&quot;longest_common_string_length&quot;</span><span class="p">:</span> <span class="nb">max</span><span class="p">(</span><span class="n">common_string_length_list</span><span class="p">),</span>
            <span class="p">},</span>
            <span class="n">instance_details</span><span class="o">=</span><span class="p">[{</span><span class="s2">&quot;common_string_length&quot;</span><span class="p">:</span> <span class="n">s</span><span class="p">}</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">common_string_length_list</span><span class="p">],</span>
        <span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="flexeval.core.metric.common_string_length.CommonStringLength.evaluate" class="doc doc-heading">
            <span class="doc doc-object-name doc-function-name">evaluate</span>


<a href="#flexeval.core.metric.common_string_length.CommonStringLength.evaluate" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="nf">evaluate</span><span class="p">(</span>
    <span class="n">lm_outputs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">references_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
    <span class="n">task_inputs_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MetricResult</span>
</code></pre></div>

    <div class="doc doc-contents ">


            <details class="quote">
              <summary>Source code in <code>flexeval/core/metric/common_string_length.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">lm_outputs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">references_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
    <span class="n">task_inputs_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MetricResult</span><span class="p">:</span>
    <span class="n">common_string_length_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">lm_output</span><span class="p">,</span> <span class="n">references</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">lm_outputs</span><span class="p">,</span> <span class="n">references_list</span><span class="p">):</span>
        <span class="n">common_string_length</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">get_longest_common_substring</span><span class="p">(</span><span class="n">lm_output</span><span class="p">,</span> <span class="n">gt</span><span class="p">))</span> <span class="k">for</span> <span class="n">gt</span> <span class="ow">in</span> <span class="n">references</span><span class="p">)</span>
        <span class="n">common_string_length_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">common_string_length</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">MetricResult</span><span class="p">(</span>
        <span class="p">{</span>
            <span class="s2">&quot;average_common_string_length&quot;</span><span class="p">:</span> <span class="nb">sum</span><span class="p">(</span><span class="n">common_string_length_list</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">common_string_length_list</span><span class="p">),</span>
            <span class="s2">&quot;longest_common_string_length&quot;</span><span class="p">:</span> <span class="nb">max</span><span class="p">(</span><span class="n">common_string_length_list</span><span class="p">),</span>
        <span class="p">},</span>
        <span class="n">instance_details</span><span class="o">=</span><span class="p">[{</span><span class="s2">&quot;common_string_length&quot;</span><span class="p">:</span> <span class="n">s</span><span class="p">}</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">common_string_length_list</span><span class="p">],</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="flexeval.core.metric.correlation.Correlation" class="doc doc-heading">
            <span class="doc doc-object-name doc-class-name">Correlation</span>


<a href="#flexeval.core.metric.correlation.Correlation" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents first">


        <p>Correlation metric to compute Pearson, Spearman, or Kendall correlation coefficients.
The lm_outputs and references should be numeric values, optionally preprocessed by StringProcessor.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>method</code></b>
              (<code><span title="typing.Literal">Literal</span>[&#39;pearson&#39;, &#39;spearman&#39;, &#39;kendall&#39;]</code>, default:
                  <code>&#39;pearson&#39;</code>
)
          –
          <div class="doc-md-description">
            <p>The correlation method to use ('pearson', 'spearman', 'kendall').</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>lm_output_processor</code></b>
              (<code><a class="autorefs autorefs-internal" title="StringProcessor (flexeval.core.string_processor.StringProcessor)" href="../StringProcessor/#flexeval.core.string_processor.base.StringProcessor">StringProcessor</a> | <span title="list">list</span>[<a class="autorefs autorefs-internal" title="StringProcessor (flexeval.core.string_processor.StringProcessor)" href="../StringProcessor/#flexeval.core.string_processor.base.StringProcessor">StringProcessor</a>] | None</code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>StringProcessor or a list of StringProcessor to be applied to the model outputs before
computing the correlation. If a list is provided, the processors will be applied in order.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>reference_processor</code></b>
              (<code><a class="autorefs autorefs-internal" title="StringProcessor (flexeval.core.string_processor.StringProcessor)" href="../StringProcessor/#flexeval.core.string_processor.base.StringProcessor">StringProcessor</a> | <span title="list">list</span>[<a class="autorefs autorefs-internal" title="StringProcessor (flexeval.core.string_processor.StringProcessor)" href="../StringProcessor/#flexeval.core.string_processor.base.StringProcessor">StringProcessor</a>] | None</code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>StringProcessor or a list of StringProcessor to be applied to the references before
computing the correlation. If a list is provided, the processors will be applied in order.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">flexeval</span><span class="w"> </span><span class="kn">import</span> <span class="n">Correlation</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">correlation</span> <span class="o">=</span> <span class="n">Correlation</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;pearson&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lm_outputs</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;1&quot;</span><span class="p">,</span> <span class="s2">&quot;2&quot;</span><span class="p">,</span> <span class="s2">&quot;3&quot;</span><span class="p">,</span> <span class="s2">&quot;4&quot;</span><span class="p">,</span> <span class="s2">&quot;5&quot;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">references</span> <span class="o">=</span> <span class="p">[[</span><span class="s2">&quot;5&quot;</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;4&quot;</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;3&quot;</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;2&quot;</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;1&quot;</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">correlation</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">lm_outputs</span><span class="p">,</span> <span class="n">references</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
<span class="go">MetricResult(</span>
<span class="go">    summary={&quot;pearson_correlation&quot;: -1.0, &quot;pearson_pvalue&quot;: 0.0},</span>
<span class="go">    instance_details=[],</span>
<span class="go">)</span>
</code></pre></div>







              <details class="quote">
                <summary>Source code in <code>flexeval/core/metric/correlation.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 14</span>
<span class="normal"> 15</span>
<span class="normal"> 16</span>
<span class="normal"> 17</span>
<span class="normal"> 18</span>
<span class="normal"> 19</span>
<span class="normal"> 20</span>
<span class="normal"> 21</span>
<span class="normal"> 22</span>
<span class="normal"> 23</span>
<span class="normal"> 24</span>
<span class="normal"> 25</span>
<span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">Correlation</span><span class="p">(</span><span class="n">Metric</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Correlation metric to compute Pearson, Spearman, or Kendall correlation coefficients.</span>
<span class="sd">    The lm_outputs and references should be numeric values, optionally preprocessed by StringProcessor.</span>

<span class="sd">    Args:</span>
<span class="sd">        method: The correlation method to use (&#39;pearson&#39;, &#39;spearman&#39;, &#39;kendall&#39;).</span>
<span class="sd">        lm_output_processor: StringProcessor or a list of StringProcessor to be applied to the model outputs before</span>
<span class="sd">            computing the correlation. If a list is provided, the processors will be applied in order.</span>
<span class="sd">        reference_processor: StringProcessor or a list of StringProcessor to be applied to the references before</span>
<span class="sd">            computing the correlation. If a list is provided, the processors will be applied in order.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from flexeval import Correlation</span>
<span class="sd">        &gt;&gt;&gt; correlation = Correlation(method=&#39;pearson&#39;)</span>
<span class="sd">        &gt;&gt;&gt; lm_outputs = [&quot;1&quot;, &quot;2&quot;, &quot;3&quot;, &quot;4&quot;, &quot;5&quot;]</span>
<span class="sd">        &gt;&gt;&gt; references = [[&quot;5&quot;], [&quot;4&quot;], [&quot;3&quot;], [&quot;2&quot;], [&quot;1&quot;]]</span>
<span class="sd">        &gt;&gt;&gt; result = correlation.evaluate(lm_outputs, references)</span>
<span class="sd">        &gt;&gt;&gt; print(result)</span>
<span class="sd">        MetricResult(</span>
<span class="sd">            summary={&quot;pearson_correlation&quot;: -1.0, &quot;pearson_pvalue&quot;: 0.0},</span>
<span class="sd">            instance_details=[],</span>
<span class="sd">        )</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">method</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;pearson&quot;</span><span class="p">,</span> <span class="s2">&quot;spearman&quot;</span><span class="p">,</span> <span class="s2">&quot;kendall&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;pearson&quot;</span><span class="p">,</span>
        <span class="n">lm_output_processor</span><span class="p">:</span> <span class="n">StringProcessor</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="n">StringProcessor</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">reference_processor</span><span class="p">:</span> <span class="n">StringProcessor</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="n">StringProcessor</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">method</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">{</span><span class="s2">&quot;pearson&quot;</span><span class="p">,</span> <span class="s2">&quot;spearman&quot;</span><span class="p">,</span> <span class="s2">&quot;kendall&quot;</span><span class="p">}:</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Invalid method &#39;</span><span class="si">{</span><span class="n">method</span><span class="si">}</span><span class="s2">&#39;. Choose from &#39;pearson&#39;, &#39;spearman&#39;, &#39;kendall&#39;.&quot;</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">=</span> <span class="n">method</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">lm_output_processor</span><span class="p">,</span> <span class="n">StringProcessor</span><span class="p">):</span>
            <span class="n">lm_output_processor</span> <span class="o">=</span> <span class="p">[</span><span class="n">lm_output_processor</span><span class="p">]</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">reference_processor</span><span class="p">,</span> <span class="n">StringProcessor</span><span class="p">):</span>
            <span class="n">reference_processor</span> <span class="o">=</span> <span class="p">[</span><span class="n">reference_processor</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lm_output_processors</span> <span class="o">=</span> <span class="n">lm_output_processor</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reference_processors</span> <span class="o">=</span> <span class="n">reference_processor</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">lm_outputs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">references_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
        <span class="n">task_inputs_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MetricResult</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">lm_outputs</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">references_list</span><span class="p">):</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Number of model outputs (</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">lm_outputs</span><span class="p">)</span><span class="si">}</span><span class="s2">) and number of references (</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">references_list</span><span class="p">)</span><span class="si">}</span><span class="s2">) &quot;</span>
                <span class="s2">&quot;should be the same.&quot;</span>
            <span class="p">)</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

        <span class="c1"># We only use the first reference here</span>
        <span class="n">references</span> <span class="o">=</span> <span class="p">[</span><span class="n">refs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">refs</span> <span class="ow">in</span> <span class="n">references_list</span><span class="p">]</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">lm_output_processors</span><span class="p">:</span>
            <span class="n">lm_outputs</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">functools</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">norm</span><span class="p">:</span> <span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">lm_output_processors</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span> <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">lm_outputs</span>
            <span class="p">]</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">reference_processors</span><span class="p">:</span>
            <span class="n">references</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">functools</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">norm</span><span class="p">:</span> <span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">reference_processors</span><span class="p">,</span> <span class="n">ref</span><span class="p">)</span> <span class="k">for</span> <span class="n">ref</span> <span class="ow">in</span> <span class="n">references</span>
            <span class="p">]</span>

        <span class="c1"># The model output should be converted to float, if fails it will be treated as 0</span>
        <span class="n">lm_outputs_as_float</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">lm_outputs</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">lm_outputs_as_float</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">output</span><span class="p">))</span>
            <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>  <span class="c1"># noqa:PERF203</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to convert model output &#39;</span><span class="si">{</span><span class="n">output</span><span class="si">}</span><span class="s2">&#39; to float. Treating it as 0.&quot;</span><span class="p">,</span> <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
                <span class="n">lm_outputs_as_float</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span>

        <span class="c1"># The reference should be converted to float</span>
        <span class="n">references_as_float</span> <span class="o">=</span> <span class="p">[</span><span class="nb">float</span><span class="p">(</span><span class="n">ref</span><span class="p">)</span> <span class="k">for</span> <span class="n">ref</span> <span class="ow">in</span> <span class="n">references</span><span class="p">]</span>

        <span class="c1"># Compute correlation</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">==</span> <span class="s2">&quot;pearson&quot;</span><span class="p">:</span>
            <span class="n">correlation</span><span class="p">,</span> <span class="n">pvalue</span> <span class="o">=</span> <span class="n">pearsonr</span><span class="p">(</span><span class="n">lm_outputs_as_float</span><span class="p">,</span> <span class="n">references_as_float</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">==</span> <span class="s2">&quot;spearman&quot;</span><span class="p">:</span>
            <span class="n">correlation</span><span class="p">,</span> <span class="n">pvalue</span> <span class="o">=</span> <span class="n">spearmanr</span><span class="p">(</span><span class="n">lm_outputs_as_float</span><span class="p">,</span> <span class="n">references_as_float</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">==</span> <span class="s2">&quot;kendall&quot;</span><span class="p">:</span>
            <span class="n">correlation</span><span class="p">,</span> <span class="n">pvalue</span> <span class="o">=</span> <span class="n">kendalltau</span><span class="p">(</span><span class="n">lm_outputs_as_float</span><span class="p">,</span> <span class="n">references_as_float</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Unsupported method: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">method</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">MetricResult</span><span class="p">(</span>
            <span class="p">{</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">method</span><span class="si">}</span><span class="s2">_correlation&quot;</span><span class="p">:</span> <span class="n">correlation</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">method</span><span class="si">}</span><span class="s2">_pvalue&quot;</span><span class="p">:</span> <span class="n">pvalue</span><span class="p">},</span>
            <span class="n">instance_details</span><span class="o">=</span><span class="p">[],</span>
        <span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.correlation.Correlation.method" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">method</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.correlation.Correlation.method" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">method</span> <span class="o">=</span> <span class="n">method</span>
</code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.correlation.Correlation.lm_output_processors" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">lm_output_processors</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.correlation.Correlation.lm_output_processors" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">lm_output_processors</span> <span class="o">=</span> <span class="n">lm_output_processor</span>
</code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.correlation.Correlation.reference_processors" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">reference_processors</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.correlation.Correlation.reference_processors" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">reference_processors</span> <span class="o">=</span> <span class="n">reference_processor</span>
</code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>



<div class="doc doc-object doc-function">


<h3 id="flexeval.core.metric.correlation.Correlation.__init__" class="doc doc-heading">
            <span class="doc doc-object-name doc-function-name">__init__</span>


<a href="#flexeval.core.metric.correlation.Correlation.__init__" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="fm">__init__</span><span class="p">(</span>
    <span class="nf">method</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span>
        <span class="s2">&quot;pearson&quot;</span><span class="p">,</span> <span class="s2">&quot;spearman&quot;</span><span class="p">,</span> <span class="s2">&quot;kendall&quot;</span>
    <span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;pearson&quot;</span><span class="p">,</span>
    <span class="n">lm_output_processor</span><span class="p">:</span> <span class="n">StringProcessor</span>
    <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="n">StringProcessor</span><span class="p">]</span>
    <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">reference_processor</span><span class="p">:</span> <span class="n">StringProcessor</span>
    <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="n">StringProcessor</span><span class="p">]</span>
    <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>

    <div class="doc doc-contents ">


            <details class="quote">
              <summary>Source code in <code>flexeval/core/metric/correlation.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">method</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;pearson&quot;</span><span class="p">,</span> <span class="s2">&quot;spearman&quot;</span><span class="p">,</span> <span class="s2">&quot;kendall&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;pearson&quot;</span><span class="p">,</span>
    <span class="n">lm_output_processor</span><span class="p">:</span> <span class="n">StringProcessor</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="n">StringProcessor</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">reference_processor</span><span class="p">:</span> <span class="n">StringProcessor</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="n">StringProcessor</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">method</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">{</span><span class="s2">&quot;pearson&quot;</span><span class="p">,</span> <span class="s2">&quot;spearman&quot;</span><span class="p">,</span> <span class="s2">&quot;kendall&quot;</span><span class="p">}:</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Invalid method &#39;</span><span class="si">{</span><span class="n">method</span><span class="si">}</span><span class="s2">&#39;. Choose from &#39;pearson&#39;, &#39;spearman&#39;, &#39;kendall&#39;.&quot;</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">=</span> <span class="n">method</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">lm_output_processor</span><span class="p">,</span> <span class="n">StringProcessor</span><span class="p">):</span>
        <span class="n">lm_output_processor</span> <span class="o">=</span> <span class="p">[</span><span class="n">lm_output_processor</span><span class="p">]</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">reference_processor</span><span class="p">,</span> <span class="n">StringProcessor</span><span class="p">):</span>
        <span class="n">reference_processor</span> <span class="o">=</span> <span class="p">[</span><span class="n">reference_processor</span><span class="p">]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">lm_output_processors</span> <span class="o">=</span> <span class="n">lm_output_processor</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">reference_processors</span> <span class="o">=</span> <span class="n">reference_processor</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="flexeval.core.metric.correlation.Correlation.evaluate" class="doc doc-heading">
            <span class="doc doc-object-name doc-function-name">evaluate</span>


<a href="#flexeval.core.metric.correlation.Correlation.evaluate" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="nf">evaluate</span><span class="p">(</span>
    <span class="n">lm_outputs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">references_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
    <span class="n">task_inputs_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MetricResult</span>
</code></pre></div>

    <div class="doc doc-contents ">


            <details class="quote">
              <summary>Source code in <code>flexeval/core/metric/correlation.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">lm_outputs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">references_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
    <span class="n">task_inputs_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MetricResult</span><span class="p">:</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">lm_outputs</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">references_list</span><span class="p">):</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Number of model outputs (</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">lm_outputs</span><span class="p">)</span><span class="si">}</span><span class="s2">) and number of references (</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">references_list</span><span class="p">)</span><span class="si">}</span><span class="s2">) &quot;</span>
            <span class="s2">&quot;should be the same.&quot;</span>
        <span class="p">)</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

    <span class="c1"># We only use the first reference here</span>
    <span class="n">references</span> <span class="o">=</span> <span class="p">[</span><span class="n">refs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">refs</span> <span class="ow">in</span> <span class="n">references_list</span><span class="p">]</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">lm_output_processors</span><span class="p">:</span>
        <span class="n">lm_outputs</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">functools</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">norm</span><span class="p">:</span> <span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">lm_output_processors</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span> <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">lm_outputs</span>
        <span class="p">]</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">reference_processors</span><span class="p">:</span>
        <span class="n">references</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">functools</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">norm</span><span class="p">:</span> <span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">reference_processors</span><span class="p">,</span> <span class="n">ref</span><span class="p">)</span> <span class="k">for</span> <span class="n">ref</span> <span class="ow">in</span> <span class="n">references</span>
        <span class="p">]</span>

    <span class="c1"># The model output should be converted to float, if fails it will be treated as 0</span>
    <span class="n">lm_outputs_as_float</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">lm_outputs</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">lm_outputs_as_float</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">output</span><span class="p">))</span>
        <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>  <span class="c1"># noqa:PERF203</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to convert model output &#39;</span><span class="si">{</span><span class="n">output</span><span class="si">}</span><span class="s2">&#39; to float. Treating it as 0.&quot;</span><span class="p">,</span> <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
            <span class="n">lm_outputs_as_float</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span>

    <span class="c1"># The reference should be converted to float</span>
    <span class="n">references_as_float</span> <span class="o">=</span> <span class="p">[</span><span class="nb">float</span><span class="p">(</span><span class="n">ref</span><span class="p">)</span> <span class="k">for</span> <span class="n">ref</span> <span class="ow">in</span> <span class="n">references</span><span class="p">]</span>

    <span class="c1"># Compute correlation</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">==</span> <span class="s2">&quot;pearson&quot;</span><span class="p">:</span>
        <span class="n">correlation</span><span class="p">,</span> <span class="n">pvalue</span> <span class="o">=</span> <span class="n">pearsonr</span><span class="p">(</span><span class="n">lm_outputs_as_float</span><span class="p">,</span> <span class="n">references_as_float</span><span class="p">)</span>
    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">==</span> <span class="s2">&quot;spearman&quot;</span><span class="p">:</span>
        <span class="n">correlation</span><span class="p">,</span> <span class="n">pvalue</span> <span class="o">=</span> <span class="n">spearmanr</span><span class="p">(</span><span class="n">lm_outputs_as_float</span><span class="p">,</span> <span class="n">references_as_float</span><span class="p">)</span>
    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">==</span> <span class="s2">&quot;kendall&quot;</span><span class="p">:</span>
        <span class="n">correlation</span><span class="p">,</span> <span class="n">pvalue</span> <span class="o">=</span> <span class="n">kendalltau</span><span class="p">(</span><span class="n">lm_outputs_as_float</span><span class="p">,</span> <span class="n">references_as_float</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Unsupported method: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">method</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">MetricResult</span><span class="p">(</span>
        <span class="p">{</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">method</span><span class="si">}</span><span class="s2">_correlation&quot;</span><span class="p">:</span> <span class="n">correlation</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">method</span><span class="si">}</span><span class="s2">_pvalue&quot;</span><span class="p">:</span> <span class="n">pvalue</span><span class="p">},</span>
        <span class="n">instance_details</span><span class="o">=</span><span class="p">[],</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="flexeval.core.metric.exact_match.ExactMatch" class="doc doc-heading">
            <span class="doc doc-object-name doc-class-name">ExactMatch</span>


<a href="#flexeval.core.metric.exact_match.ExactMatch" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents first">


        <p>Exact match metric.
If there are multiple references, the output is considered correct if it matches any of the references.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>lm_output_processor</code></b>
              (<code><a class="autorefs autorefs-internal" title="StringProcessor (flexeval.core.string_processor.StringProcessor)" href="../StringProcessor/#flexeval.core.string_processor.base.StringProcessor">StringProcessor</a> | <span title="list">list</span>[<a class="autorefs autorefs-internal" title="StringProcessor (flexeval.core.string_processor.StringProcessor)" href="../StringProcessor/#flexeval.core.string_processor.base.StringProcessor">StringProcessor</a>] | None</code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>StringProcessor or a list of StringProcessor to be applied to the model outputs before comparison.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>reference_processor</code></b>
              (<code><a class="autorefs autorefs-internal" title="StringProcessor (flexeval.core.string_processor.StringProcessor)" href="../StringProcessor/#flexeval.core.string_processor.base.StringProcessor">StringProcessor</a> | <span title="list">list</span>[<a class="autorefs autorefs-internal" title="StringProcessor (flexeval.core.string_processor.StringProcessor)" href="../StringProcessor/#flexeval.core.string_processor.base.StringProcessor">StringProcessor</a>] | None</code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>StringProcessor or list of StringProcessor to apply to the references before comparison.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>category_key</code></b>
              (<code><span title="str">str</span> | None</code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>A key to create category-wise mean score.
The category key is expected to be in task inputs.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">flexeval</span><span class="w"> </span><span class="kn">import</span> <span class="n">ExactMatch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">exact_match</span> <span class="o">=</span> <span class="n">ExactMatch</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lm_outputs</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;ABC&quot;</span><span class="p">,</span> <span class="s2">&quot;DEF&quot;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">references_list</span> <span class="o">=</span> <span class="p">[[</span><span class="s2">&quot;ABC&quot;</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;DEFG&quot;</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">exact_match</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">lm_outputs</span><span class="p">,</span> <span class="n">references_list</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
<span class="go">MetricResult(</span>
<span class="go">    summary={&quot;exact_match&quot;: 0.5},</span>
<span class="go">    instance_details=[{&quot;exact_match&quot;: True}, {&quot;exact_match&quot;: False}],</span>
<span class="go">)</span>
</code></pre></div>







              <details class="quote">
                <summary>Source code in <code>flexeval/core/metric/exact_match.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span>
<span class="normal">84</span>
<span class="normal">85</span>
<span class="normal">86</span>
<span class="normal">87</span>
<span class="normal">88</span>
<span class="normal">89</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">ExactMatch</span><span class="p">(</span><span class="n">Metric</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Exact match metric.</span>
<span class="sd">    If there are multiple references, the output is considered correct if it matches any of the references.</span>

<span class="sd">    Args:</span>
<span class="sd">        lm_output_processor:</span>
<span class="sd">            StringProcessor or a list of StringProcessor to be applied to the model outputs before comparison.</span>
<span class="sd">        reference_processor: StringProcessor or list of StringProcessor to apply to the references before comparison.</span>
<span class="sd">        category_key: A key to create category-wise mean score.</span>
<span class="sd">            The category key is expected to be in task inputs.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from flexeval import ExactMatch</span>
<span class="sd">        &gt;&gt;&gt; exact_match = ExactMatch()</span>
<span class="sd">        &gt;&gt;&gt; lm_outputs = [&quot;ABC&quot;, &quot;DEF&quot;]</span>
<span class="sd">        &gt;&gt;&gt; references_list = [[&quot;ABC&quot;], [&quot;DEFG&quot;]]</span>
<span class="sd">        &gt;&gt;&gt; result = exact_match.evaluate(lm_outputs, references_list)</span>
<span class="sd">        &gt;&gt;&gt; print(result)</span>
<span class="sd">        MetricResult(</span>
<span class="sd">            summary={&quot;exact_match&quot;: 0.5},</span>
<span class="sd">            instance_details=[{&quot;exact_match&quot;: True}, {&quot;exact_match&quot;: False}],</span>
<span class="sd">        )</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">lm_output_processor</span><span class="p">:</span> <span class="n">StringProcessor</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="n">StringProcessor</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">reference_processor</span><span class="p">:</span> <span class="n">StringProcessor</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="n">StringProcessor</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">category_key</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">lm_output_processor</span><span class="p">,</span> <span class="n">StringProcessor</span><span class="p">):</span>
            <span class="n">lm_output_processor</span> <span class="o">=</span> <span class="p">[</span><span class="n">lm_output_processor</span><span class="p">]</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">reference_processor</span><span class="p">,</span> <span class="n">StringProcessor</span><span class="p">):</span>
            <span class="n">reference_processor</span> <span class="o">=</span> <span class="p">[</span><span class="n">reference_processor</span><span class="p">]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">lm_output_processors</span> <span class="o">=</span> <span class="n">lm_output_processor</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reference_processors</span> <span class="o">=</span> <span class="n">reference_processor</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">category_key</span> <span class="o">=</span> <span class="n">category_key</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">lm_outputs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">references_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
        <span class="n">task_inputs_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MetricResult</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">lm_outputs</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">references_list</span><span class="p">):</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Number of model outputs (</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">lm_outputs</span><span class="p">)</span><span class="si">}</span><span class="s2">) and number of references (</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">references_list</span><span class="p">)</span><span class="si">}</span><span class="s2">) &quot;</span>
                <span class="s2">&quot;should be the same.&quot;</span>
            <span class="p">)</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">lm_output_processors</span><span class="p">:</span>
            <span class="n">lm_outputs</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">functools</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">norm</span><span class="p">:</span> <span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">lm_output_processors</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span> <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">lm_outputs</span>
            <span class="p">]</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">reference_processors</span><span class="p">:</span>
            <span class="n">references_list</span> <span class="o">=</span> <span class="p">[</span>
                <span class="p">[</span><span class="n">functools</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">norm</span><span class="p">:</span> <span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">reference_processors</span><span class="p">,</span> <span class="n">ref</span><span class="p">)</span> <span class="k">for</span> <span class="n">ref</span> <span class="ow">in</span> <span class="n">references</span><span class="p">]</span>
                <span class="k">for</span> <span class="n">references</span> <span class="ow">in</span> <span class="n">references_list</span>
            <span class="p">]</span>

        <span class="n">exact_match_list</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">lm_output</span> <span class="ow">in</span> <span class="n">expected_output</span> <span class="k">for</span> <span class="n">lm_output</span><span class="p">,</span> <span class="n">expected_output</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">lm_outputs</span><span class="p">,</span> <span class="n">references_list</span><span class="p">)</span>
        <span class="p">]</span>
        <span class="n">summary</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;exact_match&quot;</span><span class="p">:</span> <span class="nb">sum</span><span class="p">(</span><span class="n">exact_match_list</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">exact_match_list</span><span class="p">)}</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">category_key</span><span class="p">:</span>
            <span class="n">categories</span> <span class="o">=</span> <span class="p">[</span><span class="n">task_input</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">category_key</span><span class="p">]</span> <span class="k">for</span> <span class="n">task_input</span> <span class="ow">in</span> <span class="n">task_inputs_list</span><span class="p">]</span>
            <span class="n">category_wise_scores</span> <span class="o">=</span> <span class="n">aggregate_category_wise_scores</span><span class="p">(</span><span class="n">exact_match_list</span><span class="p">,</span> <span class="n">categories</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">category</span><span class="p">,</span> <span class="n">category_wise_score</span> <span class="ow">in</span> <span class="n">category_wise_scores</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="n">summary</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;exact_match/</span><span class="si">{</span><span class="n">category</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">category_wise_score</span>

        <span class="k">return</span> <span class="n">MetricResult</span><span class="p">(</span>
            <span class="n">summary</span><span class="p">,</span>
            <span class="n">instance_details</span><span class="o">=</span><span class="p">[{</span><span class="s2">&quot;exact_match&quot;</span><span class="p">:</span> <span class="n">s</span><span class="p">}</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">exact_match_list</span><span class="p">],</span>
        <span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.exact_match.ExactMatch.lm_output_processors" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">lm_output_processors</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.exact_match.ExactMatch.lm_output_processors" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">lm_output_processors</span> <span class="o">=</span> <span class="n">lm_output_processor</span>
</code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.exact_match.ExactMatch.reference_processors" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">reference_processors</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.exact_match.ExactMatch.reference_processors" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">reference_processors</span> <span class="o">=</span> <span class="n">reference_processor</span>
</code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.exact_match.ExactMatch.category_key" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">category_key</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.exact_match.ExactMatch.category_key" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">category_key</span> <span class="o">=</span> <span class="n">category_key</span>
</code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>



<div class="doc doc-object doc-function">


<h3 id="flexeval.core.metric.exact_match.ExactMatch.__init__" class="doc doc-heading">
            <span class="doc doc-object-name doc-function-name">__init__</span>


<a href="#flexeval.core.metric.exact_match.ExactMatch.__init__" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="fm">__init__</span><span class="p">(</span>
    <span class="nf">lm_output_processor</span><span class="p">:</span> <span class="n">StringProcessor</span>
    <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="n">StringProcessor</span><span class="p">]</span>
    <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">reference_processor</span><span class="p">:</span> <span class="n">StringProcessor</span>
    <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="n">StringProcessor</span><span class="p">]</span>
    <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">category_key</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>

    <div class="doc doc-contents ">


            <details class="quote">
              <summary>Source code in <code>flexeval/core/metric/exact_match.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">lm_output_processor</span><span class="p">:</span> <span class="n">StringProcessor</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="n">StringProcessor</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">reference_processor</span><span class="p">:</span> <span class="n">StringProcessor</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="n">StringProcessor</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">category_key</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">lm_output_processor</span><span class="p">,</span> <span class="n">StringProcessor</span><span class="p">):</span>
        <span class="n">lm_output_processor</span> <span class="o">=</span> <span class="p">[</span><span class="n">lm_output_processor</span><span class="p">]</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">reference_processor</span><span class="p">,</span> <span class="n">StringProcessor</span><span class="p">):</span>
        <span class="n">reference_processor</span> <span class="o">=</span> <span class="p">[</span><span class="n">reference_processor</span><span class="p">]</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">lm_output_processors</span> <span class="o">=</span> <span class="n">lm_output_processor</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">reference_processors</span> <span class="o">=</span> <span class="n">reference_processor</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">category_key</span> <span class="o">=</span> <span class="n">category_key</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="flexeval.core.metric.exact_match.ExactMatch.evaluate" class="doc doc-heading">
            <span class="doc doc-object-name doc-function-name">evaluate</span>


<a href="#flexeval.core.metric.exact_match.ExactMatch.evaluate" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="nf">evaluate</span><span class="p">(</span>
    <span class="n">lm_outputs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">references_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
    <span class="n">task_inputs_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MetricResult</span>
</code></pre></div>

    <div class="doc doc-contents ">


            <details class="quote">
              <summary>Source code in <code>flexeval/core/metric/exact_match.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span>
<span class="normal">84</span>
<span class="normal">85</span>
<span class="normal">86</span>
<span class="normal">87</span>
<span class="normal">88</span>
<span class="normal">89</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">lm_outputs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">references_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
    <span class="n">task_inputs_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MetricResult</span><span class="p">:</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">lm_outputs</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">references_list</span><span class="p">):</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Number of model outputs (</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">lm_outputs</span><span class="p">)</span><span class="si">}</span><span class="s2">) and number of references (</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">references_list</span><span class="p">)</span><span class="si">}</span><span class="s2">) &quot;</span>
            <span class="s2">&quot;should be the same.&quot;</span>
        <span class="p">)</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">lm_output_processors</span><span class="p">:</span>
        <span class="n">lm_outputs</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">functools</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">norm</span><span class="p">:</span> <span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">lm_output_processors</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span> <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">lm_outputs</span>
        <span class="p">]</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">reference_processors</span><span class="p">:</span>
        <span class="n">references_list</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">[</span><span class="n">functools</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">norm</span><span class="p">:</span> <span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">reference_processors</span><span class="p">,</span> <span class="n">ref</span><span class="p">)</span> <span class="k">for</span> <span class="n">ref</span> <span class="ow">in</span> <span class="n">references</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">references</span> <span class="ow">in</span> <span class="n">references_list</span>
        <span class="p">]</span>

    <span class="n">exact_match_list</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">lm_output</span> <span class="ow">in</span> <span class="n">expected_output</span> <span class="k">for</span> <span class="n">lm_output</span><span class="p">,</span> <span class="n">expected_output</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">lm_outputs</span><span class="p">,</span> <span class="n">references_list</span><span class="p">)</span>
    <span class="p">]</span>
    <span class="n">summary</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;exact_match&quot;</span><span class="p">:</span> <span class="nb">sum</span><span class="p">(</span><span class="n">exact_match_list</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">exact_match_list</span><span class="p">)}</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">category_key</span><span class="p">:</span>
        <span class="n">categories</span> <span class="o">=</span> <span class="p">[</span><span class="n">task_input</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">category_key</span><span class="p">]</span> <span class="k">for</span> <span class="n">task_input</span> <span class="ow">in</span> <span class="n">task_inputs_list</span><span class="p">]</span>
        <span class="n">category_wise_scores</span> <span class="o">=</span> <span class="n">aggregate_category_wise_scores</span><span class="p">(</span><span class="n">exact_match_list</span><span class="p">,</span> <span class="n">categories</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">category</span><span class="p">,</span> <span class="n">category_wise_score</span> <span class="ow">in</span> <span class="n">category_wise_scores</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">summary</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;exact_match/</span><span class="si">{</span><span class="n">category</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">category_wise_score</span>

    <span class="k">return</span> <span class="n">MetricResult</span><span class="p">(</span>
        <span class="n">summary</span><span class="p">,</span>
        <span class="n">instance_details</span><span class="o">=</span><span class="p">[{</span><span class="s2">&quot;exact_match&quot;</span><span class="p">:</span> <span class="n">s</span><span class="p">}</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">exact_match_list</span><span class="p">],</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="flexeval.core.metric.llm_geval_score.ChatLLMGEvalScore" class="doc doc-heading">
            <span class="doc doc-object-name doc-class-name">ChatLLMGEvalScore</span>


<a href="#flexeval.core.metric.llm_geval_score.ChatLLMGEvalScore" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents first">


        <p>A metric that evaluates the output of <code>LanguageModel.batch_generate_chat_response</code>.
Unlike ChatLLMScore, this metric let the model output logprobs for all valid scores and
calculate weighted score among them.
Note that due to constraint for OpenAI models, the number of valid scores must not exceed 20.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>language_model</code></b>
              (<code><span title="required">required</span></code>)
          –
          <div class="doc-md-description">
            <p>An instance of <code>LanguageModel</code> to evaluate the output of the model.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>prompt_template</code></b>
              (<code><span title="required">required</span></code>)
          –
          <div class="doc-md-description">
            <p>An instance of <code>PromptTemplate</code> to embed the input for the evaluator.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>valid_score_range</code></b>
              (<code><span title="required">required</span></code>)
          –
          <div class="doc-md-description">
            <p>A tuple of two integers representing the valid score range.
If the parsed score is out of the range, it will be ignored.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>batch_size</code></b>
              (<code><span title="int">int</span></code>, default:
                  <code>4</code>
)
          –
          <div class="doc-md-description">
            <p>The batch size for the evaluator.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>system_message</code></b>
              (<code><span title="str">str</span> | <a class="autorefs autorefs-internal" title="PromptTemplate (flexeval.core.prompt_template.PromptTemplate)" href="../PromptTemplate/#flexeval.core.prompt_template.base.PromptTemplate">PromptTemplate</a> | None</code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>A system message to be prepended to the input for the evaluator.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>disable_tqdm</code></b>
              (<code><span title="bool">bool</span></code>, default:
                  <code>False</code>
)
          –
          <div class="doc-md-description">
            <p>Whether to disable the progress bar.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>category_key</code></b>
              (<code><span title="str">str</span> | None</code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>A key to create category-wise mean score.
The category key is expected to be in task inputs.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>prob_threshold</code></b>
              (<code><span title="float">float</span></code>, default:
                  <code>0</code>
)
          –
          <div class="doc-md-description">
            <p>For considering low probability among all of valid scores,
return None (invalid) if sum of the all probability among vaild scores is less than this value.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">flexeval</span><span class="w"> </span><span class="kn">import</span> <span class="n">ChatLLMGEvalScore</span><span class="p">,</span> <span class="n">HuggingFaceLM</span><span class="p">,</span> <span class="n">Jinja2PromptTemplate</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">language_model</span> <span class="o">=</span> <span class="n">HuggingFaceLM</span><span class="p">(</span><span class="s2">&quot;Qwen/Qwen2.5-0.5B-Instruct&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">template</span> <span class="o">=</span> <span class="s2">&quot;Evaluate the quality of this text.</span><span class="se">\n</span><span class="s2">`{{ lm_output }}`</span><span class="se">\n</span><span class="s2">Output only a number from 1 to 5.&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">prompt_template</span> <span class="o">=</span> <span class="n">Jinja2PromptTemplate</span><span class="p">(</span><span class="n">template</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">system_message</span> <span class="o">=</span> <span class="s2">&quot;This is the system message.&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">llm_score</span> <span class="o">=</span> <span class="n">ChatLLMGEvalScore</span><span class="p">(</span><span class="n">language_model</span><span class="p">,</span> <span class="n">prompt_template</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="n">system_message</span><span class="o">=</span><span class="n">system_message</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lm_outputs</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Hello, world!&quot;</span><span class="p">,</span> <span class="s2">&quot;Good morning!&quot;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">llm_score</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">lm_outputs</span><span class="p">)</span>
<span class="go">MetricResult(</span>
<span class="go">    summary={&#39;llm_geval_score&#39;: 1.179980414173022, &#39;num_failed_score_parses&#39;: 0},</span>
<span class="go">    instance_details=[</span>
<span class="go">        {</span>
<span class="go">            &#39;llm_geval_score&#39;: 1.1509989197179789,</span>
<span class="go">            &#39;llm_geval_score_input&#39;: [</span>
<span class="go">                {&#39;role&#39;: &#39;system&#39;, &#39;content&#39;: &#39;This is the system message.&#39;},</span>
<span class="go">                {&#39;role&#39;: &#39;user&#39;, &#39;content&#39;: &#39;Evaluate the quality of this text...&#39;}</span>
<span class="go">            ],</span>
<span class="go">            &#39;llm_geval_score_logprobs&#39;: {</span>
<span class="go">                &#39;1&#39;: -0.06977498531341553,</span>
<span class="go">                &#39;2&#39;: -3.687819004058838,</span>
<span class="go">                &#39;3&#39;: -3.937819480895996,</span>
<span class="go">                &#39;4&#39;: -5.812800884246826,</span>
<span class="go">                &#39;5&#39;: -3.937807083129883</span>
<span class="go">            },</span>
<span class="go">            &#39;llm_geval_score_generation_probs&#39;: {</span>
<span class="go">                1: 0.932603645815178,</span>
<span class="go">                2: 0.02502652531327666,</span>
<span class="go">                3: 0.01949066821765914,</span>
<span class="go">                4: 0.002989046364034347,</span>
<span class="go">                5: 0.019490909859903</span>
<span class="go">            }</span>
<span class="go">        },</span>
<span class="go">        {</span>
<span class="go">            &#39;llm_geval_score&#39;: 1.208961908628065,</span>
<span class="go">            &#39;llm_geval_score_input&#39;: [</span>
<span class="go">                {&#39;role&#39;: &#39;system&#39;, &#39;content&#39;: &#39;This is the system message.&#39;},</span>
<span class="go">                {&#39;role&#39;: &#39;user&#39;, &#39;content&#39;: &#39;Evaluate the quality of this text...&#39;}</span>
<span class="go">            ],</span>
<span class="go">            &#39;llm_geval_score_logprobs&#39;: {</span>
<span class="go">                &#39;1&#39;: -0.13043057918548584,</span>
<span class="go">                &#39;2&#39;: -2.8754935264587402,</span>
<span class="go">                &#39;3&#39;: -3.000467538833618,</span>
<span class="go">                &#39;4&#39;: -4.750283241271973,</span>
<span class="go">                &#39;5&#39;: -5.000345706939697</span>
<span class="go">            },</span>
<span class="go">            &#39;llm_geval_score_generation_probs&#39;: {</span>
<span class="go">                1: 0.8777174226922144,</span>
<span class="go">                2: 0.05638830351569556,</span>
<span class="go">                3: 0.04976379642068341,</span>
<span class="go">                4: 0.008649245032977617,</span>
<span class="go">                5: 0.006735618046639277</span>
<span class="go">            }</span>
<span class="go">        }</span>
<span class="go">    ])</span>
</code></pre></div>







              <details class="quote">
                <summary>Source code in <code>flexeval/core/metric/llm_geval_score.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">ChatLLMGEvalScore</span><span class="p">(</span><span class="n">Metric</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A metric that evaluates the output of `LanguageModel.batch_generate_chat_response`.</span>
<span class="sd">    Unlike ChatLLMScore, this metric let the model output logprobs for all valid scores and</span>
<span class="sd">    calculate weighted score among them.</span>
<span class="sd">    Note that due to constraint for OpenAI models, the number of valid scores must not exceed 20.</span>

<span class="sd">    Args:</span>
<span class="sd">        language_model (required): An instance of `LanguageModel` to evaluate the output of the model.</span>
<span class="sd">        prompt_template (required): An instance of `PromptTemplate` to embed the input for the evaluator.</span>
<span class="sd">        valid_score_range (required): A tuple of two integers representing the valid score range.</span>
<span class="sd">            If the parsed score is out of the range, it will be ignored.</span>
<span class="sd">        batch_size: The batch size for the evaluator.</span>
<span class="sd">        system_message: A system message to be prepended to the input for the evaluator.</span>
<span class="sd">        disable_tqdm: Whether to disable the progress bar.</span>
<span class="sd">        category_key: A key to create category-wise mean score.</span>
<span class="sd">            The category key is expected to be in task inputs.</span>
<span class="sd">        prob_threshold: For considering low probability among all of valid scores,</span>
<span class="sd">            return None (invalid) if sum of the all probability among vaild scores is less than this value.</span>


<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from flexeval import ChatLLMGEvalScore, HuggingFaceLM, Jinja2PromptTemplate</span>
<span class="sd">        &gt;&gt;&gt; language_model = HuggingFaceLM(&quot;Qwen/Qwen2.5-0.5B-Instruct&quot;)</span>
<span class="sd">        &gt;&gt;&gt; template = &quot;Evaluate the quality of this text.\\n`{{ lm_output }}`\\nOutput only a number from 1 to 5.&quot;</span>
<span class="sd">        &gt;&gt;&gt; prompt_template = Jinja2PromptTemplate(template)</span>
<span class="sd">        &gt;&gt;&gt; system_message = &quot;This is the system message.&quot;</span>
<span class="sd">        &gt;&gt;&gt; llm_score = ChatLLMGEvalScore(language_model, prompt_template, [1, 5], system_message=system_message)</span>
<span class="sd">        &gt;&gt;&gt; lm_outputs = [&quot;Hello, world!&quot;, &quot;Good morning!&quot;]</span>
<span class="sd">        &gt;&gt;&gt; llm_score.evaluate(lm_outputs)</span>
<span class="sd">        MetricResult(</span>
<span class="sd">            summary={&#39;llm_geval_score&#39;: 1.179980414173022, &#39;num_failed_score_parses&#39;: 0},</span>
<span class="sd">            instance_details=[</span>
<span class="sd">                {</span>
<span class="sd">                    &#39;llm_geval_score&#39;: 1.1509989197179789,</span>
<span class="sd">                    &#39;llm_geval_score_input&#39;: [</span>
<span class="sd">                        {&#39;role&#39;: &#39;system&#39;, &#39;content&#39;: &#39;This is the system message.&#39;},</span>
<span class="sd">                        {&#39;role&#39;: &#39;user&#39;, &#39;content&#39;: &#39;Evaluate the quality of this text...&#39;}</span>
<span class="sd">                    ],</span>
<span class="sd">                    &#39;llm_geval_score_logprobs&#39;: {</span>
<span class="sd">                        &#39;1&#39;: -0.06977498531341553,</span>
<span class="sd">                        &#39;2&#39;: -3.687819004058838,</span>
<span class="sd">                        &#39;3&#39;: -3.937819480895996,</span>
<span class="sd">                        &#39;4&#39;: -5.812800884246826,</span>
<span class="sd">                        &#39;5&#39;: -3.937807083129883</span>
<span class="sd">                    },</span>
<span class="sd">                    &#39;llm_geval_score_generation_probs&#39;: {</span>
<span class="sd">                        1: 0.932603645815178,</span>
<span class="sd">                        2: 0.02502652531327666,</span>
<span class="sd">                        3: 0.01949066821765914,</span>
<span class="sd">                        4: 0.002989046364034347,</span>
<span class="sd">                        5: 0.019490909859903</span>
<span class="sd">                    }</span>
<span class="sd">                },</span>
<span class="sd">                {</span>
<span class="sd">                    &#39;llm_geval_score&#39;: 1.208961908628065,</span>
<span class="sd">                    &#39;llm_geval_score_input&#39;: [</span>
<span class="sd">                        {&#39;role&#39;: &#39;system&#39;, &#39;content&#39;: &#39;This is the system message.&#39;},</span>
<span class="sd">                        {&#39;role&#39;: &#39;user&#39;, &#39;content&#39;: &#39;Evaluate the quality of this text...&#39;}</span>
<span class="sd">                    ],</span>
<span class="sd">                    &#39;llm_geval_score_logprobs&#39;: {</span>
<span class="sd">                        &#39;1&#39;: -0.13043057918548584,</span>
<span class="sd">                        &#39;2&#39;: -2.8754935264587402,</span>
<span class="sd">                        &#39;3&#39;: -3.000467538833618,</span>
<span class="sd">                        &#39;4&#39;: -4.750283241271973,</span>
<span class="sd">                        &#39;5&#39;: -5.000345706939697</span>
<span class="sd">                    },</span>
<span class="sd">                    &#39;llm_geval_score_generation_probs&#39;: {</span>
<span class="sd">                        1: 0.8777174226922144,</span>
<span class="sd">                        2: 0.05638830351569556,</span>
<span class="sd">                        3: 0.04976379642068341,</span>
<span class="sd">                        4: 0.008649245032977617,</span>
<span class="sd">                        5: 0.006735618046639277</span>
<span class="sd">                    }</span>
<span class="sd">                }</span>
<span class="sd">            ])</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">language_model</span><span class="p">:</span> <span class="n">LanguageModel</span><span class="p">,</span>
        <span class="n">prompt_template</span><span class="p">:</span> <span class="n">PromptTemplate</span><span class="p">,</span>
        <span class="n">valid_score_range</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
        <span class="n">system_message</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="n">PromptTemplate</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">disable_tqdm</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">category_key</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">prob_threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">language_model</span> <span class="o">=</span> <span class="n">language_model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prompt_template</span> <span class="o">=</span> <span class="n">prompt_template</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">system_message</span> <span class="o">=</span> <span class="n">system_message</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">disable_tqdm</span> <span class="o">=</span> <span class="n">disable_tqdm</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">valid_score_range</span> <span class="o">=</span> <span class="n">valid_score_range</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">category_key</span> <span class="o">=</span> <span class="n">category_key</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prob_threshold</span> <span class="o">=</span> <span class="n">prob_threshold</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">valid_labels</span> <span class="o">=</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">score</span><span class="p">)</span> <span class="k">for</span> <span class="n">score</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">valid_score_range</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">valid_score_range</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">lm_outputs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">references_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">task_inputs_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MetricResult</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">task_inputs_list</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">task_inputs_list</span> <span class="o">=</span> <span class="p">[{}</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">lm_outputs</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">references_list</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">references_list</span> <span class="o">=</span> <span class="p">[[]</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">lm_outputs</span><span class="p">]</span>

        <span class="n">evaluator_input_list</span> <span class="o">=</span> <span class="n">prepare_chat_input_for_evaluator</span><span class="p">(</span>
            <span class="n">lm_outputs</span><span class="p">,</span> <span class="n">references_list</span><span class="p">,</span> <span class="n">task_inputs_list</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompt_template</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">system_message</span>
        <span class="p">)</span>
        <span class="n">evaluator_logprobs_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="n">generate_evaluation_logprobs</span><span class="p">(</span>
            <span class="n">evaluator_input_list</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">language_model</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">valid_labels</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">disable_tqdm</span><span class="p">,</span>
            <span class="s2">&quot;Calculating logprobs&quot;</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">evaluator_score_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">evaluator_probs_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">evaluator_logprobs</span> <span class="ow">in</span> <span class="n">evaluator_logprobs_list</span><span class="p">:</span>
            <span class="n">evaluator_score</span><span class="p">,</span> <span class="n">evaluator_probs</span> <span class="o">=</span> <span class="n">calculate_weighted_average</span><span class="p">(</span>
                <span class="n">evaluator_logprobs</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">valid_score_range</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">prob_threshold</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="n">evaluator_score</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to parse score from evaluator logprobs: </span><span class="si">{</span><span class="n">evaluator_logprobs</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">evaluator_score_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">evaluator_score</span><span class="p">)</span>
            <span class="n">evaluator_probs_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">evaluator_probs</span><span class="p">)</span>

        <span class="n">summary</span> <span class="o">=</span> <span class="n">summarize_evaluator_geval_scores</span><span class="p">(</span>
            <span class="n">evaluator_score_list</span><span class="p">,</span>
            <span class="n">task_inputs_list</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">category_key</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">MetricResult</span><span class="p">(</span>
            <span class="n">summary</span><span class="p">,</span>
            <span class="n">instance_details</span><span class="o">=</span><span class="p">[</span>
                <span class="p">{</span>
                    <span class="s2">&quot;llm_geval_score&quot;</span><span class="p">:</span> <span class="n">eval_score</span><span class="p">,</span>
                    <span class="s2">&quot;llm_geval_score_input&quot;</span><span class="p">:</span> <span class="n">eval_in</span><span class="p">,</span>
                    <span class="s2">&quot;llm_geval_score_logprobs&quot;</span><span class="p">:</span> <span class="n">eval_logprobs</span><span class="p">,</span>
                    <span class="s2">&quot;llm_geval_score_generation_probs&quot;</span><span class="p">:</span> <span class="n">eval_probs</span><span class="p">,</span>
                <span class="p">}</span>
                <span class="k">for</span> <span class="n">eval_score</span><span class="p">,</span> <span class="n">eval_in</span><span class="p">,</span> <span class="n">eval_logprobs</span><span class="p">,</span> <span class="n">eval_probs</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
                    <span class="n">evaluator_score_list</span><span class="p">,</span>
                    <span class="n">evaluator_input_list</span><span class="p">,</span>
                    <span class="n">evaluator_logprobs_list</span><span class="p">,</span>
                    <span class="n">evaluator_probs_list</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="p">],</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">(language_model=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">language_model</span><span class="si">}</span><span class="s2">, prompt_template=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">prompt_template</span><span class="si">}</span><span class="s2">)&quot;</span>
        <span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.llm_geval_score.ChatLLMGEvalScore.language_model" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">language_model</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.llm_geval_score.ChatLLMGEvalScore.language_model" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">language_model</span> <span class="o">=</span> <span class="n">language_model</span>
</code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.llm_geval_score.ChatLLMGEvalScore.prompt_template" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">prompt_template</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.llm_geval_score.ChatLLMGEvalScore.prompt_template" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">prompt_template</span> <span class="o">=</span> <span class="n">prompt_template</span>
</code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.llm_geval_score.ChatLLMGEvalScore.batch_size" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">batch_size</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.llm_geval_score.ChatLLMGEvalScore.batch_size" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
</code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.llm_geval_score.ChatLLMGEvalScore.system_message" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">system_message</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.llm_geval_score.ChatLLMGEvalScore.system_message" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">system_message</span> <span class="o">=</span> <span class="n">system_message</span>
</code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.llm_geval_score.ChatLLMGEvalScore.disable_tqdm" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">disable_tqdm</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.llm_geval_score.ChatLLMGEvalScore.disable_tqdm" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">disable_tqdm</span> <span class="o">=</span> <span class="n">disable_tqdm</span>
</code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.llm_geval_score.ChatLLMGEvalScore.valid_score_range" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">valid_score_range</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.llm_geval_score.ChatLLMGEvalScore.valid_score_range" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">valid_score_range</span> <span class="o">=</span> <span class="n">valid_score_range</span>
</code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.llm_geval_score.ChatLLMGEvalScore.category_key" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">category_key</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.llm_geval_score.ChatLLMGEvalScore.category_key" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">category_key</span> <span class="o">=</span> <span class="n">category_key</span>
</code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.llm_geval_score.ChatLLMGEvalScore.prob_threshold" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">prob_threshold</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.llm_geval_score.ChatLLMGEvalScore.prob_threshold" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">prob_threshold</span> <span class="o">=</span> <span class="n">prob_threshold</span>
</code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.llm_geval_score.ChatLLMGEvalScore.valid_labels" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">valid_labels</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.llm_geval_score.ChatLLMGEvalScore.valid_labels" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">valid_labels</span> <span class="o">=</span> <span class="p">[</span>
    <span class="nb">str</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">score</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span>
        <span class="n">valid_score_range</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">valid_score_range</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="p">)</span>
<span class="p">]</span>
</code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>



<div class="doc doc-object doc-function">


<h3 id="flexeval.core.metric.llm_geval_score.ChatLLMGEvalScore.__init__" class="doc doc-heading">
            <span class="doc doc-object-name doc-function-name">__init__</span>


<a href="#flexeval.core.metric.llm_geval_score.ChatLLMGEvalScore.__init__" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="fm">__init__</span><span class="p">(</span>
    <span class="nf">language_model</span><span class="p">:</span> <span class="n">LanguageModel</span><span class="p">,</span>
    <span class="n">prompt_template</span><span class="p">:</span> <span class="n">PromptTemplate</span><span class="p">,</span>
    <span class="n">valid_score_range</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span>
    <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
    <span class="n">system_message</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="n">PromptTemplate</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">disable_tqdm</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">category_key</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">prob_threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>

    <div class="doc doc-contents ">


            <details class="quote">
              <summary>Source code in <code>flexeval/core/metric/llm_geval_score.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">language_model</span><span class="p">:</span> <span class="n">LanguageModel</span><span class="p">,</span>
    <span class="n">prompt_template</span><span class="p">:</span> <span class="n">PromptTemplate</span><span class="p">,</span>
    <span class="n">valid_score_range</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span>
    <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
    <span class="n">system_message</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="n">PromptTemplate</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">disable_tqdm</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">category_key</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">prob_threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">language_model</span> <span class="o">=</span> <span class="n">language_model</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">prompt_template</span> <span class="o">=</span> <span class="n">prompt_template</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">system_message</span> <span class="o">=</span> <span class="n">system_message</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">disable_tqdm</span> <span class="o">=</span> <span class="n">disable_tqdm</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">valid_score_range</span> <span class="o">=</span> <span class="n">valid_score_range</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">category_key</span> <span class="o">=</span> <span class="n">category_key</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">prob_threshold</span> <span class="o">=</span> <span class="n">prob_threshold</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">valid_labels</span> <span class="o">=</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">score</span><span class="p">)</span> <span class="k">for</span> <span class="n">score</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">valid_score_range</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">valid_score_range</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="flexeval.core.metric.llm_geval_score.ChatLLMGEvalScore.evaluate" class="doc doc-heading">
            <span class="doc doc-object-name doc-function-name">evaluate</span>


<a href="#flexeval.core.metric.llm_geval_score.ChatLLMGEvalScore.evaluate" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="nf">evaluate</span><span class="p">(</span>
    <span class="n">lm_outputs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">references_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">task_inputs_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MetricResult</span>
</code></pre></div>

    <div class="doc doc-contents ">


            <details class="quote">
              <summary>Source code in <code>flexeval/core/metric/llm_geval_score.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">lm_outputs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">references_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">task_inputs_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MetricResult</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">task_inputs_list</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">task_inputs_list</span> <span class="o">=</span> <span class="p">[{}</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">lm_outputs</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">references_list</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">references_list</span> <span class="o">=</span> <span class="p">[[]</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">lm_outputs</span><span class="p">]</span>

    <span class="n">evaluator_input_list</span> <span class="o">=</span> <span class="n">prepare_chat_input_for_evaluator</span><span class="p">(</span>
        <span class="n">lm_outputs</span><span class="p">,</span> <span class="n">references_list</span><span class="p">,</span> <span class="n">task_inputs_list</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompt_template</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">system_message</span>
    <span class="p">)</span>
    <span class="n">evaluator_logprobs_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="n">generate_evaluation_logprobs</span><span class="p">(</span>
        <span class="n">evaluator_input_list</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">language_model</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">valid_labels</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">disable_tqdm</span><span class="p">,</span>
        <span class="s2">&quot;Calculating logprobs&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">evaluator_score_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">evaluator_probs_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">evaluator_logprobs</span> <span class="ow">in</span> <span class="n">evaluator_logprobs_list</span><span class="p">:</span>
        <span class="n">evaluator_score</span><span class="p">,</span> <span class="n">evaluator_probs</span> <span class="o">=</span> <span class="n">calculate_weighted_average</span><span class="p">(</span>
            <span class="n">evaluator_logprobs</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">valid_score_range</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">prob_threshold</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">evaluator_score</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to parse score from evaluator logprobs: </span><span class="si">{</span><span class="n">evaluator_logprobs</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">evaluator_score_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">evaluator_score</span><span class="p">)</span>
        <span class="n">evaluator_probs_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">evaluator_probs</span><span class="p">)</span>

    <span class="n">summary</span> <span class="o">=</span> <span class="n">summarize_evaluator_geval_scores</span><span class="p">(</span>
        <span class="n">evaluator_score_list</span><span class="p">,</span>
        <span class="n">task_inputs_list</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">category_key</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">MetricResult</span><span class="p">(</span>
        <span class="n">summary</span><span class="p">,</span>
        <span class="n">instance_details</span><span class="o">=</span><span class="p">[</span>
            <span class="p">{</span>
                <span class="s2">&quot;llm_geval_score&quot;</span><span class="p">:</span> <span class="n">eval_score</span><span class="p">,</span>
                <span class="s2">&quot;llm_geval_score_input&quot;</span><span class="p">:</span> <span class="n">eval_in</span><span class="p">,</span>
                <span class="s2">&quot;llm_geval_score_logprobs&quot;</span><span class="p">:</span> <span class="n">eval_logprobs</span><span class="p">,</span>
                <span class="s2">&quot;llm_geval_score_generation_probs&quot;</span><span class="p">:</span> <span class="n">eval_probs</span><span class="p">,</span>
            <span class="p">}</span>
            <span class="k">for</span> <span class="n">eval_score</span><span class="p">,</span> <span class="n">eval_in</span><span class="p">,</span> <span class="n">eval_logprobs</span><span class="p">,</span> <span class="n">eval_probs</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
                <span class="n">evaluator_score_list</span><span class="p">,</span>
                <span class="n">evaluator_input_list</span><span class="p">,</span>
                <span class="n">evaluator_logprobs_list</span><span class="p">,</span>
                <span class="n">evaluator_probs_list</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">],</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="flexeval.core.metric.llm_geval_score.ChatLLMGEvalScore.__repr__" class="doc doc-heading">
            <span class="doc doc-object-name doc-function-name">__repr__</span>


<a href="#flexeval.core.metric.llm_geval_score.ChatLLMGEvalScore.__repr__" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="fm">__repr__</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="nb">str</span>
</code></pre></div>

    <div class="doc doc-contents ">


            <details class="quote">
              <summary>Source code in <code>flexeval/core/metric/llm_geval_score.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="k">return</span> <span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">(language_model=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">language_model</span><span class="si">}</span><span class="s2">, prompt_template=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">prompt_template</span><span class="si">}</span><span class="s2">)&quot;</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="flexeval.core.metric.llm_geval_score.LLMGEvalScore" class="doc doc-heading">
            <span class="doc doc-object-name doc-class-name">LLMGEvalScore</span>


<a href="#flexeval.core.metric.llm_geval_score.LLMGEvalScore" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents first">


        <p>Let LanguageModel evaluate the output of another LanguageModel.
Unlike LLMScore, this metric let the model output logprobs for all valid scores and
calculate weighted score among them.
Note that due to constraint for OpenAI models, the number of valid scores must not exceed 20.
For detail, see https://aclanthology.org/2023.emnlp-main.153/</p>
<p>You can specify the evaluation criteria in <code>PromptTemplate</code>.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>language_model</code></b>
              (<code><span title="required">required</span></code>)
          –
          <div class="doc-md-description">
            <p>An instance of <code>LanguageModel</code> to evaluate the output of the model.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>prompt_template</code></b>
              (<code><span title="required">required</span></code>)
          –
          <div class="doc-md-description">
            <p>An instance of <code>PromptTemplate</code> to embed the input for the evaluator.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>valid_score_range</code></b>
              (<code><span title="required">required</span></code>)
          –
          <div class="doc-md-description">
            <p>A tuple of two integers representing the valid score range.
If the parsed score is out of the range, it will be ignored.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>batch_size</code></b>
              (<code><span title="int">int</span></code>, default:
                  <code>4</code>
)
          –
          <div class="doc-md-description">
            <p>The batch size for the evaluator.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>disable_tqdm</code></b>
              (<code><span title="bool">bool</span></code>, default:
                  <code>False</code>
)
          –
          <div class="doc-md-description">
            <p>Whether to disable the progress bar.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>category_key</code></b>
              (<code><span title="str">str</span> | None</code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>A key to create category-wise mean score.
The category key is expected to be in task inputs.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>prob_threshold</code></b>
              (<code><span title="float">float</span></code>, default:
                  <code>0</code>
)
          –
          <div class="doc-md-description">
            <p>For considering low probability among all of valid scores,
return None (invalid) if sum of the all probability among vaild scores is less than this value.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">flexeval</span><span class="w"> </span><span class="kn">import</span> <span class="n">LLMGEvalScore</span><span class="p">,</span> <span class="n">HuggingFaceLM</span><span class="p">,</span> <span class="n">Jinja2PromptTemplate</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">language_model</span> <span class="o">=</span> <span class="n">HuggingFaceLM</span><span class="p">(</span><span class="s2">&quot;Qwen/Qwen2.5-0.5B-Instruct&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">template</span> <span class="o">=</span> <span class="s2">&quot;Evaluate the quality of this text.</span><span class="se">\n</span><span class="s2">`{{ lm_output }}`</span><span class="se">\n</span><span class="s2">Output only a number from 1 to 5.&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">prompt_template</span> <span class="o">=</span> <span class="n">Jinja2PromptTemplate</span><span class="p">(</span><span class="n">template</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">llm_score</span> <span class="o">=</span> <span class="n">LLMGEvalScore</span><span class="p">(</span><span class="n">language_model</span><span class="p">,</span> <span class="n">prompt_template</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lm_outputs</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Hello, world!&quot;</span><span class="p">,</span> <span class="s2">&quot;Good morning!&quot;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">llm_score</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">lm_outputs</span><span class="p">)</span>
<span class="go">MetricResult(</span>
<span class="go">    summary={&#39;llm_geval_score&#39;: 1.4399980931290486, &#39;num_failed_score_parses&#39;: 0},</span>
<span class="go">    instance_details=[</span>
<span class="go">        {</span>
<span class="go">            &#39;llm_geval_score&#39;: 1.418920817254956,</span>
<span class="go">            &#39;llm_geval_score_input&#39;: &#39;Evaluate the quality of this text...&#39;,</span>
<span class="go">            &#39;llm_geval_score_logprobs&#39;: {</span>
<span class="go">                &#39;1&#39;: -4.0625,</span>
<span class="go">                &#39;2&#39;: -7.75,</span>
<span class="go">                &#39;3&#39;: -8.25,</span>
<span class="go">                &#39;4&#39;: -8.0625,</span>
<span class="go">                &#39;5&#39;: -6.4375</span>
<span class="go">            },</span>
<span class="go">            &#39;llm_geval_score_generation_probs&#39;: {</span>
<span class="go">                1: 0.017205950425851383,</span>
<span class="go">                2: 0.00043074254057568753,</span>
<span class="go">                3: 0.00026125855730166754,</span>
<span class="go">                4: 0.000315137974737356,</span>
<span class="go">                5: 0.0016004026902445643</span>
<span class="go">            }</span>
<span class="go">        },</span>
<span class="go">        {</span>
<span class="go">            &#39;llm_geval_score&#39;: 1.461075369003141</span>
<span class="go">            &#39;llm_geval_score_input&#39;: &#39;Evaluate the quality of this text...&#39;,</span>
<span class="go">            &#39;llm_geval_score_logprobs&#39;: {</span>
<span class="go">                &#39;1&#39;: -4.25,</span>
<span class="go">                &#39;2&#39;: -8.1875,</span>
<span class="go">                &#39;3&#39;: -8.375,</span>
<span class="go">                &#39;4&#39;: -8.125,</span>
<span class="go">                &#39;5&#39;: -6.5</span>
<span class="go">            },</span>
<span class="go">            &#39;llm_geval_score_generation_probs&#39;: {</span>
<span class="go">                1: 0.014264233908999256,</span>
<span class="go">                2: 0.00027810828659249914,</span>
<span class="go">                3: 0.00023055986759244163,</span>
<span class="go">                4: 0.0002960447300568554,</span>
<span class="go">                5: 0.0015034391929775724</span>
<span class="go">            }</span>
<span class="go">        }</span>
<span class="go">    ]</span>
<span class="go">)</span>
</code></pre></div>







              <details class="quote">
                <summary>Source code in <code>flexeval/core/metric/llm_geval_score.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">LLMGEvalScore</span><span class="p">(</span><span class="n">Metric</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Let LanguageModel evaluate the output of another LanguageModel.</span>
<span class="sd">    Unlike LLMScore, this metric let the model output logprobs for all valid scores and</span>
<span class="sd">    calculate weighted score among them.</span>
<span class="sd">    Note that due to constraint for OpenAI models, the number of valid scores must not exceed 20.</span>
<span class="sd">    For detail, see https://aclanthology.org/2023.emnlp-main.153/</span>

<span class="sd">    You can specify the evaluation criteria in `PromptTemplate`.</span>

<span class="sd">    Args:</span>
<span class="sd">        language_model (required): An instance of `LanguageModel` to evaluate the output of the model.</span>
<span class="sd">        prompt_template (required): An instance of `PromptTemplate` to embed the input for the evaluator.</span>
<span class="sd">        valid_score_range (required): A tuple of two integers representing the valid score range.</span>
<span class="sd">            If the parsed score is out of the range, it will be ignored.</span>
<span class="sd">        batch_size: The batch size for the evaluator.</span>
<span class="sd">        disable_tqdm: Whether to disable the progress bar.</span>
<span class="sd">        category_key: A key to create category-wise mean score.</span>
<span class="sd">            The category key is expected to be in task inputs.</span>
<span class="sd">        prob_threshold: For considering low probability among all of valid scores,</span>
<span class="sd">            return None (invalid) if sum of the all probability among vaild scores is less than this value.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from flexeval import LLMGEvalScore, HuggingFaceLM, Jinja2PromptTemplate</span>
<span class="sd">        &gt;&gt;&gt; language_model = HuggingFaceLM(&quot;Qwen/Qwen2.5-0.5B-Instruct&quot;)</span>
<span class="sd">        &gt;&gt;&gt; template = &quot;Evaluate the quality of this text.\\n`{{ lm_output }}`\\nOutput only a number from 1 to 5.&quot;</span>
<span class="sd">        &gt;&gt;&gt; prompt_template = Jinja2PromptTemplate(template)</span>
<span class="sd">        &gt;&gt;&gt; llm_score = LLMGEvalScore(language_model, prompt_template, [1, 5])</span>
<span class="sd">        &gt;&gt;&gt; lm_outputs = [&quot;Hello, world!&quot;, &quot;Good morning!&quot;]</span>
<span class="sd">        &gt;&gt;&gt; llm_score.evaluate(lm_outputs)</span>
<span class="sd">        MetricResult(</span>
<span class="sd">            summary={&#39;llm_geval_score&#39;: 1.4399980931290486, &#39;num_failed_score_parses&#39;: 0},</span>
<span class="sd">            instance_details=[</span>
<span class="sd">                {</span>
<span class="sd">                    &#39;llm_geval_score&#39;: 1.418920817254956,</span>
<span class="sd">                    &#39;llm_geval_score_input&#39;: &#39;Evaluate the quality of this text...&#39;,</span>
<span class="sd">                    &#39;llm_geval_score_logprobs&#39;: {</span>
<span class="sd">                        &#39;1&#39;: -4.0625,</span>
<span class="sd">                        &#39;2&#39;: -7.75,</span>
<span class="sd">                        &#39;3&#39;: -8.25,</span>
<span class="sd">                        &#39;4&#39;: -8.0625,</span>
<span class="sd">                        &#39;5&#39;: -6.4375</span>
<span class="sd">                    },</span>
<span class="sd">                    &#39;llm_geval_score_generation_probs&#39;: {</span>
<span class="sd">                        1: 0.017205950425851383,</span>
<span class="sd">                        2: 0.00043074254057568753,</span>
<span class="sd">                        3: 0.00026125855730166754,</span>
<span class="sd">                        4: 0.000315137974737356,</span>
<span class="sd">                        5: 0.0016004026902445643</span>
<span class="sd">                    }</span>
<span class="sd">                },</span>
<span class="sd">                {</span>
<span class="sd">                    &#39;llm_geval_score&#39;: 1.461075369003141</span>
<span class="sd">                    &#39;llm_geval_score_input&#39;: &#39;Evaluate the quality of this text...&#39;,</span>
<span class="sd">                    &#39;llm_geval_score_logprobs&#39;: {</span>
<span class="sd">                        &#39;1&#39;: -4.25,</span>
<span class="sd">                        &#39;2&#39;: -8.1875,</span>
<span class="sd">                        &#39;3&#39;: -8.375,</span>
<span class="sd">                        &#39;4&#39;: -8.125,</span>
<span class="sd">                        &#39;5&#39;: -6.5</span>
<span class="sd">                    },</span>
<span class="sd">                    &#39;llm_geval_score_generation_probs&#39;: {</span>
<span class="sd">                        1: 0.014264233908999256,</span>
<span class="sd">                        2: 0.00027810828659249914,</span>
<span class="sd">                        3: 0.00023055986759244163,</span>
<span class="sd">                        4: 0.0002960447300568554,</span>
<span class="sd">                        5: 0.0015034391929775724</span>
<span class="sd">                    }</span>
<span class="sd">                }</span>
<span class="sd">            ]</span>
<span class="sd">        )</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">language_model</span><span class="p">:</span> <span class="n">LanguageModel</span><span class="p">,</span>
        <span class="n">prompt_template</span><span class="p">:</span> <span class="n">PromptTemplate</span><span class="p">,</span>
        <span class="n">valid_score_range</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
        <span class="n">disable_tqdm</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">category_key</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">prob_threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">language_model</span> <span class="o">=</span> <span class="n">language_model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prompt_template</span> <span class="o">=</span> <span class="n">prompt_template</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">disable_tqdm</span> <span class="o">=</span> <span class="n">disable_tqdm</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">valid_score_range</span> <span class="o">=</span> <span class="n">valid_score_range</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">category_key</span> <span class="o">=</span> <span class="n">category_key</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prob_threshold</span> <span class="o">=</span> <span class="n">prob_threshold</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">valid_labels</span> <span class="o">=</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">score</span><span class="p">)</span> <span class="k">for</span> <span class="n">score</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">valid_score_range</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">valid_score_range</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">lm_outputs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">references_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">task_inputs_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MetricResult</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">task_inputs_list</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">task_inputs_list</span> <span class="o">=</span> <span class="p">[{}</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">lm_outputs</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">references_list</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">references_list</span> <span class="o">=</span> <span class="p">[[]</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">lm_outputs</span><span class="p">]</span>

        <span class="n">evaluator_input_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">prepare_text_input_for_evaluator</span><span class="p">(</span>
            <span class="n">lm_outputs</span><span class="p">,</span> <span class="n">references_list</span><span class="p">,</span> <span class="n">task_inputs_list</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompt_template</span>
        <span class="p">)</span>
        <span class="n">evaluator_logprobs_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="n">generate_evaluation_logprobs</span><span class="p">(</span>
            <span class="n">evaluator_input_list</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">language_model</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">valid_labels</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">disable_tqdm</span><span class="p">,</span>
            <span class="s2">&quot;Calculating logprobs&quot;</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">evaluator_score_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">evaluator_probs_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">evaluator_logprobs</span> <span class="ow">in</span> <span class="n">evaluator_logprobs_list</span><span class="p">:</span>
            <span class="n">evaluator_score</span><span class="p">,</span> <span class="n">evaluator_probs</span> <span class="o">=</span> <span class="n">calculate_weighted_average</span><span class="p">(</span>
                <span class="n">evaluator_logprobs</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">valid_score_range</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">prob_threshold</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="n">evaluator_score</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to parse score from evaluator logprobs: </span><span class="si">{</span><span class="n">evaluator_logprobs</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">evaluator_score_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">evaluator_score</span><span class="p">)</span>
            <span class="n">evaluator_probs_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">evaluator_probs</span><span class="p">)</span>

        <span class="n">summary</span> <span class="o">=</span> <span class="n">summarize_evaluator_geval_scores</span><span class="p">(</span>
            <span class="n">evaluator_score_list</span><span class="p">,</span>
            <span class="n">task_inputs_list</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">category_key</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">MetricResult</span><span class="p">(</span>
            <span class="n">summary</span><span class="p">,</span>
            <span class="n">instance_details</span><span class="o">=</span><span class="p">[</span>
                <span class="p">{</span>
                    <span class="s2">&quot;llm_geval_score&quot;</span><span class="p">:</span> <span class="n">eval_score</span><span class="p">,</span>
                    <span class="s2">&quot;llm_geval_score_input&quot;</span><span class="p">:</span> <span class="n">eval_in</span><span class="p">,</span>
                    <span class="s2">&quot;llm_geval_score_logprobs&quot;</span><span class="p">:</span> <span class="n">eval_logprobs</span><span class="p">,</span>
                    <span class="s2">&quot;llm_geval_score_generation_probs&quot;</span><span class="p">:</span> <span class="n">eval_probs</span><span class="p">,</span>
                <span class="p">}</span>
                <span class="k">for</span> <span class="n">eval_score</span><span class="p">,</span> <span class="n">eval_in</span><span class="p">,</span> <span class="n">eval_logprobs</span><span class="p">,</span> <span class="n">eval_probs</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
                    <span class="n">evaluator_score_list</span><span class="p">,</span>
                    <span class="n">evaluator_input_list</span><span class="p">,</span>
                    <span class="n">evaluator_logprobs_list</span><span class="p">,</span>
                    <span class="n">evaluator_probs_list</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="p">],</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">(language_model=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">language_model</span><span class="si">}</span><span class="s2">, prompt_template=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">prompt_template</span><span class="si">}</span><span class="s2">)&quot;</span>
        <span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.llm_geval_score.LLMGEvalScore.language_model" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">language_model</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.llm_geval_score.LLMGEvalScore.language_model" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">language_model</span> <span class="o">=</span> <span class="n">language_model</span>
</code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.llm_geval_score.LLMGEvalScore.prompt_template" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">prompt_template</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.llm_geval_score.LLMGEvalScore.prompt_template" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">prompt_template</span> <span class="o">=</span> <span class="n">prompt_template</span>
</code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.llm_geval_score.LLMGEvalScore.batch_size" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">batch_size</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.llm_geval_score.LLMGEvalScore.batch_size" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
</code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.llm_geval_score.LLMGEvalScore.disable_tqdm" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">disable_tqdm</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.llm_geval_score.LLMGEvalScore.disable_tqdm" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">disable_tqdm</span> <span class="o">=</span> <span class="n">disable_tqdm</span>
</code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.llm_geval_score.LLMGEvalScore.valid_score_range" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">valid_score_range</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.llm_geval_score.LLMGEvalScore.valid_score_range" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">valid_score_range</span> <span class="o">=</span> <span class="n">valid_score_range</span>
</code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.llm_geval_score.LLMGEvalScore.category_key" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">category_key</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.llm_geval_score.LLMGEvalScore.category_key" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">category_key</span> <span class="o">=</span> <span class="n">category_key</span>
</code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.llm_geval_score.LLMGEvalScore.prob_threshold" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">prob_threshold</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.llm_geval_score.LLMGEvalScore.prob_threshold" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">prob_threshold</span> <span class="o">=</span> <span class="n">prob_threshold</span>
</code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.llm_geval_score.LLMGEvalScore.valid_labels" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">valid_labels</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.llm_geval_score.LLMGEvalScore.valid_labels" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">valid_labels</span> <span class="o">=</span> <span class="p">[</span>
    <span class="nb">str</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">score</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span>
        <span class="n">valid_score_range</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">valid_score_range</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="p">)</span>
<span class="p">]</span>
</code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>



<div class="doc doc-object doc-function">


<h3 id="flexeval.core.metric.llm_geval_score.LLMGEvalScore.__init__" class="doc doc-heading">
            <span class="doc doc-object-name doc-function-name">__init__</span>


<a href="#flexeval.core.metric.llm_geval_score.LLMGEvalScore.__init__" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="fm">__init__</span><span class="p">(</span>
    <span class="nf">language_model</span><span class="p">:</span> <span class="n">LanguageModel</span><span class="p">,</span>
    <span class="n">prompt_template</span><span class="p">:</span> <span class="n">PromptTemplate</span><span class="p">,</span>
    <span class="n">valid_score_range</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span>
    <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
    <span class="n">disable_tqdm</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">category_key</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">prob_threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>

    <div class="doc doc-contents ">


            <details class="quote">
              <summary>Source code in <code>flexeval/core/metric/llm_geval_score.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">language_model</span><span class="p">:</span> <span class="n">LanguageModel</span><span class="p">,</span>
    <span class="n">prompt_template</span><span class="p">:</span> <span class="n">PromptTemplate</span><span class="p">,</span>
    <span class="n">valid_score_range</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span>
    <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
    <span class="n">disable_tqdm</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">category_key</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">prob_threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">language_model</span> <span class="o">=</span> <span class="n">language_model</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">prompt_template</span> <span class="o">=</span> <span class="n">prompt_template</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">disable_tqdm</span> <span class="o">=</span> <span class="n">disable_tqdm</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">valid_score_range</span> <span class="o">=</span> <span class="n">valid_score_range</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">category_key</span> <span class="o">=</span> <span class="n">category_key</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">prob_threshold</span> <span class="o">=</span> <span class="n">prob_threshold</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">valid_labels</span> <span class="o">=</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">score</span><span class="p">)</span> <span class="k">for</span> <span class="n">score</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">valid_score_range</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">valid_score_range</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="flexeval.core.metric.llm_geval_score.LLMGEvalScore.evaluate" class="doc doc-heading">
            <span class="doc doc-object-name doc-function-name">evaluate</span>


<a href="#flexeval.core.metric.llm_geval_score.LLMGEvalScore.evaluate" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="nf">evaluate</span><span class="p">(</span>
    <span class="n">lm_outputs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">references_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">task_inputs_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MetricResult</span>
</code></pre></div>

    <div class="doc doc-contents ">


            <details class="quote">
              <summary>Source code in <code>flexeval/core/metric/llm_geval_score.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">lm_outputs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">references_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">task_inputs_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MetricResult</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">task_inputs_list</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">task_inputs_list</span> <span class="o">=</span> <span class="p">[{}</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">lm_outputs</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">references_list</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">references_list</span> <span class="o">=</span> <span class="p">[[]</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">lm_outputs</span><span class="p">]</span>

    <span class="n">evaluator_input_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">prepare_text_input_for_evaluator</span><span class="p">(</span>
        <span class="n">lm_outputs</span><span class="p">,</span> <span class="n">references_list</span><span class="p">,</span> <span class="n">task_inputs_list</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompt_template</span>
    <span class="p">)</span>
    <span class="n">evaluator_logprobs_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="n">generate_evaluation_logprobs</span><span class="p">(</span>
        <span class="n">evaluator_input_list</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">language_model</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">valid_labels</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">disable_tqdm</span><span class="p">,</span>
        <span class="s2">&quot;Calculating logprobs&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">evaluator_score_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">evaluator_probs_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">evaluator_logprobs</span> <span class="ow">in</span> <span class="n">evaluator_logprobs_list</span><span class="p">:</span>
        <span class="n">evaluator_score</span><span class="p">,</span> <span class="n">evaluator_probs</span> <span class="o">=</span> <span class="n">calculate_weighted_average</span><span class="p">(</span>
            <span class="n">evaluator_logprobs</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">valid_score_range</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">prob_threshold</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">evaluator_score</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to parse score from evaluator logprobs: </span><span class="si">{</span><span class="n">evaluator_logprobs</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">evaluator_score_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">evaluator_score</span><span class="p">)</span>
        <span class="n">evaluator_probs_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">evaluator_probs</span><span class="p">)</span>

    <span class="n">summary</span> <span class="o">=</span> <span class="n">summarize_evaluator_geval_scores</span><span class="p">(</span>
        <span class="n">evaluator_score_list</span><span class="p">,</span>
        <span class="n">task_inputs_list</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">category_key</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">MetricResult</span><span class="p">(</span>
        <span class="n">summary</span><span class="p">,</span>
        <span class="n">instance_details</span><span class="o">=</span><span class="p">[</span>
            <span class="p">{</span>
                <span class="s2">&quot;llm_geval_score&quot;</span><span class="p">:</span> <span class="n">eval_score</span><span class="p">,</span>
                <span class="s2">&quot;llm_geval_score_input&quot;</span><span class="p">:</span> <span class="n">eval_in</span><span class="p">,</span>
                <span class="s2">&quot;llm_geval_score_logprobs&quot;</span><span class="p">:</span> <span class="n">eval_logprobs</span><span class="p">,</span>
                <span class="s2">&quot;llm_geval_score_generation_probs&quot;</span><span class="p">:</span> <span class="n">eval_probs</span><span class="p">,</span>
            <span class="p">}</span>
            <span class="k">for</span> <span class="n">eval_score</span><span class="p">,</span> <span class="n">eval_in</span><span class="p">,</span> <span class="n">eval_logprobs</span><span class="p">,</span> <span class="n">eval_probs</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
                <span class="n">evaluator_score_list</span><span class="p">,</span>
                <span class="n">evaluator_input_list</span><span class="p">,</span>
                <span class="n">evaluator_logprobs_list</span><span class="p">,</span>
                <span class="n">evaluator_probs_list</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">],</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="flexeval.core.metric.llm_geval_score.LLMGEvalScore.__repr__" class="doc doc-heading">
            <span class="doc doc-object-name doc-function-name">__repr__</span>


<a href="#flexeval.core.metric.llm_geval_score.LLMGEvalScore.__repr__" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="fm">__repr__</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="nb">str</span>
</code></pre></div>

    <div class="doc doc-contents ">


            <details class="quote">
              <summary>Source code in <code>flexeval/core/metric/llm_geval_score.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="k">return</span> <span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">(language_model=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">language_model</span><span class="si">}</span><span class="s2">, prompt_template=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">prompt_template</span><span class="si">}</span><span class="s2">)&quot;</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="flexeval.core.metric.llm_label.ChatLLMLabel" class="doc doc-heading">
            <span class="doc doc-object-name doc-class-name">ChatLLMLabel</span>


<a href="#flexeval.core.metric.llm_label.ChatLLMLabel" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents first">


        <p>A metric that evaluates the output of <code>LanguageModel.batch_generate_chat_response</code>.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>language_model</code></b>
              (<code><a class="autorefs autorefs-internal" title="LanguageModel (flexeval.core.language_model.LanguageModel)" href="../LMOutput/#flexeval.core.language_model.base.LanguageModel">LanguageModel</a></code>)
          –
          <div class="doc-md-description">
            <p>An instance of <code>LanguageModel</code> to evaluate the output of the model.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>prompt_template</code></b>
              (<code><a class="autorefs autorefs-internal" title="PromptTemplate (flexeval.core.prompt_template.PromptTemplate)" href="../PromptTemplate/#flexeval.core.prompt_template.base.PromptTemplate">PromptTemplate</a></code>)
          –
          <div class="doc-md-description">
            <p>An instance of <code>PromptTemplate</code> to embed the input for the evaluator.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>label_names</code></b>
              (<code><span title="list">list</span>[<span title="str">str</span>]</code>)
          –
          <div class="doc-md-description">
            <p>A list of valid label names.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>label_points</code></b>
              (<code><span title="list">list</span>[<span title="float">float</span> | <span title="int">int</span>] | None</code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>A list of points for each label specified in label_names.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>system_message</code></b>
              (<code><span title="str">str</span> | <a class="autorefs autorefs-internal" title="PromptTemplate (flexeval.core.prompt_template.PromptTemplate)" href="../PromptTemplate/#flexeval.core.prompt_template.base.PromptTemplate">PromptTemplate</a> | None</code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>A system message to be prepended to the input for the evaluator.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>batch_size</code></b>
              (<code><span title="int">int</span></code>, default:
                  <code>4</code>
)
          –
          <div class="doc-md-description">
            <p>The batch size for the evaluator.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>disable_tqdm</code></b>
              (<code><span title="bool">bool</span></code>, default:
                  <code>False</code>
)
          –
          <div class="doc-md-description">
            <p>Whether to disable the progress bar.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>category_key</code></b>
              (<code><span title="str">str</span> | None</code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>A key to create category-wise mean score.
The category key is expected to be in task inputs.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">flexeval</span><span class="w"> </span><span class="kn">import</span> <span class="n">ChatLLMScore</span><span class="p">,</span> <span class="n">OpenAIChatAPI</span><span class="p">,</span> <span class="n">Jinja2PromptTemplate</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">language_model</span> <span class="o">=</span> <span class="n">OpenAIChatAPI</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;gpt-3.5-turbo&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">template</span> <span class="o">=</span> <span class="s2">&quot;Evaluate the quality of this text on a scale of Good/Bad.</span><span class="se">\n</span><span class="s2">`{{ lm_output }}`</span><span class="se">\n</span><span class="s2">Put the label at the end like [[Good]].&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">prompt_template</span> <span class="o">=</span> <span class="n">Jinja2PromptTemplate</span><span class="p">(</span><span class="n">template</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">system_message</span> <span class="o">=</span> <span class="s2">&quot;This is the system message.&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">label_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Good&quot;</span><span class="p">,</span> <span class="s2">&quot;Bad&quot;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">label_points</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">llm_label</span> <span class="o">=</span> <span class="n">ChatLLMLabel</span><span class="p">(</span><span class="n">language_model</span><span class="p">,</span> <span class="n">prompt_template</span><span class="p">,</span> <span class="n">label_names</span><span class="p">,</span> <span class="n">label_points</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lm_outputs</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Hello, world!&quot;</span><span class="p">,</span> <span class="s2">&quot;Good morning!&quot;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">llm_label</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">lm_outputs</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
<span class="go">MetricResult(</span>
<span class="go">    summary={&#39;llm_score&#39;: 0.5, &#39;llm_label_distribution&#39;: {&#39;Good&#39;: 0.5, &#39;Bad&#39;: 0.5}, &#39;num_failed_score_parses&#39;: 0},</span>
<span class="go">    instance_details=[</span>
<span class="go">        {</span>
<span class="go">            &#39;llm_label&#39;: &#39;Good&#39;,</span>
<span class="go">            &#39;llm_score&#39;: 1.0,</span>
<span class="go">            &#39;llm_label_input&#39;: &#39;Evaluate the quality of this text...&#39;,</span>
<span class="go">            &#39;llm_label_output&#39;: &#39;This text is natural, ... [[Good]]&#39;</span>
<span class="go">        },</span>
<span class="go">        {</span>
<span class="go">            &#39;llm_label&#39;: &#39;Bad&#39;,</span>
<span class="go">            &#39;llm_score&#39;: 0.0,</span>
<span class="go">            &#39;llm_label_input&#39;: &#39;Evaluate the quality of this text on a scale of Good/Bad.\n`Good mrrrning!`\nPut the label at the end like [[Good]].&#39;,</span>
<span class="go">            &#39;llm_label_output&#39;: &#39;This text contains a spelling error, ... [[Bad]]&#39;</span>
<span class="go">        }</span>
<span class="go">    ]</span>
<span class="go">)</span>
</code></pre></div>







              <details class="quote">
                <summary>Source code in <code>flexeval/core/metric/llm_label.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">ChatLLMLabel</span><span class="p">(</span><span class="n">Metric</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A metric that evaluates the output of `LanguageModel.batch_generate_chat_response`.</span>

<span class="sd">    Args:</span>
<span class="sd">        language_model: An instance of `LanguageModel` to evaluate the output of the model.</span>
<span class="sd">        prompt_template: An instance of `PromptTemplate` to embed the input for the evaluator.</span>
<span class="sd">        label_names: A list of valid label names.</span>
<span class="sd">        label_points: A list of points for each label specified in label_names.</span>
<span class="sd">        system_message: A system message to be prepended to the input for the evaluator.</span>
<span class="sd">        batch_size: The batch size for the evaluator.</span>
<span class="sd">        disable_tqdm: Whether to disable the progress bar.</span>
<span class="sd">        category_key: A key to create category-wise mean score.</span>
<span class="sd">            The category key is expected to be in task inputs.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from flexeval import ChatLLMScore, OpenAIChatAPI, Jinja2PromptTemplate</span>
<span class="sd">        &gt;&gt;&gt; language_model = OpenAIChatAPI(model_name=&quot;gpt-3.5-turbo&quot;)</span>
<span class="sd">        &gt;&gt;&gt; template = &quot;Evaluate the quality of this text on a scale of Good/Bad.\\n`{{ lm_output }}`\\nPut the label at the end like [[Good]].&quot;</span>
<span class="sd">        &gt;&gt;&gt; prompt_template = Jinja2PromptTemplate(template)</span>
<span class="sd">        &gt;&gt;&gt; system_message = &quot;This is the system message.&quot;</span>
<span class="sd">        &gt;&gt;&gt; label_names = [&quot;Good&quot;, &quot;Bad&quot;]</span>
<span class="sd">        &gt;&gt;&gt; label_points = [1.0, 0.0]</span>
<span class="sd">        &gt;&gt;&gt; llm_label = ChatLLMLabel(language_model, prompt_template, label_names, label_points)</span>
<span class="sd">        &gt;&gt;&gt; lm_outputs = [&quot;Hello, world!&quot;, &quot;Good morning!&quot;]</span>
<span class="sd">        &gt;&gt;&gt; result = llm_label.evaluate(lm_outputs)</span>
<span class="sd">        &gt;&gt;&gt; print(result)</span>
<span class="sd">        MetricResult(</span>
<span class="sd">            summary={&#39;llm_score&#39;: 0.5, &#39;llm_label_distribution&#39;: {&#39;Good&#39;: 0.5, &#39;Bad&#39;: 0.5}, &#39;num_failed_score_parses&#39;: 0},</span>
<span class="sd">            instance_details=[</span>
<span class="sd">                {</span>
<span class="sd">                    &#39;llm_label&#39;: &#39;Good&#39;,</span>
<span class="sd">                    &#39;llm_score&#39;: 1.0,</span>
<span class="sd">                    &#39;llm_label_input&#39;: &#39;Evaluate the quality of this text...&#39;,</span>
<span class="sd">                    &#39;llm_label_output&#39;: &#39;This text is natural, ... [[Good]]&#39;</span>
<span class="sd">                },</span>
<span class="sd">                {</span>
<span class="sd">                    &#39;llm_label&#39;: &#39;Bad&#39;,</span>
<span class="sd">                    &#39;llm_score&#39;: 0.0,</span>
<span class="sd">                    &#39;llm_label_input&#39;: &#39;Evaluate the quality of this text on a scale of Good/Bad.\\n`Good mrrrning!`\\nPut the label at the end like [[Good]].&#39;,</span>
<span class="sd">                    &#39;llm_label_output&#39;: &#39;This text contains a spelling error, ... [[Bad]]&#39;</span>
<span class="sd">                }</span>
<span class="sd">            ]</span>
<span class="sd">        )</span>
<span class="sd">    &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">language_model</span><span class="p">:</span> <span class="n">LanguageModel</span><span class="p">,</span>
        <span class="n">prompt_template</span><span class="p">:</span> <span class="n">PromptTemplate</span><span class="p">,</span>
        <span class="n">label_names</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">label_points</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">float</span> <span class="o">|</span> <span class="nb">int</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">system_message</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="n">PromptTemplate</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
        <span class="n">disable_tqdm</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">category_key</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">language_model</span> <span class="o">=</span> <span class="n">language_model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prompt_template</span> <span class="o">=</span> <span class="n">prompt_template</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">label_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">re</span><span class="o">.</span><span class="n">escape</span><span class="p">(</span><span class="n">label</span><span class="p">)</span> <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">label_names</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">label_points</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">label_names</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">label_points</span><span class="p">):</span>
                <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;The lengths of label_names and weights do not match.&quot;</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
            <span class="n">label_points</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="n">label_points</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">label_points</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">label_names</span><span class="p">)</span>
            <span class="n">label_points</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="n">label_points</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">system_message</span> <span class="o">=</span> <span class="n">system_message</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">disable_tqdm</span> <span class="o">=</span> <span class="n">disable_tqdm</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">category_key</span> <span class="o">=</span> <span class="n">category_key</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">lm_outputs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">references_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">task_inputs_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MetricResult</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">task_inputs_list</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">task_inputs_list</span> <span class="o">=</span> <span class="p">[{}</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">lm_outputs</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">references_list</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">references_list</span> <span class="o">=</span> <span class="p">[[]</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">lm_outputs</span><span class="p">]</span>

        <span class="n">evaluator_input_list</span> <span class="o">=</span> <span class="n">prepare_chat_input_for_evaluator</span><span class="p">(</span>
            <span class="n">lm_outputs</span><span class="p">,</span> <span class="n">references_list</span><span class="p">,</span> <span class="n">task_inputs_list</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompt_template</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">system_message</span>
        <span class="p">)</span>

        <span class="n">evaluator_output_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">LMOutput</span><span class="p">]</span> <span class="o">=</span> <span class="n">generate_evaluations</span><span class="p">(</span>
            <span class="n">evaluator_input_list</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">language_model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">disable_tqdm</span><span class="p">,</span> <span class="s2">&quot;Calculating ChatLLM score&quot;</span>
        <span class="p">)</span>

        <span class="n">evaluator_label_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">evaluator_output</span> <span class="ow">in</span> <span class="n">evaluator_output_list</span><span class="p">:</span>
            <span class="n">evaluator_label</span> <span class="o">=</span> <span class="n">parse_label_from_evaluator_output</span><span class="p">(</span>
                <span class="n">evaluator_output</span><span class="o">.</span><span class="n">text</span><span class="p">,</span>
                <span class="n">label_names</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">label_names</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="n">evaluator_label</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to parse label from evaluator output: </span><span class="si">{</span><span class="n">evaluator_output</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">evaluator_label_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">evaluator_label</span><span class="p">)</span>

        <span class="n">label2point</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">label_names</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">))</span>
        <span class="n">evaluator_score_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">float</span> <span class="o">|</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">label2point</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">label</span><span class="p">)</span> <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">evaluator_label_list</span><span class="p">]</span>

        <span class="n">summary</span> <span class="o">=</span> <span class="n">summarize_evaluator_labels</span><span class="p">(</span>
            <span class="n">evaluator_label_list</span><span class="p">,</span>
            <span class="n">task_inputs_list</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">label_names</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">category_key</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">MetricResult</span><span class="p">(</span>
            <span class="n">summary</span><span class="p">,</span>
            <span class="n">instance_details</span><span class="o">=</span><span class="p">[</span>
                <span class="p">{</span>
                    <span class="s2">&quot;llm_label&quot;</span><span class="p">:</span> <span class="n">eval_label</span><span class="p">,</span>
                    <span class="s2">&quot;llm_score&quot;</span><span class="p">:</span> <span class="n">eval_score</span><span class="p">,</span>
                    <span class="s2">&quot;llm_label_input&quot;</span><span class="p">:</span> <span class="n">eval_in</span><span class="p">,</span>
                    <span class="s2">&quot;llm_label_output&quot;</span><span class="p">:</span> <span class="n">eval_out</span><span class="o">.</span><span class="n">text</span><span class="p">,</span>
                <span class="p">}</span>
                <span class="k">for</span> <span class="n">eval_label</span><span class="p">,</span> <span class="n">eval_score</span><span class="p">,</span> <span class="n">eval_in</span><span class="p">,</span> <span class="n">eval_out</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
                    <span class="n">evaluator_label_list</span><span class="p">,</span>
                    <span class="n">evaluator_score_list</span><span class="p">,</span>
                    <span class="n">evaluator_input_list</span><span class="p">,</span>
                    <span class="n">evaluator_output_list</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="p">],</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">(language_model=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">language_model</span><span class="si">}</span><span class="s2">, prompt_template=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">prompt_template</span><span class="si">}</span><span class="s2">)&quot;</span>
        <span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.llm_label.ChatLLMLabel.language_model" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">language_model</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.llm_label.ChatLLMLabel.language_model" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">language_model</span> <span class="o">=</span> <span class="n">language_model</span>
</code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.llm_label.ChatLLMLabel.prompt_template" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">prompt_template</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.llm_label.ChatLLMLabel.prompt_template" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">prompt_template</span> <span class="o">=</span> <span class="n">prompt_template</span>
</code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.llm_label.ChatLLMLabel.label_names" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">label_names</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.llm_label.ChatLLMLabel.label_names" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">label_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">escape</span><span class="p">(</span><span class="n">label</span><span class="p">)</span> <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">label_names</span><span class="p">]</span>
</code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.llm_label.ChatLLMLabel.weights" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">weights</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.llm_label.ChatLLMLabel.weights" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">weights</span> <span class="o">=</span> <span class="n">label_points</span>
</code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.llm_label.ChatLLMLabel.system_message" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">system_message</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.llm_label.ChatLLMLabel.system_message" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">system_message</span> <span class="o">=</span> <span class="n">system_message</span>
</code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.llm_label.ChatLLMLabel.batch_size" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">batch_size</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.llm_label.ChatLLMLabel.batch_size" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
</code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.llm_label.ChatLLMLabel.disable_tqdm" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">disable_tqdm</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.llm_label.ChatLLMLabel.disable_tqdm" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">disable_tqdm</span> <span class="o">=</span> <span class="n">disable_tqdm</span>
</code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.llm_label.ChatLLMLabel.category_key" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">category_key</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.llm_label.ChatLLMLabel.category_key" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">category_key</span> <span class="o">=</span> <span class="n">category_key</span>
</code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>



<div class="doc doc-object doc-function">


<h3 id="flexeval.core.metric.llm_label.ChatLLMLabel.__init__" class="doc doc-heading">
            <span class="doc doc-object-name doc-function-name">__init__</span>


<a href="#flexeval.core.metric.llm_label.ChatLLMLabel.__init__" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="fm">__init__</span><span class="p">(</span>
    <span class="nf">language_model</span><span class="p">:</span> <span class="n">LanguageModel</span><span class="p">,</span>
    <span class="n">prompt_template</span><span class="p">:</span> <span class="n">PromptTemplate</span><span class="p">,</span>
    <span class="n">label_names</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">label_points</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">float</span> <span class="o">|</span> <span class="nb">int</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">system_message</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="n">PromptTemplate</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
    <span class="n">disable_tqdm</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">category_key</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>

    <div class="doc doc-contents ">


            <details class="quote">
              <summary>Source code in <code>flexeval/core/metric/llm_label.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">language_model</span><span class="p">:</span> <span class="n">LanguageModel</span><span class="p">,</span>
    <span class="n">prompt_template</span><span class="p">:</span> <span class="n">PromptTemplate</span><span class="p">,</span>
    <span class="n">label_names</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">label_points</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">float</span> <span class="o">|</span> <span class="nb">int</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">system_message</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="n">PromptTemplate</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
    <span class="n">disable_tqdm</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">category_key</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">language_model</span> <span class="o">=</span> <span class="n">language_model</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">prompt_template</span> <span class="o">=</span> <span class="n">prompt_template</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">label_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">re</span><span class="o">.</span><span class="n">escape</span><span class="p">(</span><span class="n">label</span><span class="p">)</span> <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">label_names</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">label_points</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">label_names</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">label_points</span><span class="p">):</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;The lengths of label_names and weights do not match.&quot;</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
        <span class="n">label_points</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="n">label_points</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">label_points</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">label_names</span><span class="p">)</span>
        <span class="n">label_points</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="n">label_points</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">system_message</span> <span class="o">=</span> <span class="n">system_message</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">disable_tqdm</span> <span class="o">=</span> <span class="n">disable_tqdm</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">category_key</span> <span class="o">=</span> <span class="n">category_key</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="flexeval.core.metric.llm_label.ChatLLMLabel.evaluate" class="doc doc-heading">
            <span class="doc doc-object-name doc-function-name">evaluate</span>


<a href="#flexeval.core.metric.llm_label.ChatLLMLabel.evaluate" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="nf">evaluate</span><span class="p">(</span>
    <span class="n">lm_outputs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">references_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">task_inputs_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MetricResult</span>
</code></pre></div>

    <div class="doc doc-contents ">


            <details class="quote">
              <summary>Source code in <code>flexeval/core/metric/llm_label.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">lm_outputs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">references_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">task_inputs_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MetricResult</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">task_inputs_list</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">task_inputs_list</span> <span class="o">=</span> <span class="p">[{}</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">lm_outputs</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">references_list</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">references_list</span> <span class="o">=</span> <span class="p">[[]</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">lm_outputs</span><span class="p">]</span>

    <span class="n">evaluator_input_list</span> <span class="o">=</span> <span class="n">prepare_chat_input_for_evaluator</span><span class="p">(</span>
        <span class="n">lm_outputs</span><span class="p">,</span> <span class="n">references_list</span><span class="p">,</span> <span class="n">task_inputs_list</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompt_template</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">system_message</span>
    <span class="p">)</span>

    <span class="n">evaluator_output_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">LMOutput</span><span class="p">]</span> <span class="o">=</span> <span class="n">generate_evaluations</span><span class="p">(</span>
        <span class="n">evaluator_input_list</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">language_model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">disable_tqdm</span><span class="p">,</span> <span class="s2">&quot;Calculating ChatLLM score&quot;</span>
    <span class="p">)</span>

    <span class="n">evaluator_label_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">evaluator_output</span> <span class="ow">in</span> <span class="n">evaluator_output_list</span><span class="p">:</span>
        <span class="n">evaluator_label</span> <span class="o">=</span> <span class="n">parse_label_from_evaluator_output</span><span class="p">(</span>
            <span class="n">evaluator_output</span><span class="o">.</span><span class="n">text</span><span class="p">,</span>
            <span class="n">label_names</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">label_names</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">evaluator_label</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to parse label from evaluator output: </span><span class="si">{</span><span class="n">evaluator_output</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">evaluator_label_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">evaluator_label</span><span class="p">)</span>

    <span class="n">label2point</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">label_names</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">))</span>
    <span class="n">evaluator_score_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">float</span> <span class="o">|</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">label2point</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">label</span><span class="p">)</span> <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">evaluator_label_list</span><span class="p">]</span>

    <span class="n">summary</span> <span class="o">=</span> <span class="n">summarize_evaluator_labels</span><span class="p">(</span>
        <span class="n">evaluator_label_list</span><span class="p">,</span>
        <span class="n">task_inputs_list</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">label_names</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">category_key</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">MetricResult</span><span class="p">(</span>
        <span class="n">summary</span><span class="p">,</span>
        <span class="n">instance_details</span><span class="o">=</span><span class="p">[</span>
            <span class="p">{</span>
                <span class="s2">&quot;llm_label&quot;</span><span class="p">:</span> <span class="n">eval_label</span><span class="p">,</span>
                <span class="s2">&quot;llm_score&quot;</span><span class="p">:</span> <span class="n">eval_score</span><span class="p">,</span>
                <span class="s2">&quot;llm_label_input&quot;</span><span class="p">:</span> <span class="n">eval_in</span><span class="p">,</span>
                <span class="s2">&quot;llm_label_output&quot;</span><span class="p">:</span> <span class="n">eval_out</span><span class="o">.</span><span class="n">text</span><span class="p">,</span>
            <span class="p">}</span>
            <span class="k">for</span> <span class="n">eval_label</span><span class="p">,</span> <span class="n">eval_score</span><span class="p">,</span> <span class="n">eval_in</span><span class="p">,</span> <span class="n">eval_out</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
                <span class="n">evaluator_label_list</span><span class="p">,</span>
                <span class="n">evaluator_score_list</span><span class="p">,</span>
                <span class="n">evaluator_input_list</span><span class="p">,</span>
                <span class="n">evaluator_output_list</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">],</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="flexeval.core.metric.llm_label.ChatLLMLabel.__repr__" class="doc doc-heading">
            <span class="doc doc-object-name doc-function-name">__repr__</span>


<a href="#flexeval.core.metric.llm_label.ChatLLMLabel.__repr__" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="fm">__repr__</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="nb">str</span>
</code></pre></div>

    <div class="doc doc-contents ">


            <details class="quote">
              <summary>Source code in <code>flexeval/core/metric/llm_label.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="k">return</span> <span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">(language_model=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">language_model</span><span class="si">}</span><span class="s2">, prompt_template=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">prompt_template</span><span class="si">}</span><span class="s2">)&quot;</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="flexeval.core.metric.llm_label.LLMLabel" class="doc doc-heading">
            <span class="doc doc-object-name doc-class-name">LLMLabel</span>


<a href="#flexeval.core.metric.llm_label.LLMLabel" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents first">


        <p>Let LanguageModel to evaluate the output of another LanguageModel.</p>
<p>You can specify the evaluation criteria in <code>PromptTemplate</code>.
The last label value found in the output of the evaluator is used to compute the evaluation score.
You can assign a score to each label.
The final output is the average score and the distribution of the labels.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>language_model</code></b>
              (<code><a class="autorefs autorefs-internal" title="LanguageModel (flexeval.core.language_model.LanguageModel)" href="../LMOutput/#flexeval.core.language_model.base.LanguageModel">LanguageModel</a></code>)
          –
          <div class="doc-md-description">
            <p>An instance of <code>LanguageModel</code> to evaluate the output of the model.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>prompt_template</code></b>
              (<code><a class="autorefs autorefs-internal" title="PromptTemplate (flexeval.core.prompt_template.PromptTemplate)" href="../PromptTemplate/#flexeval.core.prompt_template.base.PromptTemplate">PromptTemplate</a></code>)
          –
          <div class="doc-md-description">
            <p>An instance of <code>PromptTemplate</code> to embed the input for the evaluator.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>label_names</code></b>
              (<code><span title="list">list</span>[<span title="str">str</span>]</code>)
          –
          <div class="doc-md-description">
            <p>A list of valid label names.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>label_points</code></b>
              (<code><span title="list">list</span>[<span title="float">float</span> | <span title="int">int</span>] | None</code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>A list of points for each label specified in label_names.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>batch_size</code></b>
              (<code><span title="int">int</span></code>, default:
                  <code>4</code>
)
          –
          <div class="doc-md-description">
            <p>The batch size for the evaluator.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>disable_tqdm</code></b>
              (<code><span title="bool">bool</span></code>, default:
                  <code>False</code>
)
          –
          <div class="doc-md-description">
            <p>Whether to disable the progress bar.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>category_key</code></b>
              (<code><span title="str">str</span> | None</code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>A key to create category-wise mean score.
The category key is expected to be in task inputs.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">flexeval</span><span class="w"> </span><span class="kn">import</span> <span class="n">OpenAIChatAPI</span><span class="p">,</span> <span class="n">Jinja2PromptTemplate</span><span class="p">,</span> <span class="n">LLMLabel</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">language_model</span> <span class="o">=</span> <span class="n">OpenAIChatAPI</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-3.5-turbo&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">template</span> <span class="o">=</span> <span class="s2">&quot;Evaluate the quality of this text on a scale of Good/Bad.</span><span class="se">\n</span><span class="s2">`{{ lm_output }}`</span><span class="se">\n</span><span class="s2">Put the label at the end like [[Good]].&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">prompt_template</span> <span class="o">=</span> <span class="n">Jinja2PromptTemplate</span><span class="p">(</span><span class="n">template</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">label_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Good&quot;</span><span class="p">,</span> <span class="s2">&quot;Bad&quot;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">label_points</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">llm_label</span> <span class="o">=</span> <span class="n">LLMLabel</span><span class="p">(</span><span class="n">language_model</span><span class="p">,</span> <span class="n">prompt_template</span><span class="p">,</span> <span class="n">label_names</span><span class="p">,</span> <span class="n">label_points</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lm_outputs</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Hello, world!&quot;</span><span class="p">,</span> <span class="s2">&quot;Good mrrrning!&quot;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">llm_label</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">lm_outputs</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
<span class="go">MetricResult(</span>
<span class="go">    summary={&#39;llm_score&#39;: 0.5, &#39;llm_label_distribution&#39;: {&#39;Good&#39;: 0.5, &#39;Bad&#39;: 0.5}, &#39;num_failed_score_parses&#39;: 0},</span>
<span class="go">    instance_details=[</span>
<span class="go">        {</span>
<span class="go">            &#39;llm_label&#39;: &#39;Good&#39;,</span>
<span class="go">            &#39;llm_score&#39;: 1.0,</span>
<span class="go">            &#39;llm_label_input&#39;: &#39;Evaluate the quality of this text...&#39;,</span>
<span class="go">            &#39;llm_label_output&#39;: &#39;This text is natural, ... [[Good]]&#39;</span>
<span class="go">        },</span>
<span class="go">        {</span>
<span class="go">            &#39;llm_label&#39;: &#39;Bad&#39;,</span>
<span class="go">            &#39;llm_score&#39;: 0.0,</span>
<span class="go">            &#39;llm_label_input&#39;: &#39;Evaluate the quality of this text on a scale of Good/Bad.\n`Good mrrrning!`\nPut the label at the end like [[Good]].&#39;,</span>
<span class="go">            &#39;llm_label_output&#39;: &#39;This text contains a spelling error, ... [[Bad]]&#39;</span>
<span class="go">        }</span>
<span class="go">    ]</span>
<span class="go">)</span>
</code></pre></div>







              <details class="quote">
                <summary>Source code in <code>flexeval/core/metric/llm_label.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">LLMLabel</span><span class="p">(</span><span class="n">Metric</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Let LanguageModel to evaluate the output of another LanguageModel.</span>

<span class="sd">    You can specify the evaluation criteria in `PromptTemplate`.</span>
<span class="sd">    The last label value found in the output of the evaluator is used to compute the evaluation score.</span>
<span class="sd">    You can assign a score to each label.</span>
<span class="sd">    The final output is the average score and the distribution of the labels.</span>

<span class="sd">    Args:</span>
<span class="sd">        language_model: An instance of `LanguageModel` to evaluate the output of the model.</span>
<span class="sd">        prompt_template: An instance of `PromptTemplate` to embed the input for the evaluator.</span>
<span class="sd">        label_names: A list of valid label names.</span>
<span class="sd">        label_points: A list of points for each label specified in label_names.</span>
<span class="sd">        batch_size: The batch size for the evaluator.</span>
<span class="sd">        disable_tqdm: Whether to disable the progress bar.</span>
<span class="sd">        category_key: A key to create category-wise mean score.</span>
<span class="sd">            The category key is expected to be in task inputs.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from flexeval import OpenAIChatAPI, Jinja2PromptTemplate, LLMLabel</span>
<span class="sd">        &gt;&gt;&gt; language_model = OpenAIChatAPI(model=&quot;gpt-3.5-turbo&quot;)</span>
<span class="sd">        &gt;&gt;&gt; template = &quot;Evaluate the quality of this text on a scale of Good/Bad.\\n`{{ lm_output }}`\\nPut the label at the end like [[Good]].&quot;</span>
<span class="sd">        &gt;&gt;&gt; prompt_template = Jinja2PromptTemplate(template)</span>
<span class="sd">        &gt;&gt;&gt; label_names = [&quot;Good&quot;, &quot;Bad&quot;]</span>
<span class="sd">        &gt;&gt;&gt; label_points = [1.0, 0.0]</span>
<span class="sd">        &gt;&gt;&gt; llm_label = LLMLabel(language_model, prompt_template, label_names, label_points)</span>
<span class="sd">        &gt;&gt;&gt; lm_outputs = [&quot;Hello, world!&quot;, &quot;Good mrrrning!&quot;]</span>
<span class="sd">        &gt;&gt;&gt; result = llm_label.evaluate(lm_outputs)</span>
<span class="sd">        &gt;&gt;&gt; print(result)</span>
<span class="sd">        MetricResult(</span>
<span class="sd">            summary={&#39;llm_score&#39;: 0.5, &#39;llm_label_distribution&#39;: {&#39;Good&#39;: 0.5, &#39;Bad&#39;: 0.5}, &#39;num_failed_score_parses&#39;: 0},</span>
<span class="sd">            instance_details=[</span>
<span class="sd">                {</span>
<span class="sd">                    &#39;llm_label&#39;: &#39;Good&#39;,</span>
<span class="sd">                    &#39;llm_score&#39;: 1.0,</span>
<span class="sd">                    &#39;llm_label_input&#39;: &#39;Evaluate the quality of this text...&#39;,</span>
<span class="sd">                    &#39;llm_label_output&#39;: &#39;This text is natural, ... [[Good]]&#39;</span>
<span class="sd">                },</span>
<span class="sd">                {</span>
<span class="sd">                    &#39;llm_label&#39;: &#39;Bad&#39;,</span>
<span class="sd">                    &#39;llm_score&#39;: 0.0,</span>
<span class="sd">                    &#39;llm_label_input&#39;: &#39;Evaluate the quality of this text on a scale of Good/Bad.\\n`Good mrrrning!`\\nPut the label at the end like [[Good]].&#39;,</span>
<span class="sd">                    &#39;llm_label_output&#39;: &#39;This text contains a spelling error, ... [[Bad]]&#39;</span>
<span class="sd">                }</span>
<span class="sd">            ]</span>
<span class="sd">        )</span>
<span class="sd">    &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">language_model</span><span class="p">:</span> <span class="n">LanguageModel</span><span class="p">,</span>
        <span class="n">prompt_template</span><span class="p">:</span> <span class="n">PromptTemplate</span><span class="p">,</span>
        <span class="n">label_names</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">label_points</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">float</span> <span class="o">|</span> <span class="nb">int</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
        <span class="n">disable_tqdm</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">valid_score_range</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">category_key</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">language_model</span> <span class="o">=</span> <span class="n">language_model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prompt_template</span> <span class="o">=</span> <span class="n">prompt_template</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">label_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">re</span><span class="o">.</span><span class="n">escape</span><span class="p">(</span><span class="n">label</span><span class="p">)</span> <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">label_names</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">label_points</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">label_names</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">label_points</span><span class="p">):</span>
                <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;The lengths of label_names and weights do not match.&quot;</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
            <span class="n">label_points</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="n">label_points</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">label_points</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">label_names</span><span class="p">)</span>
            <span class="n">label_points</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="n">label_points</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">disable_tqdm</span> <span class="o">=</span> <span class="n">disable_tqdm</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">valid_score_range</span> <span class="o">=</span> <span class="n">valid_score_range</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">category_key</span> <span class="o">=</span> <span class="n">category_key</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">lm_outputs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">references_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">task_inputs_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MetricResult</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">task_inputs_list</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">task_inputs_list</span> <span class="o">=</span> <span class="p">[{}</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">lm_outputs</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">references_list</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">references_list</span> <span class="o">=</span> <span class="p">[[]</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">lm_outputs</span><span class="p">]</span>

        <span class="n">evaluator_input_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">prepare_text_input_for_evaluator</span><span class="p">(</span>
            <span class="n">lm_outputs</span><span class="p">,</span> <span class="n">references_list</span><span class="p">,</span> <span class="n">task_inputs_list</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompt_template</span>
        <span class="p">)</span>
        <span class="n">evaluator_output_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">LMOutput</span><span class="p">]</span> <span class="o">=</span> <span class="n">generate_evaluations</span><span class="p">(</span>
            <span class="n">evaluator_input_list</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">language_model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">disable_tqdm</span><span class="p">,</span> <span class="s2">&quot;Calculating LLM score&quot;</span>
        <span class="p">)</span>

        <span class="n">evaluator_label_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">evaluator_output</span> <span class="ow">in</span> <span class="n">evaluator_output_list</span><span class="p">:</span>
            <span class="n">evaluator_label</span> <span class="o">=</span> <span class="n">parse_label_from_evaluator_output</span><span class="p">(</span>
                <span class="n">evaluator_output</span><span class="o">.</span><span class="n">text</span><span class="p">,</span>
                <span class="n">label_names</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">label_names</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="n">evaluator_label</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to parse label from evaluator output: </span><span class="si">{</span><span class="n">evaluator_output</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">evaluator_label_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">evaluator_label</span><span class="p">)</span>

        <span class="n">label2point</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">label_names</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">))</span>
        <span class="n">evaluator_score_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">float</span> <span class="o">|</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">label2point</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">label</span><span class="p">)</span> <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">evaluator_label_list</span><span class="p">]</span>

        <span class="n">summary</span> <span class="o">=</span> <span class="n">summarize_evaluator_labels</span><span class="p">(</span>
            <span class="n">evaluator_label_list</span><span class="p">,</span>
            <span class="n">task_inputs_list</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">label_names</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">category_key</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">MetricResult</span><span class="p">(</span>
            <span class="n">summary</span><span class="p">,</span>
            <span class="n">instance_details</span><span class="o">=</span><span class="p">[</span>
                <span class="p">{</span>
                    <span class="s2">&quot;llm_label&quot;</span><span class="p">:</span> <span class="n">eval_label</span><span class="p">,</span>
                    <span class="s2">&quot;llm_score&quot;</span><span class="p">:</span> <span class="n">eval_score</span><span class="p">,</span>
                    <span class="s2">&quot;llm_label_input&quot;</span><span class="p">:</span> <span class="n">eval_in</span><span class="p">,</span>
                    <span class="s2">&quot;llm_label_output&quot;</span><span class="p">:</span> <span class="n">eval_out</span><span class="o">.</span><span class="n">text</span><span class="p">,</span>
                <span class="p">}</span>
                <span class="k">for</span> <span class="n">eval_label</span><span class="p">,</span> <span class="n">eval_score</span><span class="p">,</span> <span class="n">eval_in</span><span class="p">,</span> <span class="n">eval_out</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
                    <span class="n">evaluator_label_list</span><span class="p">,</span>
                    <span class="n">evaluator_score_list</span><span class="p">,</span>
                    <span class="n">evaluator_input_list</span><span class="p">,</span>
                    <span class="n">evaluator_output_list</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="p">],</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">(language_model=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">language_model</span><span class="si">}</span><span class="s2">, prompt_template=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">prompt_template</span><span class="si">}</span><span class="s2">)&quot;</span>
        <span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.llm_label.LLMLabel.language_model" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">language_model</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.llm_label.LLMLabel.language_model" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">language_model</span> <span class="o">=</span> <span class="n">language_model</span>
</code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.llm_label.LLMLabel.prompt_template" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">prompt_template</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.llm_label.LLMLabel.prompt_template" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">prompt_template</span> <span class="o">=</span> <span class="n">prompt_template</span>
</code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.llm_label.LLMLabel.label_names" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">label_names</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.llm_label.LLMLabel.label_names" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">label_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">escape</span><span class="p">(</span><span class="n">label</span><span class="p">)</span> <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">label_names</span><span class="p">]</span>
</code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.llm_label.LLMLabel.weights" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">weights</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.llm_label.LLMLabel.weights" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">weights</span> <span class="o">=</span> <span class="n">label_points</span>
</code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.llm_label.LLMLabel.batch_size" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">batch_size</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.llm_label.LLMLabel.batch_size" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
</code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.llm_label.LLMLabel.disable_tqdm" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">disable_tqdm</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.llm_label.LLMLabel.disable_tqdm" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">disable_tqdm</span> <span class="o">=</span> <span class="n">disable_tqdm</span>
</code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.llm_label.LLMLabel.valid_score_range" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">valid_score_range</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.llm_label.LLMLabel.valid_score_range" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">valid_score_range</span> <span class="o">=</span> <span class="n">valid_score_range</span>
</code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.llm_label.LLMLabel.category_key" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">category_key</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.llm_label.LLMLabel.category_key" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">category_key</span> <span class="o">=</span> <span class="n">category_key</span>
</code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>



<div class="doc doc-object doc-function">


<h3 id="flexeval.core.metric.llm_label.LLMLabel.__init__" class="doc doc-heading">
            <span class="doc doc-object-name doc-function-name">__init__</span>


<a href="#flexeval.core.metric.llm_label.LLMLabel.__init__" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="fm">__init__</span><span class="p">(</span>
    <span class="nf">language_model</span><span class="p">:</span> <span class="n">LanguageModel</span><span class="p">,</span>
    <span class="n">prompt_template</span><span class="p">:</span> <span class="n">PromptTemplate</span><span class="p">,</span>
    <span class="n">label_names</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">label_points</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">float</span> <span class="o">|</span> <span class="nb">int</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
    <span class="n">disable_tqdm</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">valid_score_range</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">category_key</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>

    <div class="doc doc-contents ">


            <details class="quote">
              <summary>Source code in <code>flexeval/core/metric/llm_label.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">language_model</span><span class="p">:</span> <span class="n">LanguageModel</span><span class="p">,</span>
    <span class="n">prompt_template</span><span class="p">:</span> <span class="n">PromptTemplate</span><span class="p">,</span>
    <span class="n">label_names</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">label_points</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">float</span> <span class="o">|</span> <span class="nb">int</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
    <span class="n">disable_tqdm</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">valid_score_range</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">category_key</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">language_model</span> <span class="o">=</span> <span class="n">language_model</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">prompt_template</span> <span class="o">=</span> <span class="n">prompt_template</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">label_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">re</span><span class="o">.</span><span class="n">escape</span><span class="p">(</span><span class="n">label</span><span class="p">)</span> <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">label_names</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">label_points</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">label_names</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">label_points</span><span class="p">):</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;The lengths of label_names and weights do not match.&quot;</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
        <span class="n">label_points</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="n">label_points</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">label_points</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">label_names</span><span class="p">)</span>
        <span class="n">label_points</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="n">label_points</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">disable_tqdm</span> <span class="o">=</span> <span class="n">disable_tqdm</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">valid_score_range</span> <span class="o">=</span> <span class="n">valid_score_range</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">category_key</span> <span class="o">=</span> <span class="n">category_key</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="flexeval.core.metric.llm_label.LLMLabel.evaluate" class="doc doc-heading">
            <span class="doc doc-object-name doc-function-name">evaluate</span>


<a href="#flexeval.core.metric.llm_label.LLMLabel.evaluate" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="nf">evaluate</span><span class="p">(</span>
    <span class="n">lm_outputs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">references_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">task_inputs_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MetricResult</span>
</code></pre></div>

    <div class="doc doc-contents ">


            <details class="quote">
              <summary>Source code in <code>flexeval/core/metric/llm_label.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">lm_outputs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">references_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">task_inputs_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MetricResult</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">task_inputs_list</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">task_inputs_list</span> <span class="o">=</span> <span class="p">[{}</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">lm_outputs</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">references_list</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">references_list</span> <span class="o">=</span> <span class="p">[[]</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">lm_outputs</span><span class="p">]</span>

    <span class="n">evaluator_input_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">prepare_text_input_for_evaluator</span><span class="p">(</span>
        <span class="n">lm_outputs</span><span class="p">,</span> <span class="n">references_list</span><span class="p">,</span> <span class="n">task_inputs_list</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompt_template</span>
    <span class="p">)</span>
    <span class="n">evaluator_output_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">LMOutput</span><span class="p">]</span> <span class="o">=</span> <span class="n">generate_evaluations</span><span class="p">(</span>
        <span class="n">evaluator_input_list</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">language_model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">disable_tqdm</span><span class="p">,</span> <span class="s2">&quot;Calculating LLM score&quot;</span>
    <span class="p">)</span>

    <span class="n">evaluator_label_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">evaluator_output</span> <span class="ow">in</span> <span class="n">evaluator_output_list</span><span class="p">:</span>
        <span class="n">evaluator_label</span> <span class="o">=</span> <span class="n">parse_label_from_evaluator_output</span><span class="p">(</span>
            <span class="n">evaluator_output</span><span class="o">.</span><span class="n">text</span><span class="p">,</span>
            <span class="n">label_names</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">label_names</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">evaluator_label</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to parse label from evaluator output: </span><span class="si">{</span><span class="n">evaluator_output</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">evaluator_label_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">evaluator_label</span><span class="p">)</span>

    <span class="n">label2point</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">label_names</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">))</span>
    <span class="n">evaluator_score_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">float</span> <span class="o">|</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">label2point</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">label</span><span class="p">)</span> <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">evaluator_label_list</span><span class="p">]</span>

    <span class="n">summary</span> <span class="o">=</span> <span class="n">summarize_evaluator_labels</span><span class="p">(</span>
        <span class="n">evaluator_label_list</span><span class="p">,</span>
        <span class="n">task_inputs_list</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">label_names</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">category_key</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">MetricResult</span><span class="p">(</span>
        <span class="n">summary</span><span class="p">,</span>
        <span class="n">instance_details</span><span class="o">=</span><span class="p">[</span>
            <span class="p">{</span>
                <span class="s2">&quot;llm_label&quot;</span><span class="p">:</span> <span class="n">eval_label</span><span class="p">,</span>
                <span class="s2">&quot;llm_score&quot;</span><span class="p">:</span> <span class="n">eval_score</span><span class="p">,</span>
                <span class="s2">&quot;llm_label_input&quot;</span><span class="p">:</span> <span class="n">eval_in</span><span class="p">,</span>
                <span class="s2">&quot;llm_label_output&quot;</span><span class="p">:</span> <span class="n">eval_out</span><span class="o">.</span><span class="n">text</span><span class="p">,</span>
            <span class="p">}</span>
            <span class="k">for</span> <span class="n">eval_label</span><span class="p">,</span> <span class="n">eval_score</span><span class="p">,</span> <span class="n">eval_in</span><span class="p">,</span> <span class="n">eval_out</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
                <span class="n">evaluator_label_list</span><span class="p">,</span>
                <span class="n">evaluator_score_list</span><span class="p">,</span>
                <span class="n">evaluator_input_list</span><span class="p">,</span>
                <span class="n">evaluator_output_list</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">],</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="flexeval.core.metric.llm_label.LLMLabel.__repr__" class="doc doc-heading">
            <span class="doc doc-object-name doc-function-name">__repr__</span>


<a href="#flexeval.core.metric.llm_label.LLMLabel.__repr__" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="fm">__repr__</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="nb">str</span>
</code></pre></div>

    <div class="doc doc-contents ">


            <details class="quote">
              <summary>Source code in <code>flexeval/core/metric/llm_label.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="k">return</span> <span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">(language_model=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">language_model</span><span class="si">}</span><span class="s2">, prompt_template=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">prompt_template</span><span class="si">}</span><span class="s2">)&quot;</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="flexeval.core.metric.llm_score.ChatLLMScore" class="doc doc-heading">
            <span class="doc doc-object-name doc-class-name">ChatLLMScore</span>


<a href="#flexeval.core.metric.llm_score.ChatLLMScore" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents first">


        <p>A metric that evaluates the output of <code>LanguageModel.batch_generate_chat_response</code>.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>language_model</code></b>
              (<code><a class="autorefs autorefs-internal" title="LanguageModel (flexeval.core.language_model.LanguageModel)" href="../LMOutput/#flexeval.core.language_model.base.LanguageModel">LanguageModel</a></code>)
          –
          <div class="doc-md-description">
            <p>An instance of <code>LanguageModel</code> to evaluate the output of the model.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>prompt_template</code></b>
              (<code><a class="autorefs autorefs-internal" title="PromptTemplate (flexeval.core.prompt_template.PromptTemplate)" href="../PromptTemplate/#flexeval.core.prompt_template.base.PromptTemplate">PromptTemplate</a></code>)
          –
          <div class="doc-md-description">
            <p>An instance of <code>PromptTemplate</code> to embed the input for the evaluator.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>system_message</code></b>
              (<code><span title="str">str</span> | <a class="autorefs autorefs-internal" title="PromptTemplate (flexeval.core.prompt_template.PromptTemplate)" href="../PromptTemplate/#flexeval.core.prompt_template.base.PromptTemplate">PromptTemplate</a> | None</code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>A system message to be prepended to the input for the evaluator.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>batch_size</code></b>
              (<code><span title="int">int</span></code>, default:
                  <code>4</code>
)
          –
          <div class="doc-md-description">
            <p>The batch size for the evaluator.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>disable_tqdm</code></b>
              (<code><span title="bool">bool</span></code>, default:
                  <code>False</code>
)
          –
          <div class="doc-md-description">
            <p>Whether to disable the progress bar.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>valid_score_range</code></b>
              (<code><span title="tuple">tuple</span>[<span title="int">int</span>, <span title="int">int</span>] | None</code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>A tuple of two integers representing the valid score range.
If the parsed score is out of the range, it will be ignored.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>category_key</code></b>
              (<code><span title="str">str</span> | None</code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>A key to create category-wise mean score.
The category key is expected to be in task inputs.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">flexeval</span><span class="w"> </span><span class="kn">import</span> <span class="n">ChatLLMScore</span><span class="p">,</span> <span class="n">OpenAIChatAPI</span><span class="p">,</span> <span class="n">Jinja2PromptTemplate</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">language_model</span> <span class="o">=</span> <span class="n">OpenAIChatAPI</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;gpt-3.5-turbo&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">template</span> <span class="o">=</span> <span class="s2">&quot;Evaluate the quality of this text.</span><span class="se">\n</span><span class="s2">`{{ lm_output }}`</span><span class="se">\n</span><span class="s2">Put the score at the end like [[5]].&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">prompt_template</span> <span class="o">=</span> <span class="n">Jinja2PromptTemplate</span><span class="p">(</span><span class="n">template</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">system_message</span> <span class="o">=</span> <span class="s2">&quot;This is the system message.&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">llm_score</span> <span class="o">=</span> <span class="n">ChatLLMScore</span><span class="p">(</span><span class="n">language_model</span><span class="p">,</span> <span class="n">prompt_template</span><span class="p">,</span> <span class="n">system_message</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lm_outputs</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Hello, world!&quot;</span><span class="p">,</span> <span class="s2">&quot;Good morning!&quot;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">llm_score</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">lm_outputs</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
<span class="go">MetricResult(</span>
<span class="go">    summary={&#39;llm_score&#39;: 3.0, &#39;num_failed_score_parses&#39;: 0},</span>
<span class="go">    instance_details=[</span>
<span class="go">        {</span>
<span class="go">            &#39;llm_score&#39;: 2,</span>
<span class="go">            &#39;llm_score_input&#39;: [{&#39;role&#39;: &#39;user&#39;, &#39;content&#39;: &#39;Evaluate the quality of this text...&#39;}],</span>
<span class="go">            &#39;llm_score_output&#39;: &#39;This text is very simple,... Therefore, its quality is average. [[2]]&#39;},</span>
<span class="go">        {</span>
<span class="go">            &#39;llm_score&#39;: 4,</span>
<span class="go">            &#39;llm_score_input&#39;: [{&#39;role&#39;: &#39;user&#39;, &#39;content&#39;: &#39;Evaluate the quality of this text...&#39;}],</span>
<span class="go">            &#39;llm_score_output&#39;: &#39;... Overall, the quality of the text is good but basic. [[4]]&#39;}</span>
<span class="go">    ]</span>
<span class="go">)</span>
</code></pre></div>







              <details class="quote">
                <summary>Source code in <code>flexeval/core/metric/llm_score.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">ChatLLMScore</span><span class="p">(</span><span class="n">Metric</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A metric that evaluates the output of `LanguageModel.batch_generate_chat_response`.</span>

<span class="sd">    Args:</span>
<span class="sd">        language_model: An instance of `LanguageModel` to evaluate the output of the model.</span>
<span class="sd">        prompt_template: An instance of `PromptTemplate` to embed the input for the evaluator.</span>
<span class="sd">        system_message: A system message to be prepended to the input for the evaluator.</span>
<span class="sd">        batch_size: The batch size for the evaluator.</span>
<span class="sd">        disable_tqdm: Whether to disable the progress bar.</span>
<span class="sd">        valid_score_range: A tuple of two integers representing the valid score range.</span>
<span class="sd">            If the parsed score is out of the range, it will be ignored.</span>
<span class="sd">        category_key: A key to create category-wise mean score.</span>
<span class="sd">            The category key is expected to be in task inputs.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from flexeval import ChatLLMScore, OpenAIChatAPI, Jinja2PromptTemplate</span>
<span class="sd">        &gt;&gt;&gt; language_model = OpenAIChatAPI(model_name=&quot;gpt-3.5-turbo&quot;)</span>
<span class="sd">        &gt;&gt;&gt; template = &quot;Evaluate the quality of this text.\\n`{{ lm_output }}`\\nPut the score at the end like [[5]].&quot;</span>
<span class="sd">        &gt;&gt;&gt; prompt_template = Jinja2PromptTemplate(template)</span>
<span class="sd">        &gt;&gt;&gt; system_message = &quot;This is the system message.&quot;</span>
<span class="sd">        &gt;&gt;&gt; llm_score = ChatLLMScore(language_model, prompt_template, system_message)</span>
<span class="sd">        &gt;&gt;&gt; lm_outputs = [&quot;Hello, world!&quot;, &quot;Good morning!&quot;]</span>
<span class="sd">        &gt;&gt;&gt; result = llm_score.evaluate(lm_outputs)</span>
<span class="sd">        &gt;&gt;&gt; print(result)</span>
<span class="sd">        MetricResult(</span>
<span class="sd">            summary={&#39;llm_score&#39;: 3.0, &#39;num_failed_score_parses&#39;: 0},</span>
<span class="sd">            instance_details=[</span>
<span class="sd">                {</span>
<span class="sd">                    &#39;llm_score&#39;: 2,</span>
<span class="sd">                    &#39;llm_score_input&#39;: [{&#39;role&#39;: &#39;user&#39;, &#39;content&#39;: &#39;Evaluate the quality of this text...&#39;}],</span>
<span class="sd">                    &#39;llm_score_output&#39;: &#39;This text is very simple,... Therefore, its quality is average. [[2]]&#39;},</span>
<span class="sd">                {</span>
<span class="sd">                    &#39;llm_score&#39;: 4,</span>
<span class="sd">                    &#39;llm_score_input&#39;: [{&#39;role&#39;: &#39;user&#39;, &#39;content&#39;: &#39;Evaluate the quality of this text...&#39;}],</span>
<span class="sd">                    &#39;llm_score_output&#39;: &#39;... Overall, the quality of the text is good but basic. [[4]]&#39;}</span>
<span class="sd">            ]</span>
<span class="sd">        )</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">language_model</span><span class="p">:</span> <span class="n">LanguageModel</span><span class="p">,</span>
        <span class="n">prompt_template</span><span class="p">:</span> <span class="n">PromptTemplate</span><span class="p">,</span>
        <span class="n">system_message</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="n">PromptTemplate</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
        <span class="n">disable_tqdm</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">valid_score_range</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">category_key</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">language_model</span> <span class="o">=</span> <span class="n">language_model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prompt_template</span> <span class="o">=</span> <span class="n">prompt_template</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">system_message</span> <span class="o">=</span> <span class="n">system_message</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">disable_tqdm</span> <span class="o">=</span> <span class="n">disable_tqdm</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">valid_score_range</span> <span class="o">=</span> <span class="n">valid_score_range</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">category_key</span> <span class="o">=</span> <span class="n">category_key</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">lm_outputs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">references_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">task_inputs_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MetricResult</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">task_inputs_list</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">task_inputs_list</span> <span class="o">=</span> <span class="p">[{}</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">lm_outputs</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">references_list</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">references_list</span> <span class="o">=</span> <span class="p">[[]</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">lm_outputs</span><span class="p">]</span>

        <span class="n">evaluator_input_list</span> <span class="o">=</span> <span class="n">prepare_chat_input_for_evaluator</span><span class="p">(</span>
            <span class="n">lm_outputs</span><span class="p">,</span> <span class="n">references_list</span><span class="p">,</span> <span class="n">task_inputs_list</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompt_template</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">system_message</span>
        <span class="p">)</span>
        <span class="n">evaluator_output_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">LMOutput</span><span class="p">]</span> <span class="o">=</span> <span class="n">generate_evaluations</span><span class="p">(</span>
            <span class="n">evaluator_input_list</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">language_model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">disable_tqdm</span><span class="p">,</span> <span class="s2">&quot;Calculating ChatLLM score&quot;</span>
        <span class="p">)</span>

        <span class="n">evaluator_score_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">evaluator_output</span> <span class="ow">in</span> <span class="n">evaluator_output_list</span><span class="p">:</span>
            <span class="n">evaluator_score</span> <span class="o">=</span> <span class="n">parse_score_from_evaluator_output</span><span class="p">(</span>
                <span class="n">evaluator_output</span><span class="o">.</span><span class="n">text</span><span class="p">,</span>
                <span class="n">valid_score_range</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">valid_score_range</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="n">evaluator_score</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to parse score from evaluator output: </span><span class="si">{</span><span class="n">evaluator_output</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">evaluator_score_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">evaluator_score</span><span class="p">)</span>

        <span class="n">summary</span> <span class="o">=</span> <span class="n">summarize_evaluator_scores</span><span class="p">(</span>
            <span class="n">evaluator_score_list</span><span class="p">,</span>
            <span class="n">task_inputs_list</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">category_key</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">MetricResult</span><span class="p">(</span>
            <span class="n">summary</span><span class="p">,</span>
            <span class="n">instance_details</span><span class="o">=</span><span class="p">[</span>
                <span class="p">{</span><span class="s2">&quot;llm_score&quot;</span><span class="p">:</span> <span class="n">eval_score</span><span class="p">,</span> <span class="s2">&quot;llm_score_input&quot;</span><span class="p">:</span> <span class="n">eval_in</span><span class="p">,</span> <span class="s2">&quot;llm_score_output&quot;</span><span class="p">:</span> <span class="n">eval_out</span><span class="o">.</span><span class="n">text</span><span class="p">}</span>
                <span class="k">for</span> <span class="n">eval_score</span><span class="p">,</span> <span class="n">eval_in</span><span class="p">,</span> <span class="n">eval_out</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
                    <span class="n">evaluator_score_list</span><span class="p">,</span>
                    <span class="n">evaluator_input_list</span><span class="p">,</span>
                    <span class="n">evaluator_output_list</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="p">],</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">(language_model=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">language_model</span><span class="si">}</span><span class="s2">, prompt_template=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">prompt_template</span><span class="si">}</span><span class="s2">)&quot;</span>
        <span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.llm_score.ChatLLMScore.language_model" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">language_model</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.llm_score.ChatLLMScore.language_model" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">language_model</span> <span class="o">=</span> <span class="n">language_model</span>
</code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.llm_score.ChatLLMScore.prompt_template" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">prompt_template</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.llm_score.ChatLLMScore.prompt_template" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">prompt_template</span> <span class="o">=</span> <span class="n">prompt_template</span>
</code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.llm_score.ChatLLMScore.system_message" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">system_message</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.llm_score.ChatLLMScore.system_message" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">system_message</span> <span class="o">=</span> <span class="n">system_message</span>
</code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.llm_score.ChatLLMScore.batch_size" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">batch_size</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.llm_score.ChatLLMScore.batch_size" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
</code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.llm_score.ChatLLMScore.disable_tqdm" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">disable_tqdm</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.llm_score.ChatLLMScore.disable_tqdm" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">disable_tqdm</span> <span class="o">=</span> <span class="n">disable_tqdm</span>
</code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.llm_score.ChatLLMScore.valid_score_range" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">valid_score_range</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.llm_score.ChatLLMScore.valid_score_range" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">valid_score_range</span> <span class="o">=</span> <span class="n">valid_score_range</span>
</code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.llm_score.ChatLLMScore.category_key" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">category_key</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.llm_score.ChatLLMScore.category_key" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">category_key</span> <span class="o">=</span> <span class="n">category_key</span>
</code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>



<div class="doc doc-object doc-function">


<h3 id="flexeval.core.metric.llm_score.ChatLLMScore.__init__" class="doc doc-heading">
            <span class="doc doc-object-name doc-function-name">__init__</span>


<a href="#flexeval.core.metric.llm_score.ChatLLMScore.__init__" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="fm">__init__</span><span class="p">(</span>
    <span class="nf">language_model</span><span class="p">:</span> <span class="n">LanguageModel</span><span class="p">,</span>
    <span class="n">prompt_template</span><span class="p">:</span> <span class="n">PromptTemplate</span><span class="p">,</span>
    <span class="n">system_message</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="n">PromptTemplate</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
    <span class="n">disable_tqdm</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">valid_score_range</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">category_key</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>

    <div class="doc doc-contents ">


            <details class="quote">
              <summary>Source code in <code>flexeval/core/metric/llm_score.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">language_model</span><span class="p">:</span> <span class="n">LanguageModel</span><span class="p">,</span>
    <span class="n">prompt_template</span><span class="p">:</span> <span class="n">PromptTemplate</span><span class="p">,</span>
    <span class="n">system_message</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="n">PromptTemplate</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
    <span class="n">disable_tqdm</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">valid_score_range</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">category_key</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">language_model</span> <span class="o">=</span> <span class="n">language_model</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">prompt_template</span> <span class="o">=</span> <span class="n">prompt_template</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">system_message</span> <span class="o">=</span> <span class="n">system_message</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">disable_tqdm</span> <span class="o">=</span> <span class="n">disable_tqdm</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">valid_score_range</span> <span class="o">=</span> <span class="n">valid_score_range</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">category_key</span> <span class="o">=</span> <span class="n">category_key</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="flexeval.core.metric.llm_score.ChatLLMScore.evaluate" class="doc doc-heading">
            <span class="doc doc-object-name doc-function-name">evaluate</span>


<a href="#flexeval.core.metric.llm_score.ChatLLMScore.evaluate" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="nf">evaluate</span><span class="p">(</span>
    <span class="n">lm_outputs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">references_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">task_inputs_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MetricResult</span>
</code></pre></div>

    <div class="doc doc-contents ">


            <details class="quote">
              <summary>Source code in <code>flexeval/core/metric/llm_score.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">lm_outputs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">references_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">task_inputs_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MetricResult</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">task_inputs_list</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">task_inputs_list</span> <span class="o">=</span> <span class="p">[{}</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">lm_outputs</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">references_list</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">references_list</span> <span class="o">=</span> <span class="p">[[]</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">lm_outputs</span><span class="p">]</span>

    <span class="n">evaluator_input_list</span> <span class="o">=</span> <span class="n">prepare_chat_input_for_evaluator</span><span class="p">(</span>
        <span class="n">lm_outputs</span><span class="p">,</span> <span class="n">references_list</span><span class="p">,</span> <span class="n">task_inputs_list</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompt_template</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">system_message</span>
    <span class="p">)</span>
    <span class="n">evaluator_output_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">LMOutput</span><span class="p">]</span> <span class="o">=</span> <span class="n">generate_evaluations</span><span class="p">(</span>
        <span class="n">evaluator_input_list</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">language_model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">disable_tqdm</span><span class="p">,</span> <span class="s2">&quot;Calculating ChatLLM score&quot;</span>
    <span class="p">)</span>

    <span class="n">evaluator_score_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">evaluator_output</span> <span class="ow">in</span> <span class="n">evaluator_output_list</span><span class="p">:</span>
        <span class="n">evaluator_score</span> <span class="o">=</span> <span class="n">parse_score_from_evaluator_output</span><span class="p">(</span>
            <span class="n">evaluator_output</span><span class="o">.</span><span class="n">text</span><span class="p">,</span>
            <span class="n">valid_score_range</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">valid_score_range</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">evaluator_score</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to parse score from evaluator output: </span><span class="si">{</span><span class="n">evaluator_output</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">evaluator_score_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">evaluator_score</span><span class="p">)</span>

    <span class="n">summary</span> <span class="o">=</span> <span class="n">summarize_evaluator_scores</span><span class="p">(</span>
        <span class="n">evaluator_score_list</span><span class="p">,</span>
        <span class="n">task_inputs_list</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">category_key</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">MetricResult</span><span class="p">(</span>
        <span class="n">summary</span><span class="p">,</span>
        <span class="n">instance_details</span><span class="o">=</span><span class="p">[</span>
            <span class="p">{</span><span class="s2">&quot;llm_score&quot;</span><span class="p">:</span> <span class="n">eval_score</span><span class="p">,</span> <span class="s2">&quot;llm_score_input&quot;</span><span class="p">:</span> <span class="n">eval_in</span><span class="p">,</span> <span class="s2">&quot;llm_score_output&quot;</span><span class="p">:</span> <span class="n">eval_out</span><span class="o">.</span><span class="n">text</span><span class="p">}</span>
            <span class="k">for</span> <span class="n">eval_score</span><span class="p">,</span> <span class="n">eval_in</span><span class="p">,</span> <span class="n">eval_out</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
                <span class="n">evaluator_score_list</span><span class="p">,</span>
                <span class="n">evaluator_input_list</span><span class="p">,</span>
                <span class="n">evaluator_output_list</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">],</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="flexeval.core.metric.llm_score.ChatLLMScore.__repr__" class="doc doc-heading">
            <span class="doc doc-object-name doc-function-name">__repr__</span>


<a href="#flexeval.core.metric.llm_score.ChatLLMScore.__repr__" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="fm">__repr__</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="nb">str</span>
</code></pre></div>

    <div class="doc doc-contents ">


            <details class="quote">
              <summary>Source code in <code>flexeval/core/metric/llm_score.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="k">return</span> <span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">(language_model=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">language_model</span><span class="si">}</span><span class="s2">, prompt_template=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">prompt_template</span><span class="si">}</span><span class="s2">)&quot;</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="flexeval.core.metric.llm_score.LLMScore" class="doc doc-heading">
            <span class="doc doc-object-name doc-class-name">LLMScore</span>


<a href="#flexeval.core.metric.llm_score.LLMScore" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents first">


        <p>Let LanguageModel to evaluate the output of another LanguageModel.</p>
<p>You can specify the evaluation criteria in <code>PromptTemplate</code>.
The last integer value in the output of the evaluator is used as the evaluation score.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>language_model</code></b>
              (<code><a class="autorefs autorefs-internal" title="LanguageModel (flexeval.core.language_model.LanguageModel)" href="../LMOutput/#flexeval.core.language_model.base.LanguageModel">LanguageModel</a></code>)
          –
          <div class="doc-md-description">
            <p>An instance of <code>LanguageModel</code> to evaluate the output of the model.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>prompt_template</code></b>
              (<code><a class="autorefs autorefs-internal" title="PromptTemplate (flexeval.core.prompt_template.PromptTemplate)" href="../PromptTemplate/#flexeval.core.prompt_template.base.PromptTemplate">PromptTemplate</a></code>)
          –
          <div class="doc-md-description">
            <p>An instance of <code>PromptTemplate</code> to embed the input for the evaluator.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>batch_size</code></b>
              (<code><span title="int">int</span></code>, default:
                  <code>4</code>
)
          –
          <div class="doc-md-description">
            <p>The batch size for the evaluator.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>disable_tqdm</code></b>
              (<code><span title="bool">bool</span></code>, default:
                  <code>False</code>
)
          –
          <div class="doc-md-description">
            <p>Whether to disable the progress bar.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>valid_score_range</code></b>
              (<code><span title="tuple">tuple</span>[<span title="int">int</span>, <span title="int">int</span>] | None</code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>A tuple of two integers representing the valid score range.
If the parsed score is out of the range, it will be ignored.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>category_key</code></b>
              (<code><span title="str">str</span> | None</code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>A key to create category-wise mean score.
The category key is expected to be in task inputs.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">flexeval</span><span class="w"> </span><span class="kn">import</span> <span class="n">LLMScore</span><span class="p">,</span> <span class="n">OpenAIChatAPI</span><span class="p">,</span> <span class="n">Jinja2PromptTemplate</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">language_model</span> <span class="o">=</span> <span class="n">OpenAIChatAPI</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;gpt-3.5-turbo&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">template</span> <span class="o">=</span> <span class="s2">&quot;Evaluate the quality of this text.</span><span class="se">\n</span><span class="s2">`{{ lm_output }}`</span><span class="se">\n</span><span class="s2">Put the score at the end like [[5]].&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">prompt_template</span> <span class="o">=</span> <span class="n">Jinja2PromptTemplate</span><span class="p">(</span><span class="n">template</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">llm_score</span> <span class="o">=</span> <span class="n">LLMScore</span><span class="p">(</span><span class="n">language_model</span><span class="p">,</span> <span class="n">prompt_template</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lm_outputs</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Hello, world!&quot;</span><span class="p">,</span> <span class="s2">&quot;Good morning!&quot;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">llm_score</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">lm_outputs</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
<span class="go">MetricResult(</span>
<span class="go">    summary={&#39;llm_score&#39;: 3.0, &#39;num_failed_score_parses&#39;: 0},</span>
<span class="go">    instance_details=[</span>
<span class="go">        {</span>
<span class="go">            &#39;llm_score&#39;: 2,</span>
<span class="go">            &#39;llm_score_input&#39;: &#39;Evaluate the quality of this text...&#39;,</span>
<span class="go">            &#39;llm_score_output&#39;: &#39;This text is very simple,... Therefore, its quality is average. [[2]]&#39;},</span>
<span class="go">        {</span>
<span class="go">            &#39;llm_score&#39;: 4,</span>
<span class="go">            &#39;llm_score_input&#39;: &#39;Evaluate the quality of this text...&#39;,</span>
<span class="go">            &#39;llm_score_output&#39;: &#39;... Overall, the quality of the text is good but basic. [[4]]&#39;}</span>
<span class="go">    ]</span>
<span class="go">)</span>
</code></pre></div>







              <details class="quote">
                <summary>Source code in <code>flexeval/core/metric/llm_score.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">LLMScore</span><span class="p">(</span><span class="n">Metric</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Let LanguageModel to evaluate the output of another LanguageModel.</span>

<span class="sd">    You can specify the evaluation criteria in `PromptTemplate`.</span>
<span class="sd">    The last integer value in the output of the evaluator is used as the evaluation score.</span>

<span class="sd">    Args:</span>
<span class="sd">        language_model: An instance of `LanguageModel` to evaluate the output of the model.</span>
<span class="sd">        prompt_template: An instance of `PromptTemplate` to embed the input for the evaluator.</span>
<span class="sd">        batch_size: The batch size for the evaluator.</span>
<span class="sd">        disable_tqdm: Whether to disable the progress bar.</span>
<span class="sd">        valid_score_range: A tuple of two integers representing the valid score range.</span>
<span class="sd">            If the parsed score is out of the range, it will be ignored.</span>
<span class="sd">        category_key: A key to create category-wise mean score.</span>
<span class="sd">            The category key is expected to be in task inputs.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from flexeval import LLMScore, OpenAIChatAPI, Jinja2PromptTemplate</span>
<span class="sd">        &gt;&gt;&gt; language_model = OpenAIChatAPI(model_name=&quot;gpt-3.5-turbo&quot;)</span>
<span class="sd">        &gt;&gt;&gt; template = &quot;Evaluate the quality of this text.\\n`{{ lm_output }}`\\nPut the score at the end like [[5]].&quot;</span>
<span class="sd">        &gt;&gt;&gt; prompt_template = Jinja2PromptTemplate(template)</span>
<span class="sd">        &gt;&gt;&gt; llm_score = LLMScore(language_model, prompt_template)</span>
<span class="sd">        &gt;&gt;&gt; lm_outputs = [&quot;Hello, world!&quot;, &quot;Good morning!&quot;]</span>
<span class="sd">        &gt;&gt;&gt; result = llm_score.evaluate(lm_outputs)</span>
<span class="sd">        &gt;&gt;&gt; print(result)</span>
<span class="sd">        MetricResult(</span>
<span class="sd">            summary={&#39;llm_score&#39;: 3.0, &#39;num_failed_score_parses&#39;: 0},</span>
<span class="sd">            instance_details=[</span>
<span class="sd">                {</span>
<span class="sd">                    &#39;llm_score&#39;: 2,</span>
<span class="sd">                    &#39;llm_score_input&#39;: &#39;Evaluate the quality of this text...&#39;,</span>
<span class="sd">                    &#39;llm_score_output&#39;: &#39;This text is very simple,... Therefore, its quality is average. [[2]]&#39;},</span>
<span class="sd">                {</span>
<span class="sd">                    &#39;llm_score&#39;: 4,</span>
<span class="sd">                    &#39;llm_score_input&#39;: &#39;Evaluate the quality of this text...&#39;,</span>
<span class="sd">                    &#39;llm_score_output&#39;: &#39;... Overall, the quality of the text is good but basic. [[4]]&#39;}</span>
<span class="sd">            ]</span>
<span class="sd">        )</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">language_model</span><span class="p">:</span> <span class="n">LanguageModel</span><span class="p">,</span>
        <span class="n">prompt_template</span><span class="p">:</span> <span class="n">PromptTemplate</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
        <span class="n">disable_tqdm</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">valid_score_range</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">category_key</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">language_model</span> <span class="o">=</span> <span class="n">language_model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prompt_template</span> <span class="o">=</span> <span class="n">prompt_template</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">disable_tqdm</span> <span class="o">=</span> <span class="n">disable_tqdm</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">valid_score_range</span> <span class="o">=</span> <span class="n">valid_score_range</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">category_key</span> <span class="o">=</span> <span class="n">category_key</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">lm_outputs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">references_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">task_inputs_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MetricResult</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">task_inputs_list</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">task_inputs_list</span> <span class="o">=</span> <span class="p">[{}</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">lm_outputs</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">references_list</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">references_list</span> <span class="o">=</span> <span class="p">[[]</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">lm_outputs</span><span class="p">]</span>

        <span class="n">evaluator_input_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">prepare_text_input_for_evaluator</span><span class="p">(</span>
            <span class="n">lm_outputs</span><span class="p">,</span> <span class="n">references_list</span><span class="p">,</span> <span class="n">task_inputs_list</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompt_template</span>
        <span class="p">)</span>
        <span class="n">evaluator_output_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">LMOutput</span><span class="p">]</span> <span class="o">=</span> <span class="n">generate_evaluations</span><span class="p">(</span>
            <span class="n">evaluator_input_list</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">language_model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">disable_tqdm</span><span class="p">,</span> <span class="s2">&quot;Calculating LLM score&quot;</span>
        <span class="p">)</span>

        <span class="n">evaluator_score_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">evaluator_output</span> <span class="ow">in</span> <span class="n">evaluator_output_list</span><span class="p">:</span>
            <span class="n">evaluator_score</span> <span class="o">=</span> <span class="n">parse_score_from_evaluator_output</span><span class="p">(</span>
                <span class="n">evaluator_output</span><span class="o">.</span><span class="n">text</span><span class="p">,</span>
                <span class="n">valid_score_range</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">valid_score_range</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="n">evaluator_score</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to parse score from evaluator output: </span><span class="si">{</span><span class="n">evaluator_output</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">evaluator_score_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">evaluator_score</span><span class="p">)</span>

        <span class="n">summary</span> <span class="o">=</span> <span class="n">summarize_evaluator_scores</span><span class="p">(</span>
            <span class="n">evaluator_score_list</span><span class="p">,</span>
            <span class="n">task_inputs_list</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">category_key</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">MetricResult</span><span class="p">(</span>
            <span class="n">summary</span><span class="p">,</span>
            <span class="n">instance_details</span><span class="o">=</span><span class="p">[</span>
                <span class="p">{</span><span class="s2">&quot;llm_score&quot;</span><span class="p">:</span> <span class="n">eval_score</span><span class="p">,</span> <span class="s2">&quot;llm_score_input&quot;</span><span class="p">:</span> <span class="n">eval_in</span><span class="p">,</span> <span class="s2">&quot;llm_score_output&quot;</span><span class="p">:</span> <span class="n">eval_out</span><span class="o">.</span><span class="n">text</span><span class="p">}</span>
                <span class="k">for</span> <span class="n">eval_score</span><span class="p">,</span> <span class="n">eval_in</span><span class="p">,</span> <span class="n">eval_out</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
                    <span class="n">evaluator_score_list</span><span class="p">,</span>
                    <span class="n">evaluator_input_list</span><span class="p">,</span>
                    <span class="n">evaluator_output_list</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="p">],</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">(language_model=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">language_model</span><span class="si">}</span><span class="s2">, prompt_template=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">prompt_template</span><span class="si">}</span><span class="s2">)&quot;</span>
        <span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.llm_score.LLMScore.language_model" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">language_model</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.llm_score.LLMScore.language_model" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">language_model</span> <span class="o">=</span> <span class="n">language_model</span>
</code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.llm_score.LLMScore.prompt_template" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">prompt_template</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.llm_score.LLMScore.prompt_template" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">prompt_template</span> <span class="o">=</span> <span class="n">prompt_template</span>
</code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.llm_score.LLMScore.batch_size" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">batch_size</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.llm_score.LLMScore.batch_size" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
</code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.llm_score.LLMScore.disable_tqdm" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">disable_tqdm</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.llm_score.LLMScore.disable_tqdm" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">disable_tqdm</span> <span class="o">=</span> <span class="n">disable_tqdm</span>
</code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.llm_score.LLMScore.valid_score_range" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">valid_score_range</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.llm_score.LLMScore.valid_score_range" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">valid_score_range</span> <span class="o">=</span> <span class="n">valid_score_range</span>
</code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.llm_score.LLMScore.category_key" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">category_key</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.llm_score.LLMScore.category_key" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">category_key</span> <span class="o">=</span> <span class="n">category_key</span>
</code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>



<div class="doc doc-object doc-function">


<h3 id="flexeval.core.metric.llm_score.LLMScore.__init__" class="doc doc-heading">
            <span class="doc doc-object-name doc-function-name">__init__</span>


<a href="#flexeval.core.metric.llm_score.LLMScore.__init__" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="fm">__init__</span><span class="p">(</span>
    <span class="nf">language_model</span><span class="p">:</span> <span class="n">LanguageModel</span><span class="p">,</span>
    <span class="n">prompt_template</span><span class="p">:</span> <span class="n">PromptTemplate</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
    <span class="n">disable_tqdm</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">valid_score_range</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">category_key</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>

    <div class="doc doc-contents ">


            <details class="quote">
              <summary>Source code in <code>flexeval/core/metric/llm_score.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">language_model</span><span class="p">:</span> <span class="n">LanguageModel</span><span class="p">,</span>
    <span class="n">prompt_template</span><span class="p">:</span> <span class="n">PromptTemplate</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
    <span class="n">disable_tqdm</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">valid_score_range</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">category_key</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">language_model</span> <span class="o">=</span> <span class="n">language_model</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">prompt_template</span> <span class="o">=</span> <span class="n">prompt_template</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">disable_tqdm</span> <span class="o">=</span> <span class="n">disable_tqdm</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">valid_score_range</span> <span class="o">=</span> <span class="n">valid_score_range</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">category_key</span> <span class="o">=</span> <span class="n">category_key</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="flexeval.core.metric.llm_score.LLMScore.evaluate" class="doc doc-heading">
            <span class="doc doc-object-name doc-function-name">evaluate</span>


<a href="#flexeval.core.metric.llm_score.LLMScore.evaluate" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="nf">evaluate</span><span class="p">(</span>
    <span class="n">lm_outputs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">references_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">task_inputs_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MetricResult</span>
</code></pre></div>

    <div class="doc doc-contents ">


            <details class="quote">
              <summary>Source code in <code>flexeval/core/metric/llm_score.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">lm_outputs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">references_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">task_inputs_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MetricResult</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">task_inputs_list</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">task_inputs_list</span> <span class="o">=</span> <span class="p">[{}</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">lm_outputs</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">references_list</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">references_list</span> <span class="o">=</span> <span class="p">[[]</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">lm_outputs</span><span class="p">]</span>

    <span class="n">evaluator_input_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">prepare_text_input_for_evaluator</span><span class="p">(</span>
        <span class="n">lm_outputs</span><span class="p">,</span> <span class="n">references_list</span><span class="p">,</span> <span class="n">task_inputs_list</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompt_template</span>
    <span class="p">)</span>
    <span class="n">evaluator_output_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">LMOutput</span><span class="p">]</span> <span class="o">=</span> <span class="n">generate_evaluations</span><span class="p">(</span>
        <span class="n">evaluator_input_list</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">language_model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">disable_tqdm</span><span class="p">,</span> <span class="s2">&quot;Calculating LLM score&quot;</span>
    <span class="p">)</span>

    <span class="n">evaluator_score_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">evaluator_output</span> <span class="ow">in</span> <span class="n">evaluator_output_list</span><span class="p">:</span>
        <span class="n">evaluator_score</span> <span class="o">=</span> <span class="n">parse_score_from_evaluator_output</span><span class="p">(</span>
            <span class="n">evaluator_output</span><span class="o">.</span><span class="n">text</span><span class="p">,</span>
            <span class="n">valid_score_range</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">valid_score_range</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">evaluator_score</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to parse score from evaluator output: </span><span class="si">{</span><span class="n">evaluator_output</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">evaluator_score_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">evaluator_score</span><span class="p">)</span>

    <span class="n">summary</span> <span class="o">=</span> <span class="n">summarize_evaluator_scores</span><span class="p">(</span>
        <span class="n">evaluator_score_list</span><span class="p">,</span>
        <span class="n">task_inputs_list</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">category_key</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">MetricResult</span><span class="p">(</span>
        <span class="n">summary</span><span class="p">,</span>
        <span class="n">instance_details</span><span class="o">=</span><span class="p">[</span>
            <span class="p">{</span><span class="s2">&quot;llm_score&quot;</span><span class="p">:</span> <span class="n">eval_score</span><span class="p">,</span> <span class="s2">&quot;llm_score_input&quot;</span><span class="p">:</span> <span class="n">eval_in</span><span class="p">,</span> <span class="s2">&quot;llm_score_output&quot;</span><span class="p">:</span> <span class="n">eval_out</span><span class="o">.</span><span class="n">text</span><span class="p">}</span>
            <span class="k">for</span> <span class="n">eval_score</span><span class="p">,</span> <span class="n">eval_in</span><span class="p">,</span> <span class="n">eval_out</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
                <span class="n">evaluator_score_list</span><span class="p">,</span>
                <span class="n">evaluator_input_list</span><span class="p">,</span>
                <span class="n">evaluator_output_list</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">],</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="flexeval.core.metric.llm_score.LLMScore.__repr__" class="doc doc-heading">
            <span class="doc doc-object-name doc-function-name">__repr__</span>


<a href="#flexeval.core.metric.llm_score.LLMScore.__repr__" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="fm">__repr__</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="nb">str</span>
</code></pre></div>

    <div class="doc doc-contents ">


            <details class="quote">
              <summary>Source code in <code>flexeval/core/metric/llm_score.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="k">return</span> <span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">(language_model=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">language_model</span><span class="si">}</span><span class="s2">, prompt_template=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">prompt_template</span><span class="si">}</span><span class="s2">)&quot;</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="flexeval.core.metric.output_length_stats.OutputLengthStats" class="doc doc-heading">
            <span class="doc doc-object-name doc-class-name">OutputLengthStats</span>


<a href="#flexeval.core.metric.output_length_stats.OutputLengthStats" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents first">


        <p>Compute statistics on the length of the outputs.</p>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">flexeval</span><span class="w"> </span><span class="kn">import</span> <span class="n">OutputLengthStats</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output_length_stats</span> <span class="o">=</span> <span class="n">OutputLengthStats</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lm_outputs</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;123456&quot;</span><span class="p">,</span> <span class="s2">&quot;123456789&quot;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">output_length_stats</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">lm_outputs</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
<span class="go">MetricResult(</span>
<span class="go">    summary={&#39;avg_output_length&#39;: 7.5, &#39;max_output_length&#39;: 9, &#39;min_output_length&#39;: 6},</span>
<span class="go">    instance_details=[{&#39;output_length&#39;: 6}, {&#39;output_length&#39;: 9}]</span>
<span class="go">)</span>
</code></pre></div>







              <details class="quote">
                <summary>Source code in <code>flexeval/core/metric/output_length_stats.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">OutputLengthStats</span><span class="p">(</span><span class="n">Metric</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute statistics on the length of the outputs.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from flexeval import OutputLengthStats</span>
<span class="sd">        &gt;&gt;&gt; output_length_stats = OutputLengthStats()</span>
<span class="sd">        &gt;&gt;&gt; lm_outputs = [&quot;123456&quot;, &quot;123456789&quot;]</span>
<span class="sd">        &gt;&gt;&gt; result = output_length_stats.evaluate(lm_outputs)</span>
<span class="sd">        &gt;&gt;&gt; print(result)</span>
<span class="sd">        MetricResult(</span>
<span class="sd">            summary={&#39;avg_output_length&#39;: 7.5, &#39;max_output_length&#39;: 9, &#39;min_output_length&#39;: 6},</span>
<span class="sd">            instance_details=[{&#39;output_length&#39;: 6}, {&#39;output_length&#39;: 9}]</span>
<span class="sd">        )</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">lm_outputs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">references_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">task_inputs_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MetricResult</span><span class="p">:</span>
        <span class="n">output_length_list</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">output</span><span class="p">)</span> <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">lm_outputs</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">MetricResult</span><span class="p">(</span>
            <span class="p">{</span>
                <span class="s2">&quot;avg_output_length&quot;</span><span class="p">:</span> <span class="nb">sum</span><span class="p">(</span><span class="n">output_length_list</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">output_length_list</span><span class="p">),</span>
                <span class="s2">&quot;max_output_length&quot;</span><span class="p">:</span> <span class="nb">max</span><span class="p">(</span><span class="n">output_length_list</span><span class="p">),</span>
                <span class="s2">&quot;min_output_length&quot;</span><span class="p">:</span> <span class="nb">min</span><span class="p">(</span><span class="n">output_length_list</span><span class="p">),</span>
            <span class="p">},</span>
            <span class="n">instance_details</span><span class="o">=</span><span class="p">[{</span><span class="s2">&quot;output_length&quot;</span><span class="p">:</span> <span class="n">s</span><span class="p">}</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">output_length_list</span><span class="p">],</span>
        <span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="flexeval.core.metric.output_length_stats.OutputLengthStats.evaluate" class="doc doc-heading">
            <span class="doc doc-object-name doc-function-name">evaluate</span>


<a href="#flexeval.core.metric.output_length_stats.OutputLengthStats.evaluate" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="nf">evaluate</span><span class="p">(</span>
    <span class="n">lm_outputs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">references_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">task_inputs_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MetricResult</span>
</code></pre></div>

    <div class="doc doc-contents ">


            <details class="quote">
              <summary>Source code in <code>flexeval/core/metric/output_length_stats.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">lm_outputs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">references_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">task_inputs_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MetricResult</span><span class="p">:</span>
    <span class="n">output_length_list</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">output</span><span class="p">)</span> <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">lm_outputs</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">MetricResult</span><span class="p">(</span>
        <span class="p">{</span>
            <span class="s2">&quot;avg_output_length&quot;</span><span class="p">:</span> <span class="nb">sum</span><span class="p">(</span><span class="n">output_length_list</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">output_length_list</span><span class="p">),</span>
            <span class="s2">&quot;max_output_length&quot;</span><span class="p">:</span> <span class="nb">max</span><span class="p">(</span><span class="n">output_length_list</span><span class="p">),</span>
            <span class="s2">&quot;min_output_length&quot;</span><span class="p">:</span> <span class="nb">min</span><span class="p">(</span><span class="n">output_length_list</span><span class="p">),</span>
        <span class="p">},</span>
        <span class="n">instance_details</span><span class="o">=</span><span class="p">[{</span><span class="s2">&quot;output_length&quot;</span><span class="p">:</span> <span class="n">s</span><span class="p">}</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">output_length_list</span><span class="p">],</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="flexeval.core.metric.perspective_api.PerspectiveAPI" class="doc doc-heading">
            <span class="doc doc-object-name doc-class-name">PerspectiveAPI</span>


<a href="#flexeval.core.metric.perspective_api.PerspectiveAPI" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents first">


        <p>A metric that evaluates text outputs using the Perspective API.
Please set <code>PERSPECTIVE_API_KEY</code> in the environment variable.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>languages</code></b>
              (<code><span title="list">list</span>[<span title="str">str</span>]</code>)
          –
          <div class="doc-md-description">
            <p>A list of languages to analyze.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">flexeval</span><span class="w"> </span><span class="kn">import</span> <span class="n">PerspectiveAPI</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">perspective_api</span> <span class="o">=</span> <span class="n">PerspectiveAPI</span><span class="p">(</span><span class="n">languages</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;en&quot;</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lm_outputs</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;I love you&quot;</span><span class="p">,</span> <span class="s2">&quot;I hate you&quot;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">perspective_api</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">lm_outputs</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
<span class="go">MetricResult(</span>
<span class="go">    summary={&#39;TOXICITY&#39;: 0.35407552, ..., &#39;THREAT&#39;: 0.0265799825},</span>
<span class="go">    instance_details=[</span>
<span class="go">        {&#39;TOXICITY&#39;: 0.02543884, ..., &#39;THREAT&#39;: 0.009204263},</span>
<span class="go">        {&#39;TOXICITY&#39;: 0.6827122, ..., &#39;THREAT&#39;: 0.043955702}</span>
<span class="go">        ]</span>
<span class="go">    )</span>
</code></pre></div>







              <details class="quote">
                <summary>Source code in <code>flexeval/core/metric/perspective_api.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span>
<span class="normal">84</span>
<span class="normal">85</span>
<span class="normal">86</span>
<span class="normal">87</span>
<span class="normal">88</span>
<span class="normal">89</span>
<span class="normal">90</span>
<span class="normal">91</span>
<span class="normal">92</span>
<span class="normal">93</span>
<span class="normal">94</span>
<span class="normal">95</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">PerspectiveAPI</span><span class="p">(</span><span class="n">Metric</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A metric that evaluates text outputs using the Perspective API.</span>
<span class="sd">    Please set `PERSPECTIVE_API_KEY` in the environment variable.</span>

<span class="sd">    Args:</span>
<span class="sd">        languages: A list of languages to analyze.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from flexeval import PerspectiveAPI</span>
<span class="sd">        &gt;&gt;&gt; perspective_api = PerspectiveAPI(languages=[&quot;en&quot;])</span>
<span class="sd">        &gt;&gt;&gt; lm_outputs = [&quot;I love you&quot;, &quot;I hate you&quot;]</span>
<span class="sd">        &gt;&gt;&gt; result = perspective_api.evaluate(lm_outputs)</span>
<span class="sd">        &gt;&gt;&gt; print(result)</span>
<span class="sd">        MetricResult(</span>
<span class="sd">            summary={&#39;TOXICITY&#39;: 0.35407552, ..., &#39;THREAT&#39;: 0.0265799825},</span>
<span class="sd">            instance_details=[</span>
<span class="sd">                {&#39;TOXICITY&#39;: 0.02543884, ..., &#39;THREAT&#39;: 0.009204263},</span>
<span class="sd">                {&#39;TOXICITY&#39;: 0.6827122, ..., &#39;THREAT&#39;: 0.043955702}</span>
<span class="sd">                ]</span>
<span class="sd">            )</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">languages</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">client</span> <span class="o">=</span> <span class="n">discovery</span><span class="o">.</span><span class="n">build</span><span class="p">(</span>
            <span class="s2">&quot;commentanalyzer&quot;</span><span class="p">,</span>
            <span class="s2">&quot;v1alpha1&quot;</span><span class="p">,</span>
            <span class="n">developerKey</span><span class="o">=</span><span class="n">PERSPECTIVE_API_KEY</span><span class="p">,</span>
            <span class="n">discoveryServiceUrl</span><span class="o">=</span><span class="s2">&quot;https://commentanalyzer.googleapis.com/$discovery/rest?version=v1alpha1&quot;</span><span class="p">,</span>
            <span class="n">static_discovery</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">languages</span> <span class="o">=</span> <span class="n">languages</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attributes</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;TOXICITY&quot;</span><span class="p">,</span> <span class="s2">&quot;SEVERE_TOXICITY&quot;</span><span class="p">,</span> <span class="s2">&quot;IDENTITY_ATTACK&quot;</span><span class="p">,</span> <span class="s2">&quot;INSULT&quot;</span><span class="p">,</span> <span class="s2">&quot;PROFANITY&quot;</span><span class="p">,</span> <span class="s2">&quot;THREAT&quot;</span><span class="p">]</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">lm_outputs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">references_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">task_inputs_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MetricResult</span><span class="p">:</span>
        <span class="n">instance_details</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">lm_output</span> <span class="ow">in</span> <span class="n">lm_outputs</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">lm_output</span> <span class="o">==</span> <span class="s2">&quot;&quot;</span><span class="p">:</span>
                <span class="n">instance_details</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="n">att</span><span class="p">:</span> <span class="mf">0.0</span> <span class="k">for</span> <span class="n">att</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">attributes</span><span class="p">})</span>
                <span class="k">continue</span>
            <span class="n">analyze_request</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s2">&quot;comment&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;text&quot;</span><span class="p">:</span> <span class="n">lm_output</span><span class="p">},</span>
                <span class="s2">&quot;languages&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">languages</span><span class="p">,</span>
                <span class="s2">&quot;requestedAttributes&quot;</span><span class="p">:</span> <span class="p">{</span><span class="n">att</span><span class="p">:</span> <span class="p">{}</span> <span class="k">for</span> <span class="n">att</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">attributes</span><span class="p">},</span>
            <span class="p">}</span>
            <span class="n">response</span> <span class="o">=</span> <span class="n">retry_on_error</span><span class="p">(</span><span class="n">perspectiveapi_call</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">client</span><span class="o">.</span><span class="n">comments</span><span class="p">()</span><span class="o">.</span><span class="n">analyze</span><span class="p">(</span><span class="n">body</span><span class="o">=</span><span class="n">analyze_request</span><span class="p">)</span><span class="o">.</span><span class="n">execute</span><span class="p">)</span>
            <span class="n">instance_details</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="p">{</span><span class="n">att</span><span class="p">:</span> <span class="n">response</span><span class="p">[</span><span class="s2">&quot;attributeScores&quot;</span><span class="p">][</span><span class="n">att</span><span class="p">][</span><span class="s2">&quot;summaryScore&quot;</span><span class="p">][</span><span class="s2">&quot;value&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">att</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">attributes</span><span class="p">},</span>
            <span class="p">)</span>
        <span class="n">scores_for_attribute</span> <span class="o">=</span> <span class="p">{</span><span class="n">att</span><span class="p">:</span> <span class="p">[]</span> <span class="k">for</span> <span class="n">att</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">attributes</span><span class="p">}</span>
        <span class="k">for</span> <span class="n">instance</span> <span class="ow">in</span> <span class="n">instance_details</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">att</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">attributes</span><span class="p">:</span>
                <span class="n">scores_for_attribute</span><span class="p">[</span><span class="n">att</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">instance</span><span class="p">[</span><span class="n">att</span><span class="p">])</span>
        <span class="n">average_scores</span> <span class="o">=</span> <span class="p">{</span><span class="n">att</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">scores_for_attribute</span><span class="p">[</span><span class="n">att</span><span class="p">])</span> <span class="k">for</span> <span class="n">att</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">attributes</span><span class="p">}</span>
        <span class="k">return</span> <span class="n">MetricResult</span><span class="p">(</span><span class="n">average_scores</span><span class="p">,</span> <span class="n">instance_details</span><span class="o">=</span><span class="n">instance_details</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.perspective_api.PerspectiveAPI.client" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">client</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.perspective_api.PerspectiveAPI.client" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">client</span> <span class="o">=</span> <span class="n">build</span><span class="p">(</span>
    <span class="s2">&quot;commentanalyzer&quot;</span><span class="p">,</span>
    <span class="s2">&quot;v1alpha1&quot;</span><span class="p">,</span>
    <span class="n">developerKey</span><span class="o">=</span><span class="n">PERSPECTIVE_API_KEY</span><span class="p">,</span>
    <span class="n">discoveryServiceUrl</span><span class="o">=</span><span class="s2">&quot;https://commentanalyzer.googleapis.com/$discovery/rest?version=v1alpha1&quot;</span><span class="p">,</span>
    <span class="n">static_discovery</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">)</span>
</code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.perspective_api.PerspectiveAPI.languages" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">languages</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.perspective_api.PerspectiveAPI.languages" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">languages</span> <span class="o">=</span> <span class="n">languages</span>
</code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.perspective_api.PerspectiveAPI.attributes" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">attributes</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.perspective_api.PerspectiveAPI.attributes" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">attributes</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;TOXICITY&quot;</span><span class="p">,</span>
    <span class="s2">&quot;SEVERE_TOXICITY&quot;</span><span class="p">,</span>
    <span class="s2">&quot;IDENTITY_ATTACK&quot;</span><span class="p">,</span>
    <span class="s2">&quot;INSULT&quot;</span><span class="p">,</span>
    <span class="s2">&quot;PROFANITY&quot;</span><span class="p">,</span>
    <span class="s2">&quot;THREAT&quot;</span><span class="p">,</span>
<span class="p">]</span>
</code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>



<div class="doc doc-object doc-function">


<h3 id="flexeval.core.metric.perspective_api.PerspectiveAPI.__init__" class="doc doc-heading">
            <span class="doc doc-object-name doc-function-name">__init__</span>


<a href="#flexeval.core.metric.perspective_api.PerspectiveAPI.__init__" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="fm">__init__</span><span class="p">(</span><span class="nf">languages</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>

    <div class="doc doc-contents ">


            <details class="quote">
              <summary>Source code in <code>flexeval/core/metric/perspective_api.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">languages</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">client</span> <span class="o">=</span> <span class="n">discovery</span><span class="o">.</span><span class="n">build</span><span class="p">(</span>
        <span class="s2">&quot;commentanalyzer&quot;</span><span class="p">,</span>
        <span class="s2">&quot;v1alpha1&quot;</span><span class="p">,</span>
        <span class="n">developerKey</span><span class="o">=</span><span class="n">PERSPECTIVE_API_KEY</span><span class="p">,</span>
        <span class="n">discoveryServiceUrl</span><span class="o">=</span><span class="s2">&quot;https://commentanalyzer.googleapis.com/$discovery/rest?version=v1alpha1&quot;</span><span class="p">,</span>
        <span class="n">static_discovery</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">languages</span> <span class="o">=</span> <span class="n">languages</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">attributes</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;TOXICITY&quot;</span><span class="p">,</span> <span class="s2">&quot;SEVERE_TOXICITY&quot;</span><span class="p">,</span> <span class="s2">&quot;IDENTITY_ATTACK&quot;</span><span class="p">,</span> <span class="s2">&quot;INSULT&quot;</span><span class="p">,</span> <span class="s2">&quot;PROFANITY&quot;</span><span class="p">,</span> <span class="s2">&quot;THREAT&quot;</span><span class="p">]</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="flexeval.core.metric.perspective_api.PerspectiveAPI.evaluate" class="doc doc-heading">
            <span class="doc doc-object-name doc-function-name">evaluate</span>


<a href="#flexeval.core.metric.perspective_api.PerspectiveAPI.evaluate" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="nf">evaluate</span><span class="p">(</span>
    <span class="n">lm_outputs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">references_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">task_inputs_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MetricResult</span>
</code></pre></div>

    <div class="doc doc-contents ">


            <details class="quote">
              <summary>Source code in <code>flexeval/core/metric/perspective_api.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span>
<span class="normal">84</span>
<span class="normal">85</span>
<span class="normal">86</span>
<span class="normal">87</span>
<span class="normal">88</span>
<span class="normal">89</span>
<span class="normal">90</span>
<span class="normal">91</span>
<span class="normal">92</span>
<span class="normal">93</span>
<span class="normal">94</span>
<span class="normal">95</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">lm_outputs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">references_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">task_inputs_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MetricResult</span><span class="p">:</span>
    <span class="n">instance_details</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">lm_output</span> <span class="ow">in</span> <span class="n">lm_outputs</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">lm_output</span> <span class="o">==</span> <span class="s2">&quot;&quot;</span><span class="p">:</span>
            <span class="n">instance_details</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="n">att</span><span class="p">:</span> <span class="mf">0.0</span> <span class="k">for</span> <span class="n">att</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">attributes</span><span class="p">})</span>
            <span class="k">continue</span>
        <span class="n">analyze_request</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;comment&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;text&quot;</span><span class="p">:</span> <span class="n">lm_output</span><span class="p">},</span>
            <span class="s2">&quot;languages&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">languages</span><span class="p">,</span>
            <span class="s2">&quot;requestedAttributes&quot;</span><span class="p">:</span> <span class="p">{</span><span class="n">att</span><span class="p">:</span> <span class="p">{}</span> <span class="k">for</span> <span class="n">att</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">attributes</span><span class="p">},</span>
        <span class="p">}</span>
        <span class="n">response</span> <span class="o">=</span> <span class="n">retry_on_error</span><span class="p">(</span><span class="n">perspectiveapi_call</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">client</span><span class="o">.</span><span class="n">comments</span><span class="p">()</span><span class="o">.</span><span class="n">analyze</span><span class="p">(</span><span class="n">body</span><span class="o">=</span><span class="n">analyze_request</span><span class="p">)</span><span class="o">.</span><span class="n">execute</span><span class="p">)</span>
        <span class="n">instance_details</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="p">{</span><span class="n">att</span><span class="p">:</span> <span class="n">response</span><span class="p">[</span><span class="s2">&quot;attributeScores&quot;</span><span class="p">][</span><span class="n">att</span><span class="p">][</span><span class="s2">&quot;summaryScore&quot;</span><span class="p">][</span><span class="s2">&quot;value&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">att</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">attributes</span><span class="p">},</span>
        <span class="p">)</span>
    <span class="n">scores_for_attribute</span> <span class="o">=</span> <span class="p">{</span><span class="n">att</span><span class="p">:</span> <span class="p">[]</span> <span class="k">for</span> <span class="n">att</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">attributes</span><span class="p">}</span>
    <span class="k">for</span> <span class="n">instance</span> <span class="ow">in</span> <span class="n">instance_details</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">att</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">attributes</span><span class="p">:</span>
            <span class="n">scores_for_attribute</span><span class="p">[</span><span class="n">att</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">instance</span><span class="p">[</span><span class="n">att</span><span class="p">])</span>
    <span class="n">average_scores</span> <span class="o">=</span> <span class="p">{</span><span class="n">att</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">scores_for_attribute</span><span class="p">[</span><span class="n">att</span><span class="p">])</span> <span class="k">for</span> <span class="n">att</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">attributes</span><span class="p">}</span>
    <span class="k">return</span> <span class="n">MetricResult</span><span class="p">(</span><span class="n">average_scores</span><span class="p">,</span> <span class="n">instance_details</span><span class="o">=</span><span class="n">instance_details</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="flexeval.core.metric.repetition_count.RepetitionCount" class="doc doc-heading">
            <span class="doc doc-object-name doc-class-name">RepetitionCount</span>


<a href="#flexeval.core.metric.repetition_count.RepetitionCount" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents first">


        <p>A metric that counts the number of repetitions of the most repeated pattern in the model's output.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>lm_output_processor</code></b>
              (<code><a class="autorefs autorefs-internal" title="StringProcessor (flexeval.core.string_processor.StringProcessor)" href="../StringProcessor/#flexeval.core.string_processor.base.StringProcessor">StringProcessor</a> | <span title="list">list</span>[<a class="autorefs autorefs-internal" title="StringProcessor (flexeval.core.string_processor.StringProcessor)" href="../StringProcessor/#flexeval.core.string_processor.base.StringProcessor">StringProcessor</a>] | None</code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>StringProcessor or list of Normalizers to apply to the model outputs before analysis.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">flexeval</span><span class="w"> </span><span class="kn">import</span> <span class="n">RepetitionCount</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">repetition_count</span> <span class="o">=</span> <span class="n">RepetitionCount</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lm_outputs</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;hello hello hello hello hello hello hello hello hello hello&quot;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">references_list</span> <span class="o">=</span> <span class="p">[[]]</span>  <span class="c1"># Not used for this metric</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">repetition_count</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">lm_outputs</span><span class="p">,</span> <span class="n">references_list</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
<span class="go">MetricResult(</span>
<span class="go">    summary={&#39;repetition_ratio&#39;: 1.0},</span>
<span class="go">    instance_details=[{&#39;most_repeated_pattern&#39;: &#39;hello hell&#39;, &#39;repetition_count&#39;: 9, &#39;is_repetition&#39;: True}]</span>
<span class="go">)</span>
</code></pre></div>







              <details class="quote">
                <summary>Source code in <code>flexeval/core/metric/repetition_count.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span>
<span class="normal">84</span>
<span class="normal">85</span>
<span class="normal">86</span>
<span class="normal">87</span>
<span class="normal">88</span>
<span class="normal">89</span>
<span class="normal">90</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">RepetitionCount</span><span class="p">(</span><span class="n">Metric</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A metric that counts the number of repetitions of the most repeated pattern in the model&#39;s output.</span>

<span class="sd">    Args:</span>
<span class="sd">        lm_output_processor: StringProcessor or list of Normalizers to apply to the model outputs before analysis.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from flexeval import RepetitionCount</span>
<span class="sd">        &gt;&gt;&gt; repetition_count = RepetitionCount()</span>
<span class="sd">        &gt;&gt;&gt; lm_outputs = [&quot;hello hello hello hello hello hello hello hello hello hello&quot;]</span>
<span class="sd">        &gt;&gt;&gt; references_list = [[]]  # Not used for this metric</span>
<span class="sd">        &gt;&gt;&gt; result = repetition_count.evaluate(lm_outputs, references_list)</span>
<span class="sd">        &gt;&gt;&gt; print(result)</span>
<span class="sd">        MetricResult(</span>
<span class="sd">            summary={&#39;repetition_ratio&#39;: 1.0},</span>
<span class="sd">            instance_details=[{&#39;most_repeated_pattern&#39;: &#39;hello hell&#39;, &#39;repetition_count&#39;: 9, &#39;is_repetition&#39;: True}]</span>
<span class="sd">        )</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">count_threshold</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">30</span><span class="p">,</span>
        <span class="n">threshold_length</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
        <span class="n">lm_output_processor</span><span class="p">:</span> <span class="n">StringProcessor</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="n">StringProcessor</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">count_threshold</span> <span class="o">=</span> <span class="n">count_threshold</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">threshold_length</span> <span class="o">=</span> <span class="n">threshold_length</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">lm_output_processor</span><span class="p">,</span> <span class="n">StringProcessor</span><span class="p">):</span>
            <span class="n">lm_output_processor</span> <span class="o">=</span> <span class="p">[</span><span class="n">lm_output_processor</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lm_output_processors</span> <span class="o">=</span> <span class="n">lm_output_processor</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">lm_outputs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">references_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>  <span class="c1"># Not used in this metric</span>
        <span class="n">task_inputs_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># Not used in this metric</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MetricResult</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">lm_output_processors</span><span class="p">:</span>
            <span class="n">lm_outputs</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">functools</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">norm</span><span class="p">:</span> <span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">lm_output_processors</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span> <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">lm_outputs</span>
            <span class="p">]</span>

        <span class="n">repetition_details</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">num_repetitions</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">lm_outputs</span><span class="p">:</span>
            <span class="n">most_repeated_pattern</span><span class="p">,</span> <span class="n">count</span> <span class="o">=</span> <span class="n">get_most_repeated_pattern</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">threshold_length</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">threshold_length</span><span class="p">)</span>
            <span class="n">is_repetition</span> <span class="o">=</span> <span class="n">count</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">count_threshold</span>
            <span class="n">repetition_details</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="p">{</span>
                    <span class="s2">&quot;most_repeated_pattern&quot;</span><span class="p">:</span> <span class="n">most_repeated_pattern</span><span class="p">,</span>
                    <span class="s2">&quot;repetition_count&quot;</span><span class="p">:</span> <span class="n">count</span><span class="p">,</span>
                    <span class="s2">&quot;is_repetition&quot;</span><span class="p">:</span> <span class="n">is_repetition</span><span class="p">,</span>
                <span class="p">}</span>
            <span class="p">)</span>
            <span class="n">num_repetitions</span> <span class="o">+=</span> <span class="nb">int</span><span class="p">(</span><span class="n">is_repetition</span><span class="p">)</span>

        <span class="n">repetition_rate</span> <span class="o">=</span> <span class="n">num_repetitions</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">lm_outputs</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">MetricResult</span><span class="p">(</span>
            <span class="n">summary</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;repetition_ratio&quot;</span><span class="p">:</span> <span class="n">repetition_rate</span><span class="p">},</span>
            <span class="n">instance_details</span><span class="o">=</span><span class="n">repetition_details</span><span class="p">,</span>
        <span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.repetition_count.RepetitionCount.count_threshold" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">count_threshold</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.repetition_count.RepetitionCount.count_threshold" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">count_threshold</span> <span class="o">=</span> <span class="n">count_threshold</span>
</code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.repetition_count.RepetitionCount.threshold_length" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">threshold_length</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.repetition_count.RepetitionCount.threshold_length" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">threshold_length</span> <span class="o">=</span> <span class="n">threshold_length</span>
</code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.repetition_count.RepetitionCount.lm_output_processors" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">lm_output_processors</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.repetition_count.RepetitionCount.lm_output_processors" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">lm_output_processors</span> <span class="o">=</span> <span class="n">lm_output_processor</span>
</code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>



<div class="doc doc-object doc-function">


<h3 id="flexeval.core.metric.repetition_count.RepetitionCount.__init__" class="doc doc-heading">
            <span class="doc doc-object-name doc-function-name">__init__</span>


<a href="#flexeval.core.metric.repetition_count.RepetitionCount.__init__" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="fm">__init__</span><span class="p">(</span>
    <span class="nf">count_threshold</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">30</span><span class="p">,</span>
    <span class="n">threshold_length</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
    <span class="n">lm_output_processor</span><span class="p">:</span> <span class="n">StringProcessor</span>
    <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="n">StringProcessor</span><span class="p">]</span>
    <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>

    <div class="doc doc-contents ">


            <details class="quote">
              <summary>Source code in <code>flexeval/core/metric/repetition_count.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">count_threshold</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">30</span><span class="p">,</span>
    <span class="n">threshold_length</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
    <span class="n">lm_output_processor</span><span class="p">:</span> <span class="n">StringProcessor</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="n">StringProcessor</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">count_threshold</span> <span class="o">=</span> <span class="n">count_threshold</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">threshold_length</span> <span class="o">=</span> <span class="n">threshold_length</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">lm_output_processor</span><span class="p">,</span> <span class="n">StringProcessor</span><span class="p">):</span>
        <span class="n">lm_output_processor</span> <span class="o">=</span> <span class="p">[</span><span class="n">lm_output_processor</span><span class="p">]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">lm_output_processors</span> <span class="o">=</span> <span class="n">lm_output_processor</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="flexeval.core.metric.repetition_count.RepetitionCount.evaluate" class="doc doc-heading">
            <span class="doc doc-object-name doc-function-name">evaluate</span>


<a href="#flexeval.core.metric.repetition_count.RepetitionCount.evaluate" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="nf">evaluate</span><span class="p">(</span>
    <span class="n">lm_outputs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">references_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
    <span class="n">task_inputs_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MetricResult</span>
</code></pre></div>

    <div class="doc doc-contents ">


            <details class="quote">
              <summary>Source code in <code>flexeval/core/metric/repetition_count.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span>
<span class="normal">84</span>
<span class="normal">85</span>
<span class="normal">86</span>
<span class="normal">87</span>
<span class="normal">88</span>
<span class="normal">89</span>
<span class="normal">90</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">lm_outputs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">references_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>  <span class="c1"># Not used in this metric</span>
    <span class="n">task_inputs_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># Not used in this metric</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MetricResult</span><span class="p">:</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">lm_output_processors</span><span class="p">:</span>
        <span class="n">lm_outputs</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">functools</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">norm</span><span class="p">:</span> <span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">lm_output_processors</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span> <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">lm_outputs</span>
        <span class="p">]</span>

    <span class="n">repetition_details</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">num_repetitions</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">lm_outputs</span><span class="p">:</span>
        <span class="n">most_repeated_pattern</span><span class="p">,</span> <span class="n">count</span> <span class="o">=</span> <span class="n">get_most_repeated_pattern</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">threshold_length</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">threshold_length</span><span class="p">)</span>
        <span class="n">is_repetition</span> <span class="o">=</span> <span class="n">count</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">count_threshold</span>
        <span class="n">repetition_details</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="p">{</span>
                <span class="s2">&quot;most_repeated_pattern&quot;</span><span class="p">:</span> <span class="n">most_repeated_pattern</span><span class="p">,</span>
                <span class="s2">&quot;repetition_count&quot;</span><span class="p">:</span> <span class="n">count</span><span class="p">,</span>
                <span class="s2">&quot;is_repetition&quot;</span><span class="p">:</span> <span class="n">is_repetition</span><span class="p">,</span>
            <span class="p">}</span>
        <span class="p">)</span>
        <span class="n">num_repetitions</span> <span class="o">+=</span> <span class="nb">int</span><span class="p">(</span><span class="n">is_repetition</span><span class="p">)</span>

    <span class="n">repetition_rate</span> <span class="o">=</span> <span class="n">num_repetitions</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">lm_outputs</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">MetricResult</span><span class="p">(</span>
        <span class="n">summary</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;repetition_ratio&quot;</span><span class="p">:</span> <span class="n">repetition_rate</span><span class="p">},</span>
        <span class="n">instance_details</span><span class="o">=</span><span class="n">repetition_details</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="flexeval.core.metric.rouge.ROUGE" class="doc doc-heading">
            <span class="doc doc-object-name doc-class-name">ROUGE</span>


<a href="#flexeval.core.metric.rouge.ROUGE" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents first">


        <p>An implementation of <a href="https://aclanthology.org/W04-1013/">ROUGE</a>.</p>
<p>The calculation is based on the <a href="https://github.com/pltrdy/rouge">rouge</a> library.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>tokenizer</code></b>
              (<code><a class="autorefs autorefs-internal" title="Tokenizer (flexeval.core.tokenizer.Tokenizer)" href="../Tokenizer/#flexeval.core.tokenizer.base.Tokenizer">Tokenizer</a></code>)
          –
          <div class="doc-md-description">
            <p>An instance of <code>Tokenizer</code> to tokenize the input and output strings.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">flexeval</span><span class="w"> </span><span class="kn">import</span> <span class="n">ROUGE</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">flexeval</span><span class="w"> </span><span class="kn">import</span> <span class="n">WhitespaceTokenizer</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">WhitespaceTokenizer</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rouge</span> <span class="o">=</span> <span class="n">ROUGE</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lm_outputs</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;I am a student .&quot;</span><span class="p">,</span> <span class="s2">&quot;I am a teacher .&quot;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">references_list</span> <span class="o">=</span> <span class="p">[[</span><span class="s2">&quot;I am a student .&quot;</span><span class="p">,</span> <span class="s2">&quot;I am a learner .&quot;</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;I am a teacher .&quot;</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">rouge</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">lm_outputs</span><span class="p">,</span> <span class="n">references_list</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
<span class="go">MetricResult(</span>
<span class="go">    summary={&#39;rouge1&#39;: 0.999999995, &#39;rouge2&#39;: 0.999999995, &#39;rougeL&#39;: 0.999999995},</span>
<span class="go">    instance_details=[</span>
<span class="go">        {&#39;rouge1&#39;: 0.999999995, &#39;rouge2&#39;: 0.999999995, &#39;rougeL&#39;: 0.999999995},</span>
<span class="go">        {&#39;rouge1&#39;: 0.999999995, &#39;rouge2&#39;: 0.999999995, &#39;rougeL&#39;: 0.999999995}</span>
<span class="go">    ]</span>
<span class="go">)</span>
</code></pre></div>







              <details class="quote">
                <summary>Source code in <code>flexeval/core/metric/rouge.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">ROUGE</span><span class="p">(</span><span class="n">Metric</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;An implementation of [ROUGE](https://aclanthology.org/W04-1013/).</span>

<span class="sd">    The calculation is based on the [rouge](https://github.com/pltrdy/rouge) library.</span>

<span class="sd">    Args:</span>
<span class="sd">        tokenizer: An instance of `Tokenizer` to tokenize the input and output strings.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from flexeval import ROUGE</span>
<span class="sd">        &gt;&gt;&gt; from flexeval import WhitespaceTokenizer</span>
<span class="sd">        &gt;&gt;&gt; tokenizer = WhitespaceTokenizer()</span>
<span class="sd">        &gt;&gt;&gt; rouge = ROUGE(tokenizer)</span>
<span class="sd">        &gt;&gt;&gt; lm_outputs = [&quot;I am a student .&quot;, &quot;I am a teacher .&quot;]</span>
<span class="sd">        &gt;&gt;&gt; references_list = [[&quot;I am a student .&quot;, &quot;I am a learner .&quot;], [&quot;I am a teacher .&quot;]]</span>
<span class="sd">        &gt;&gt;&gt; result = rouge.evaluate(lm_outputs, references_list)</span>
<span class="sd">        &gt;&gt;&gt; print(result)</span>
<span class="sd">        MetricResult(</span>
<span class="sd">            summary={&#39;rouge1&#39;: 0.999999995, &#39;rouge2&#39;: 0.999999995, &#39;rougeL&#39;: 0.999999995},</span>
<span class="sd">            instance_details=[</span>
<span class="sd">                {&#39;rouge1&#39;: 0.999999995, &#39;rouge2&#39;: 0.999999995, &#39;rougeL&#39;: 0.999999995},</span>
<span class="sd">                {&#39;rouge1&#39;: 0.999999995, &#39;rouge2&#39;: 0.999999995, &#39;rougeL&#39;: 0.999999995}</span>
<span class="sd">            ]</span>
<span class="sd">        )</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">:</span> <span class="n">Tokenizer</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_tokenizer</span> <span class="o">=</span> <span class="n">tokenizer</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">lm_outputs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">references_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
        <span class="n">task_inputs_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MetricResult</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">lm_outputs</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">references_list</span><span class="p">):</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;lm_outputs and references_list must have the same length, &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;but got </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">lm_outputs</span><span class="p">)</span><span class="si">}</span><span class="s2"> and </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">references_list</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

        <span class="c1"># we only need the first reference</span>
        <span class="n">target_summaries</span> <span class="o">=</span> <span class="p">[</span><span class="n">references</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">references</span> <span class="ow">in</span> <span class="n">references_list</span><span class="p">]</span>

        <span class="n">tokenized_lm_outputs</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">lm_output</span><span class="p">))</span> <span class="k">for</span> <span class="n">lm_output</span> <span class="ow">in</span> <span class="n">lm_outputs</span><span class="p">]</span>
        <span class="n">tokenized_target_summaries</span> <span class="o">=</span> <span class="p">[</span>
            <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">target_summary</span><span class="p">))</span> <span class="k">for</span> <span class="n">target_summary</span> <span class="ow">in</span> <span class="n">target_summaries</span>
        <span class="p">]</span>

        <span class="c1"># replace empty string with &quot; &quot; to avoid &quot;ValueError: Hypothesis is empty&quot; from rouge</span>
        <span class="n">tokenized_lm_outputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">o</span> <span class="k">if</span> <span class="n">o</span> <span class="k">else</span> <span class="s2">&quot; &quot;</span> <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="n">tokenized_lm_outputs</span><span class="p">]</span>

        <span class="n">rouge</span> <span class="o">=</span> <span class="n">RougeCalculator</span><span class="p">()</span>
        <span class="n">score_outputs</span> <span class="o">=</span> <span class="n">rouge</span><span class="o">.</span><span class="n">get_scores</span><span class="p">(</span>
            <span class="n">tokenized_lm_outputs</span><span class="p">,</span>
            <span class="n">tokenized_target_summaries</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">rouge1_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">o</span><span class="p">[</span><span class="s2">&quot;rouge-1&quot;</span><span class="p">][</span><span class="s2">&quot;f&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="n">score_outputs</span><span class="p">]</span>
        <span class="n">rouge2_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">o</span><span class="p">[</span><span class="s2">&quot;rouge-2&quot;</span><span class="p">][</span><span class="s2">&quot;f&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="n">score_outputs</span><span class="p">]</span>
        <span class="n">rouge_l_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">o</span><span class="p">[</span><span class="s2">&quot;rouge-l&quot;</span><span class="p">][</span><span class="s2">&quot;f&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="n">score_outputs</span><span class="p">]</span>

        <span class="c1"># we only need the f1 score</span>
        <span class="k">return</span> <span class="n">MetricResult</span><span class="p">(</span>
            <span class="p">{</span>
                <span class="s2">&quot;rouge1&quot;</span><span class="p">:</span> <span class="nb">sum</span><span class="p">(</span><span class="n">rouge1_list</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">rouge1_list</span><span class="p">),</span>
                <span class="s2">&quot;rouge2&quot;</span><span class="p">:</span> <span class="nb">sum</span><span class="p">(</span><span class="n">rouge2_list</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">rouge2_list</span><span class="p">),</span>
                <span class="s2">&quot;rougeL&quot;</span><span class="p">:</span> <span class="nb">sum</span><span class="p">(</span><span class="n">rouge_l_list</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">rouge_l_list</span><span class="p">),</span>
            <span class="p">},</span>
            <span class="n">instance_details</span><span class="o">=</span><span class="p">[</span>
                <span class="p">{</span><span class="s2">&quot;rouge1&quot;</span><span class="p">:</span> <span class="n">r1</span><span class="p">,</span> <span class="s2">&quot;rouge2&quot;</span><span class="p">:</span> <span class="n">r2</span><span class="p">,</span> <span class="s2">&quot;rougeL&quot;</span><span class="p">:</span> <span class="n">rL</span><span class="p">}</span> <span class="k">for</span> <span class="n">r1</span><span class="p">,</span> <span class="n">r2</span><span class="p">,</span> <span class="n">rL</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">rouge1_list</span><span class="p">,</span> <span class="n">rouge2_list</span><span class="p">,</span> <span class="n">rouge_l_list</span><span class="p">)</span>
            <span class="p">],</span>
        <span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="flexeval.core.metric.rouge.ROUGE.__init__" class="doc doc-heading">
            <span class="doc doc-object-name doc-function-name">__init__</span>


<a href="#flexeval.core.metric.rouge.ROUGE.__init__" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="fm">__init__</span><span class="p">(</span><span class="nf">tokenizer</span><span class="p">:</span> <span class="n">Tokenizer</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>

    <div class="doc doc-contents ">


            <details class="quote">
              <summary>Source code in <code>flexeval/core/metric/rouge.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">36</span>
<span class="normal">37</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">:</span> <span class="n">Tokenizer</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_tokenizer</span> <span class="o">=</span> <span class="n">tokenizer</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="flexeval.core.metric.rouge.ROUGE.evaluate" class="doc doc-heading">
            <span class="doc doc-object-name doc-function-name">evaluate</span>


<a href="#flexeval.core.metric.rouge.ROUGE.evaluate" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="nf">evaluate</span><span class="p">(</span>
    <span class="n">lm_outputs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">references_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
    <span class="n">task_inputs_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MetricResult</span>
</code></pre></div>

    <div class="doc doc-contents ">


            <details class="quote">
              <summary>Source code in <code>flexeval/core/metric/rouge.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">lm_outputs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">references_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
    <span class="n">task_inputs_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MetricResult</span><span class="p">:</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">lm_outputs</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">references_list</span><span class="p">):</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;lm_outputs and references_list must have the same length, &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;but got </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">lm_outputs</span><span class="p">)</span><span class="si">}</span><span class="s2"> and </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">references_list</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span>
        <span class="p">)</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

    <span class="c1"># we only need the first reference</span>
    <span class="n">target_summaries</span> <span class="o">=</span> <span class="p">[</span><span class="n">references</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">references</span> <span class="ow">in</span> <span class="n">references_list</span><span class="p">]</span>

    <span class="n">tokenized_lm_outputs</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">lm_output</span><span class="p">))</span> <span class="k">for</span> <span class="n">lm_output</span> <span class="ow">in</span> <span class="n">lm_outputs</span><span class="p">]</span>
    <span class="n">tokenized_target_summaries</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">target_summary</span><span class="p">))</span> <span class="k">for</span> <span class="n">target_summary</span> <span class="ow">in</span> <span class="n">target_summaries</span>
    <span class="p">]</span>

    <span class="c1"># replace empty string with &quot; &quot; to avoid &quot;ValueError: Hypothesis is empty&quot; from rouge</span>
    <span class="n">tokenized_lm_outputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">o</span> <span class="k">if</span> <span class="n">o</span> <span class="k">else</span> <span class="s2">&quot; &quot;</span> <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="n">tokenized_lm_outputs</span><span class="p">]</span>

    <span class="n">rouge</span> <span class="o">=</span> <span class="n">RougeCalculator</span><span class="p">()</span>
    <span class="n">score_outputs</span> <span class="o">=</span> <span class="n">rouge</span><span class="o">.</span><span class="n">get_scores</span><span class="p">(</span>
        <span class="n">tokenized_lm_outputs</span><span class="p">,</span>
        <span class="n">tokenized_target_summaries</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">rouge1_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">o</span><span class="p">[</span><span class="s2">&quot;rouge-1&quot;</span><span class="p">][</span><span class="s2">&quot;f&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="n">score_outputs</span><span class="p">]</span>
    <span class="n">rouge2_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">o</span><span class="p">[</span><span class="s2">&quot;rouge-2&quot;</span><span class="p">][</span><span class="s2">&quot;f&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="n">score_outputs</span><span class="p">]</span>
    <span class="n">rouge_l_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">o</span><span class="p">[</span><span class="s2">&quot;rouge-l&quot;</span><span class="p">][</span><span class="s2">&quot;f&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="n">score_outputs</span><span class="p">]</span>

    <span class="c1"># we only need the f1 score</span>
    <span class="k">return</span> <span class="n">MetricResult</span><span class="p">(</span>
        <span class="p">{</span>
            <span class="s2">&quot;rouge1&quot;</span><span class="p">:</span> <span class="nb">sum</span><span class="p">(</span><span class="n">rouge1_list</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">rouge1_list</span><span class="p">),</span>
            <span class="s2">&quot;rouge2&quot;</span><span class="p">:</span> <span class="nb">sum</span><span class="p">(</span><span class="n">rouge2_list</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">rouge2_list</span><span class="p">),</span>
            <span class="s2">&quot;rougeL&quot;</span><span class="p">:</span> <span class="nb">sum</span><span class="p">(</span><span class="n">rouge_l_list</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">rouge_l_list</span><span class="p">),</span>
        <span class="p">},</span>
        <span class="n">instance_details</span><span class="o">=</span><span class="p">[</span>
            <span class="p">{</span><span class="s2">&quot;rouge1&quot;</span><span class="p">:</span> <span class="n">r1</span><span class="p">,</span> <span class="s2">&quot;rouge2&quot;</span><span class="p">:</span> <span class="n">r2</span><span class="p">,</span> <span class="s2">&quot;rougeL&quot;</span><span class="p">:</span> <span class="n">rL</span><span class="p">}</span> <span class="k">for</span> <span class="n">r1</span><span class="p">,</span> <span class="n">r2</span><span class="p">,</span> <span class="n">rL</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">rouge1_list</span><span class="p">,</span> <span class="n">rouge2_list</span><span class="p">,</span> <span class="n">rouge_l_list</span><span class="p">)</span>
        <span class="p">],</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="flexeval.core.metric.substring_match.SubstringMatch" class="doc doc-heading">
            <span class="doc doc-object-name doc-class-name">SubstringMatch</span>


<a href="#flexeval.core.metric.substring_match.SubstringMatch" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents first">


        <p>A metric that calculates how many outputs contain any of the expected substrings.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>mode</code></b>
              (<code><span title="typing.Literal">Literal</span>[&#39;any&#39;, &#39;all&#39;]</code>, default:
                  <code>&#39;any&#39;</code>
)
          –
          <div class="doc-md-description">
            <p>The mode to calculate the substring match.
- "any": If any of the expected substrings are in the output, it is a match.
- "all": If all of the expected substrings are in the output, it is a match.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
            <b><code>category_key</code></b>
              (<code><span title="str">str</span> | None</code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>Optional key to group scores by category from task_inputs_list.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">flexeval</span><span class="w"> </span><span class="kn">import</span> <span class="n">SubstringMatch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">substring_match</span> <span class="o">=</span> <span class="n">SubstringMatch</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lm_outputs</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;This is a cat .&quot;</span><span class="p">,</span> <span class="s2">&quot;This is a dog .&quot;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">references_list</span> <span class="o">=</span> <span class="p">[[</span><span class="s2">&quot;cat&quot;</span><span class="p">,</span> <span class="s2">&quot;dog&quot;</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;mouse&quot;</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">substring_match</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">lm_outputs</span><span class="p">,</span> <span class="n">references_list</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
<span class="go">MetricResult(</span>
<span class="go">    summary={&#39;substring_match&#39;: 0.5},</span>
<span class="go">    instance_details=[{&#39;substring_match&#39;: True}, {&#39;substring_match&#39;: False}]</span>
<span class="go">)</span>
</code></pre></div>







              <details class="quote">
                <summary>Source code in <code>flexeval/core/metric/substring_match.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">SubstringMatch</span><span class="p">(</span><span class="n">Metric</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A metric that calculates how many outputs contain any of the expected substrings.</span>

<span class="sd">    Args:</span>
<span class="sd">        mode: The mode to calculate the substring match.</span>
<span class="sd">            - &quot;any&quot;: If any of the expected substrings are in the output, it is a match.</span>
<span class="sd">            - &quot;all&quot;: If all of the expected substrings are in the output, it is a match.</span>
<span class="sd">        category_key: Optional key to group scores by category from task_inputs_list.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from flexeval import SubstringMatch</span>
<span class="sd">        &gt;&gt;&gt; substring_match = SubstringMatch()</span>
<span class="sd">        &gt;&gt;&gt; lm_outputs = [&quot;This is a cat .&quot;, &quot;This is a dog .&quot;]</span>
<span class="sd">        &gt;&gt;&gt; references_list = [[&quot;cat&quot;, &quot;dog&quot;], [&quot;mouse&quot;]]</span>
<span class="sd">        &gt;&gt;&gt; result = substring_match.evaluate(lm_outputs, references_list)</span>
<span class="sd">        &gt;&gt;&gt; print(result)</span>
<span class="sd">        MetricResult(</span>
<span class="sd">            summary={&#39;substring_match&#39;: 0.5},</span>
<span class="sd">            instance_details=[{&#39;substring_match&#39;: True}, {&#39;substring_match&#39;: False}]</span>
<span class="sd">        )</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mode</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;any&quot;</span><span class="p">,</span> <span class="s2">&quot;all&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;any&quot;</span><span class="p">,</span> <span class="n">category_key</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="n">mode</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">category_key</span> <span class="o">=</span> <span class="n">category_key</span>
        <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;all&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">match_func</span> <span class="o">=</span> <span class="nb">all</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;any&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">match_func</span> <span class="o">=</span> <span class="nb">any</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;mode must be &#39;any&#39; or &#39;all&#39;, but got &#39;</span><span class="si">{</span><span class="n">mode</span><span class="si">}</span><span class="s2">&#39;.&quot;</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">lm_outputs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">references_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
        <span class="n">task_inputs_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MetricResult</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">lm_outputs</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">references_list</span><span class="p">):</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;lm_outputs and references_list must have the same length, &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;but got </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">lm_outputs</span><span class="p">)</span><span class="si">}</span><span class="s2"> and </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">references_list</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

        <span class="n">match_list</span> <span class="o">=</span> <span class="p">[</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">match_func</span><span class="p">(</span><span class="n">substring</span> <span class="ow">in</span> <span class="n">lm_output</span> <span class="k">for</span> <span class="n">substring</span> <span class="ow">in</span> <span class="n">expected_output</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">lm_output</span><span class="p">,</span> <span class="n">expected_output</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">lm_outputs</span><span class="p">,</span> <span class="n">references_list</span><span class="p">)</span>
        <span class="p">]</span>

        <span class="n">score</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">match_list</span><span class="p">):</span>
            <span class="n">score</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">match_list</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">match_list</span><span class="p">)</span>

        <span class="n">summary</span> <span class="o">=</span> <span class="p">{</span><span class="sa">f</span><span class="s2">&quot;substring_match-</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">mode</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">:</span> <span class="n">score</span><span class="p">}</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">category_key</span><span class="p">:</span>
            <span class="n">categories</span> <span class="o">=</span> <span class="p">[</span><span class="n">task_input</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">category_key</span><span class="p">]</span> <span class="k">for</span> <span class="n">task_input</span> <span class="ow">in</span> <span class="n">task_inputs_list</span><span class="p">]</span>
            <span class="n">category_wise_scores</span> <span class="o">=</span> <span class="n">aggregate_category_wise_scores</span><span class="p">(</span><span class="n">match_list</span><span class="p">,</span> <span class="n">categories</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">category</span><span class="p">,</span> <span class="n">category_wise_score</span> <span class="ow">in</span> <span class="n">category_wise_scores</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="n">summary</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;substring_match-</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">mode</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">category</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">category_wise_score</span>

        <span class="k">return</span> <span class="n">MetricResult</span><span class="p">(</span>
            <span class="n">summary</span><span class="p">,</span>
            <span class="n">instance_details</span><span class="o">=</span><span class="p">[{</span><span class="s2">&quot;substring_match&quot;</span><span class="p">:</span> <span class="n">match</span><span class="p">}</span> <span class="k">for</span> <span class="n">match</span> <span class="ow">in</span> <span class="n">match_list</span><span class="p">],</span>
        <span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.substring_match.SubstringMatch.mode" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">mode</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.substring_match.SubstringMatch.mode" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">mode</span> <span class="o">=</span> <span class="n">mode</span>
</code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.substring_match.SubstringMatch.category_key" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">category_key</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.substring_match.SubstringMatch.category_key" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">category_key</span> <span class="o">=</span> <span class="n">category_key</span>
</code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.substring_match.SubstringMatch.match_func" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">match_func</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.substring_match.SubstringMatch.match_func" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">match_func</span> <span class="o">=</span> <span class="nb">all</span>
</code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>



<div class="doc doc-object doc-function">


<h3 id="flexeval.core.metric.substring_match.SubstringMatch.__init__" class="doc doc-heading">
            <span class="doc doc-object-name doc-function-name">__init__</span>


<a href="#flexeval.core.metric.substring_match.SubstringMatch.__init__" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="fm">__init__</span><span class="p">(</span>
    <span class="nf">mode</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;any&quot;</span><span class="p">,</span> <span class="s2">&quot;all&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;any&quot;</span><span class="p">,</span>
    <span class="n">category_key</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>

    <div class="doc doc-contents ">


            <details class="quote">
              <summary>Source code in <code>flexeval/core/metric/substring_match.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mode</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;any&quot;</span><span class="p">,</span> <span class="s2">&quot;all&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;any&quot;</span><span class="p">,</span> <span class="n">category_key</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="n">mode</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">category_key</span> <span class="o">=</span> <span class="n">category_key</span>
    <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;all&quot;</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">match_func</span> <span class="o">=</span> <span class="nb">all</span>
    <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;any&quot;</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">match_func</span> <span class="o">=</span> <span class="nb">any</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;mode must be &#39;any&#39; or &#39;all&#39;, but got &#39;</span><span class="si">{</span><span class="n">mode</span><span class="si">}</span><span class="s2">&#39;.&quot;</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="flexeval.core.metric.substring_match.SubstringMatch.evaluate" class="doc doc-heading">
            <span class="doc doc-object-name doc-function-name">evaluate</span>


<a href="#flexeval.core.metric.substring_match.SubstringMatch.evaluate" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="nf">evaluate</span><span class="p">(</span>
    <span class="n">lm_outputs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">references_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
    <span class="n">task_inputs_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MetricResult</span>
</code></pre></div>

    <div class="doc doc-contents ">


            <details class="quote">
              <summary>Source code in <code>flexeval/core/metric/substring_match.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">lm_outputs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">references_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
    <span class="n">task_inputs_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MetricResult</span><span class="p">:</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">lm_outputs</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">references_list</span><span class="p">):</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;lm_outputs and references_list must have the same length, &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;but got </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">lm_outputs</span><span class="p">)</span><span class="si">}</span><span class="s2"> and </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">references_list</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span>
        <span class="p">)</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

    <span class="n">match_list</span> <span class="o">=</span> <span class="p">[</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">match_func</span><span class="p">(</span><span class="n">substring</span> <span class="ow">in</span> <span class="n">lm_output</span> <span class="k">for</span> <span class="n">substring</span> <span class="ow">in</span> <span class="n">expected_output</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">lm_output</span><span class="p">,</span> <span class="n">expected_output</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">lm_outputs</span><span class="p">,</span> <span class="n">references_list</span><span class="p">)</span>
    <span class="p">]</span>

    <span class="n">score</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">match_list</span><span class="p">):</span>
        <span class="n">score</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">match_list</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">match_list</span><span class="p">)</span>

    <span class="n">summary</span> <span class="o">=</span> <span class="p">{</span><span class="sa">f</span><span class="s2">&quot;substring_match-</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">mode</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">:</span> <span class="n">score</span><span class="p">}</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">category_key</span><span class="p">:</span>
        <span class="n">categories</span> <span class="o">=</span> <span class="p">[</span><span class="n">task_input</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">category_key</span><span class="p">]</span> <span class="k">for</span> <span class="n">task_input</span> <span class="ow">in</span> <span class="n">task_inputs_list</span><span class="p">]</span>
        <span class="n">category_wise_scores</span> <span class="o">=</span> <span class="n">aggregate_category_wise_scores</span><span class="p">(</span><span class="n">match_list</span><span class="p">,</span> <span class="n">categories</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">category</span><span class="p">,</span> <span class="n">category_wise_score</span> <span class="ow">in</span> <span class="n">category_wise_scores</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">summary</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;substring_match-</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">mode</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">category</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">category_wise_score</span>

    <span class="k">return</span> <span class="n">MetricResult</span><span class="p">(</span>
        <span class="n">summary</span><span class="p">,</span>
        <span class="n">instance_details</span><span class="o">=</span><span class="p">[{</span><span class="s2">&quot;substring_match&quot;</span><span class="p">:</span> <span class="n">match</span><span class="p">}</span> <span class="k">for</span> <span class="n">match</span> <span class="ow">in</span> <span class="n">match_list</span><span class="p">],</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="flexeval.core.metric.xer.XER" class="doc doc-heading">
            <span class="doc doc-object-name doc-class-name">XER</span>


<a href="#flexeval.core.metric.xer.XER" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents first">


        <p>Calculate the Character Error Rate (CER) and Word Error Rate (WER) between the model outputs and the references.
The calculation is based on the <a href="https://github.com/jitsi/jiwer">jiwer</a> library.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
            <b><code>tokenizer</code></b>
              (<code><a class="autorefs autorefs-internal" title="Tokenizer (flexeval.core.tokenizer.Tokenizer)" href="../Tokenizer/#flexeval.core.tokenizer.base.Tokenizer">Tokenizer</a> | None</code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>An instance of <code>Tokenizer</code> to tokenize the input and output strings.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">flexeval</span><span class="w"> </span><span class="kn">import</span> <span class="n">XER</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xer</span> <span class="o">=</span> <span class="n">XER</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lm_outputs</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;I am a student .&quot;</span><span class="p">,</span> <span class="s2">&quot;I am a teacher .&quot;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">references_list</span> <span class="o">=</span> <span class="p">[[</span><span class="s2">&quot;I am a student .&quot;</span><span class="p">,</span> <span class="s2">&quot;I am a learner .&quot;</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;Are you the student ?&quot;</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">xer</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">lm_outputs</span><span class="p">,</span> <span class="n">references_list</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
<span class="go">MetricResult(</span>
<span class="go">    summary={&#39;cer_score&#39;: 0.43243243243243246, &#39;wer_score&#39;: 0.5},</span>
<span class="go">    instance_details=[{&#39;cer_score&#39;: 0.0, &#39;wer_score&#39;: 0.0}, {&#39;cer_score&#39;: 0.7619047619047619, &#39;wer_score&#39;: 1.0}</span>
<span class="go">    ]</span>
<span class="go">)</span>
</code></pre></div>







              <details class="quote">
                <summary>Source code in <code>flexeval/core/metric/xer.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">XER</span><span class="p">(</span><span class="n">Metric</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate the Character Error Rate (CER) and Word Error Rate (WER) between the model outputs and the references.</span>
<span class="sd">    The calculation is based on the [jiwer](https://github.com/jitsi/jiwer) library.</span>

<span class="sd">    Args:</span>
<span class="sd">        tokenizer: An instance of `Tokenizer` to tokenize the input and output strings.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; from flexeval import XER</span>
<span class="sd">        &gt;&gt;&gt; xer = XER()</span>
<span class="sd">        &gt;&gt;&gt; lm_outputs = [&quot;I am a student .&quot;, &quot;I am a teacher .&quot;]</span>
<span class="sd">        &gt;&gt;&gt; references_list = [[&quot;I am a student .&quot;, &quot;I am a learner .&quot;], [&quot;Are you the student ?&quot;]]</span>
<span class="sd">        &gt;&gt;&gt; result = xer.evaluate(lm_outputs, references_list)</span>
<span class="sd">        &gt;&gt;&gt; print(result)</span>
<span class="sd">        MetricResult(</span>
<span class="sd">            summary={&#39;cer_score&#39;: 0.43243243243243246, &#39;wer_score&#39;: 0.5},</span>
<span class="sd">            instance_details=[{&#39;cer_score&#39;: 0.0, &#39;wer_score&#39;: 0.0}, {&#39;cer_score&#39;: 0.7619047619047619, &#39;wer_score&#39;: 1.0}</span>
<span class="sd">            ]</span>
<span class="sd">        )</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">:</span> <span class="n">Tokenizer</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">tokenizer</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">lm_outputs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">references_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
        <span class="n">task_inputs_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MetricResult</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">lm_outputs</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">references_list</span><span class="p">):</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;lm_outputs and references_list must have the same length, &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;but got </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">lm_outputs</span><span class="p">)</span><span class="si">}</span><span class="s2"> and </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">references_list</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

        <span class="c1"># we only need the first reference</span>
        <span class="n">references</span> <span class="o">=</span> <span class="p">[</span><span class="n">references</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">references</span> <span class="ow">in</span> <span class="n">references_list</span><span class="p">]</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">:</span>
            <span class="n">tokenized_lm_outputs</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">lm_output</span><span class="p">))</span> <span class="k">for</span> <span class="n">lm_output</span> <span class="ow">in</span> <span class="n">lm_outputs</span><span class="p">]</span>
            <span class="n">tokenized_references</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">reference</span><span class="p">))</span> <span class="k">for</span> <span class="n">reference</span> <span class="ow">in</span> <span class="n">references</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">tokenized_lm_outputs</span> <span class="o">=</span> <span class="n">lm_outputs</span>
            <span class="n">tokenized_references</span> <span class="o">=</span> <span class="n">references</span>

        <span class="n">cer_score</span> <span class="o">=</span> <span class="n">cer</span><span class="p">(</span><span class="n">references</span><span class="p">,</span> <span class="n">lm_outputs</span><span class="p">)</span>
        <span class="n">wer_score</span> <span class="o">=</span> <span class="n">wer</span><span class="p">(</span><span class="n">tokenized_references</span><span class="p">,</span> <span class="n">tokenized_lm_outputs</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">MetricResult</span><span class="p">(</span>
            <span class="p">{</span>
                <span class="s2">&quot;cer_score&quot;</span><span class="p">:</span> <span class="n">cer_score</span><span class="p">,</span>
                <span class="s2">&quot;wer_score&quot;</span><span class="p">:</span> <span class="n">wer_score</span><span class="p">,</span>
            <span class="p">},</span>
            <span class="n">instance_details</span><span class="o">=</span><span class="p">[</span>
                <span class="p">{</span>
                    <span class="s2">&quot;cer_score&quot;</span><span class="p">:</span> <span class="n">cer</span><span class="p">(</span><span class="n">reference</span><span class="p">,</span> <span class="n">lm_output</span><span class="p">),</span>
                    <span class="s2">&quot;wer_score&quot;</span><span class="p">:</span> <span class="n">wer</span><span class="p">(</span><span class="n">reference</span><span class="p">,</span> <span class="n">lm_output</span><span class="p">),</span>
                <span class="p">}</span>
                <span class="k">for</span> <span class="n">lm_output</span><span class="p">,</span> <span class="n">reference</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">lm_outputs</span><span class="p">,</span> <span class="n">references</span><span class="p">)</span>
            <span class="p">],</span>
        <span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h3 id="flexeval.core.metric.xer.XER.tokenizer" class="doc doc-heading">
            <span class="doc doc-object-name doc-attribute-name">tokenizer</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#flexeval.core.metric.xer.XER.tokenizer" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">tokenizer</span>
</code></pre></div>

    <div class="doc doc-contents ">

    </div>

</div>



<div class="doc doc-object doc-function">


<h3 id="flexeval.core.metric.xer.XER.__init__" class="doc doc-heading">
            <span class="doc doc-object-name doc-function-name">__init__</span>


<a href="#flexeval.core.metric.xer.XER.__init__" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="fm">__init__</span><span class="p">(</span><span class="nf">tokenizer</span><span class="p">:</span> <span class="n">Tokenizer</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>

    <div class="doc doc-contents ">


            <details class="quote">
              <summary>Source code in <code>flexeval/core/metric/xer.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">32</span>
<span class="normal">33</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">:</span> <span class="n">Tokenizer</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">tokenizer</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="flexeval.core.metric.xer.XER.evaluate" class="doc doc-heading">
            <span class="doc doc-object-name doc-function-name">evaluate</span>


<a href="#flexeval.core.metric.xer.XER.evaluate" class="headerlink" title="Permanent link">&para;</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><span class="nf">evaluate</span><span class="p">(</span>
    <span class="n">lm_outputs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">references_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
    <span class="n">task_inputs_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MetricResult</span>
</code></pre></div>

    <div class="doc doc-contents ">


            <details class="quote">
              <summary>Source code in <code>flexeval/core/metric/xer.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">lm_outputs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">references_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
    <span class="n">task_inputs_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MetricResult</span><span class="p">:</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">lm_outputs</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">references_list</span><span class="p">):</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;lm_outputs and references_list must have the same length, &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;but got </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">lm_outputs</span><span class="p">)</span><span class="si">}</span><span class="s2"> and </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">references_list</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span>
        <span class="p">)</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

    <span class="c1"># we only need the first reference</span>
    <span class="n">references</span> <span class="o">=</span> <span class="p">[</span><span class="n">references</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">references</span> <span class="ow">in</span> <span class="n">references_list</span><span class="p">]</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">:</span>
        <span class="n">tokenized_lm_outputs</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">lm_output</span><span class="p">))</span> <span class="k">for</span> <span class="n">lm_output</span> <span class="ow">in</span> <span class="n">lm_outputs</span><span class="p">]</span>
        <span class="n">tokenized_references</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">reference</span><span class="p">))</span> <span class="k">for</span> <span class="n">reference</span> <span class="ow">in</span> <span class="n">references</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">tokenized_lm_outputs</span> <span class="o">=</span> <span class="n">lm_outputs</span>
        <span class="n">tokenized_references</span> <span class="o">=</span> <span class="n">references</span>

    <span class="n">cer_score</span> <span class="o">=</span> <span class="n">cer</span><span class="p">(</span><span class="n">references</span><span class="p">,</span> <span class="n">lm_outputs</span><span class="p">)</span>
    <span class="n">wer_score</span> <span class="o">=</span> <span class="n">wer</span><span class="p">(</span><span class="n">tokenized_references</span><span class="p">,</span> <span class="n">tokenized_lm_outputs</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">MetricResult</span><span class="p">(</span>
        <span class="p">{</span>
            <span class="s2">&quot;cer_score&quot;</span><span class="p">:</span> <span class="n">cer_score</span><span class="p">,</span>
            <span class="s2">&quot;wer_score&quot;</span><span class="p">:</span> <span class="n">wer_score</span><span class="p">,</span>
        <span class="p">},</span>
        <span class="n">instance_details</span><span class="o">=</span><span class="p">[</span>
            <span class="p">{</span>
                <span class="s2">&quot;cer_score&quot;</span><span class="p">:</span> <span class="n">cer</span><span class="p">(</span><span class="n">reference</span><span class="p">,</span> <span class="n">lm_output</span><span class="p">),</span>
                <span class="s2">&quot;wer_score&quot;</span><span class="p">:</span> <span class="n">wer</span><span class="p">(</span><span class="n">reference</span><span class="p">,</span> <span class="n">lm_output</span><span class="p">),</span>
            <span class="p">}</span>
            <span class="k">for</span> <span class="n">lm_output</span><span class="p">,</span> <span class="n">reference</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">lm_outputs</span><span class="p">,</span> <span class="n">references</span><span class="p">)</span>
        <span class="p">],</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": [], "search": "../../assets/javascripts/workers/search.f8cc74c7.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.f1b6f286.min.js"></script>
      
    
  </body>
</html>